---
title: Language Instructed Reinforcement Learning for Human-AI Coordination
openreview: CSAAs2QAyW
abstract: One of the fundamental quests of AI is to produce agents that coordinate
  well with humans. This problem is challenging, especially in domains that lack high
  quality human behavioral data, because multi-agent reinforcement learning (RL) often
  converges to different equilibria from the ones that humans prefer. We propose a
  novel framework, instructRL, that enables humans to specify what kind of strategies
  they expect from their AI partners through natural language instructions. We use
  pretrained large language models to generate a prior policy conditioned on the human
  instruction and use the prior to regularize the RL objective. This leads to the
  RL agent converging to equilibria that are aligned with human preferences. We show
  that instructRL converges to human-like policies that satisfy the given instructions
  in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally,
  we show that knowing the language instruction significantly boosts human-AI coordination
  performance in human evaluations in Hanabi.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu23e
month: 0
tex_title: Language Instructed Reinforcement Learning for Human-{AI} Coordination
firstpage: 13584
lastpage: 13598
page: 13584-13598
order: 13584
cycles: false
bibtex_author: Hu, Hengyuan and Sadigh, Dorsa
author:
- given: Hengyuan
  family: Hu
- given: Dorsa
  family: Sadigh
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/hu23e/hu23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
