---
title: Inverse Reinforcement Learning without Reinforcement Learning
openreview: NrJCNcI5WV
abstract: 'Inverse Reinforcement Learning (IRL) is a powerful set of techniques for
  imitation learning that aims to learn a reward function that rationalizes expert
  demonstrations. Unfortunately, traditional IRL methods suffer from a computational
  weakness: they require repeatedly solving a hard reinforcement learning (RL) problem
  as a subroutine. This is counter-intuitive from the viewpoint of reductions: we
  have reduced the <em>easier</em> problem of imitation learning to repeatedly solving
  the <em>harder</em> problem of RL. Another thread of work has proved that access
  to the side-information of the distribution of states where a strong policy spends
  time can dramatically reduce the sample and computational complexities of solving
  an RL problem. In this work, we demonstrate for the first time a more informed imitation
  learning reduction where we utilize the state distribution of the expert to alleviate
  the global exploration component of the RL subroutine, providing an <em>exponential</em>
  speedup in theory. In practice, we find that we are able to significantly speed
  up the prior art on continuous control tasks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: swamy23a
month: 0
tex_title: Inverse Reinforcement Learning without Reinforcement Learning
firstpage: 33299
lastpage: 33318
page: 33299-33318
order: 33299
cycles: false
bibtex_author: Swamy, Gokul and Wu, David and Choudhury, Sanjiban and Bagnell, Drew
  and Wu, Steven
author:
- given: Gokul
  family: Swamy
- given: David
  family: Wu
- given: Sanjiban
  family: Choudhury
- given: Drew
  family: Bagnell
- given: Steven
  family: Wu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/swamy23a/swamy23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
