---
title: Thompson Sampling with Diffusion Generative Prior
openreview: Eo7e468wi8
abstract: In this work, we initiate the idea of using denoising diffusion models to
  learn priors for online decision making problems. We specifically focus on bandit
  meta-learning, aiming to learn a policy that performs well across bandit tasks of
  a same class. To this end, we train a diffusion model that learns the underlying
  task distribution and combine Thompson sampling with the learned prior to deal with
  new tasks at test time. Our posterior sampling algorithm carefully balances between
  the learned prior and the noisy observations that come from the learner’s interaction
  with the environment. To capture realistic bandit scenarios, we propose a novel
  diffusion model training procedure that trains from incomplete and noisy data, which
  could be of independent interest. Finally, our extensive experiments clearly demonstrate
  the potential of the proposed approach.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hsieh23a
month: 0
tex_title: Thompson Sampling with Diffusion Generative Prior
firstpage: 13434
lastpage: 13468
page: 13434-13468
order: 13434
cycles: false
bibtex_author: Hsieh, Yu-Guan and Kasiviswanathan, Shiva and Kveton, Branislav and
  Bl\"{o}baum, Patrick
author:
- given: Yu-Guan
  family: Hsieh
- given: Shiva
  family: Kasiviswanathan
- given: Branislav
  family: Kveton
- given: Patrick
  family: Blöbaum
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/hsieh23a/hsieh23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
