---
title: On the Forward Invariance of Neural ODEs
openreview: jSkV9aP1Mi
abstract: We propose a new method to ensure neural ordinary differential equations
  (ODEs) satisfy output specifications by using invariance set propagation. Our approach
  uses a class of control barrier functions to transform output specifications into
  constraints on the parameters and inputs of the learning system. This setup allows
  us to achieve output specification guarantees simply by changing the constrained
  parameters/inputs both during training and inference. Moreover, we demonstrate that
  our invariance set propagation through data-controlled neural ODEs not only maintains
  generalization performance but also creates an additional degree of robustness by
  enabling causal manipulation of the systemâ€™s parameters/inputs. We test our method
  on a series of representation learning tasks, including modeling physical dynamics
  and convexity portraits, as well as safe collision avoidance for autonomous vehicles.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xiao23d
month: 0
tex_title: On the Forward Invariance of Neural {ODE}s
firstpage: 38100
lastpage: 38124
page: 38100-38124
order: 38100
cycles: false
bibtex_author: Xiao, Wei and Wang, Tsun-Hsuan and Hasani, Ramin and Lechner, Mathias
  and Ban, Yutong and Gan, Chuang and Rus, Daniela
author:
- given: Wei
  family: Xiao
- given: Tsun-Hsuan
  family: Wang
- given: Ramin
  family: Hasani
- given: Mathias
  family: Lechner
- given: Yutong
  family: Ban
- given: Chuang
  family: Gan
- given: Daniela
  family: Rus
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xiao23d/xiao23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
