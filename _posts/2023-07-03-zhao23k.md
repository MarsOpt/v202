---
title: Simplified Temporal Consistency Reinforcement Learning
openreview: IkhTCX9x5i
abstract: Reinforcement learning (RL) is able to solve complex sequential decision-making
  tasks but is currently limited by sample efficiency and required computation. To
  improve sample efficiency, recent work focuses on model-based RL which interleaves
  model learning with planning. Recent methods further utilize policy learning, value
  estimation, and, self-supervised learning as auxiliary objectives. In this paper
  we show that, surprisingly, a simple representation learning approach relying only
  on a latent dynamics model trained by latent temporal consistency is sufficient
  for high-performance RL. This applies when using pure planning with a dynamics model
  conditioned on the representation, but, also when utilizing the representation as
  policy and value function features in model-free RL. In experiments, our approach
  learns an accurate dynamics model to solve challenging high-dimensional locomotion
  tasks with online planners while being 4.1$\times$ faster to train compared to ensemble-based
  methods. With model-free RL without planning, especially on high-dimensional tasks,
  such as the Deepmind Control Suite Humanoid and Dog tasks, our approach outperforms
  model-free methods by a large margin and matches model-based methodsâ€™ sample efficiency
  while training 2.4$\times$ faster.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao23k
month: 0
tex_title: Simplified Temporal Consistency Reinforcement Learning
firstpage: 42227
lastpage: 42246
page: 42227-42246
order: 42227
cycles: false
bibtex_author: Zhao, Yi and Zhao, Wenshuai and Boney, Rinu and Kannala, Juho and Pajarinen,
  Joni
author:
- given: Yi
  family: Zhao
- given: Wenshuai
  family: Zhao
- given: Rinu
  family: Boney
- given: Juho
  family: Kannala
- given: Joni
  family: Pajarinen
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhao23k/zhao23k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
