---
title: Pareto Regret Analyses in Multi-objective Multi-armed Bandit
openreview: d28UZYETzI
abstract: We study Pareto optimality in multi-objective multi-armed bandit by providing
  a formulation of adversarial multi-objective multi-armed bandit and defining its
  Pareto regrets that can be applied to both stochastic and adversarial settings.
  The regrets do not rely on any scalarization functions and reflect Pareto optimality
  compared to scalarized regrets. We also present new algorithms assuming both with
  and without prior information of the multi-objective multi-armed bandit setting.
  The algorithms are shown optimal in adversarial settings and nearly optimal up to
  a logarithmic factor in stochastic settings simultaneously by our established upper
  bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show
  that the new regrets are consistent with the existing Pareto regret for stochastic
  settings and extend an adversarial attack mechanism from bandit to the multi-objective
  one.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu23i
month: 0
tex_title: Pareto Regret Analyses in Multi-objective Multi-armed Bandit
firstpage: 38499
lastpage: 38517
page: 38499-38517
order: 38499
cycles: false
bibtex_author: Xu, Mengfan and Klabjan, Diego
author:
- given: Mengfan
  family: Xu
- given: Diego
  family: Klabjan
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xu23i/xu23i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
