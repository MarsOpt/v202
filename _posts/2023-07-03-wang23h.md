---
title: On Regularization and Inference with Label Constraints
openreview: PsQJm6lG3s
abstract: Prior knowledge and symbolic rules in machine learning are often expressed
  in the form of label constraints, especially in structured prediction problems.
  In this work, we compare two common strategies for encoding label constraints in
  a machine learning pipeline, <em>regularization with constraints</em> and <em>constrained
  inference</em>, by quantifying their impact on model performance. For regularization,
  we show that it narrows the generalization gap by precluding models that are inconsistent
  with the constraints. However, its preference for small violations introduces a
  bias toward a suboptimal model. For constrained inference, we show that it reduces
  the population risk by correcting a modelâ€™s violation, and hence turns the violation
  into an advantage. Given these differences, we further explore the use of two approaches
  together and propose conditions for constrained inference to compensate for the
  bias introduced by regularization, aiming to improve both the model complexity and
  optimal risk.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23h
month: 0
tex_title: On Regularization and Inference with Label Constraints
firstpage: 35740
lastpage: 35762
page: 35740-35762
order: 35740
cycles: false
bibtex_author: Wang, Kaifu and He, Hangfeng and Nguyen, Tin D. and Kumar, Piyush and
  Roth, Dan
author:
- given: Kaifu
  family: Wang
- given: Hangfeng
  family: He
- given: Tin D.
  family: Nguyen
- given: Piyush
  family: Kumar
- given: Dan
  family: Roth
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wang23h/wang23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
