---
title: 'Hypothesis Transfer Learning with Surrogate Classification Losses: Generalization
  Bounds through Algorithmic Stability'
openreview: Dg5H4Qd0dZ
abstract: Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing
  for a previous task leverage, named the source, into a new one, the target, without
  requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt
  from such source data, relieving the hurdle of expansive data storage and providing
  great practical benefits. Hence, HTL is highly beneficial for real-world applications
  relying on big data. The analysis of such a method from a theoretical perspective
  faces multiple challenges, particularly in classification tasks. This paper deals
  with this problem by studying the learning theory of HTL through algorithmic stability,
  an attractive theoretical framework for machine learning algorithms analysis. In
  particular, we are interested in the statistical behavior of the regularized empirical
  risk minimizers in the case of binary classification. Our stability analysis provides
  learning guarantees under mild assumptions. Consequently, we derive several complexity-free
  generalization bounds for essential statistical quantities like the training error,
  the excess risk and cross-validation estimates. These refined bounds allow understanding
  the benefits of transfer learning and comparing the behavior of standard losses
  in different scenarios, leading to valuable insights for practitioners.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: aghbalou23a
month: 0
tex_title: 'Hypothesis Transfer Learning with Surrogate Classification Losses: Generalization
  Bounds through Algorithmic Stability'
firstpage: 280
lastpage: 303
page: 280-303
order: 280
cycles: false
bibtex_author: Aghbalou, Anass and Staerman, Guillaume
author:
- given: Anass
  family: Aghbalou
- given: Guillaume
  family: Staerman
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/aghbalou23a/aghbalou23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
