---
title: Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty
  Equivalents
openreview: na4JLS1Hh9
abstract: The optimized certainty equivalent (OCE) is a family of risk measures that
  cover important examples such as entropic risk, conditional value-at-risk and mean-variance
  models. In this paper, we propose a new episodic risk-sensitive reinforcement learning
  formulation based on tabular Markov decision processes with recursive OCEs. We design
  an efficient learning algorithm for this problem based on value iteration and upper
  confidence bound. We derive an upper bound on the regret of the proposed algorithm,
  and also establish a minimax lower bound. Our bounds show that the regret rate achieved
  by our proposed algorithm has optimal dependence on the number of episodes and the
  number of actions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu23d
month: 0
tex_title: Regret Bounds for {M}arkov Decision Processes with Recursive Optimized
  Certainty Equivalents
firstpage: 38400
lastpage: 38427
page: 38400-38427
order: 38400
cycles: false
bibtex_author: Xu, Wenhao and Gao, Xuefeng and He, Xuedong
author:
- given: Wenhao
  family: Xu
- given: Xuefeng
  family: Gao
- given: Xuedong
  family: He
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xu23d/xu23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
