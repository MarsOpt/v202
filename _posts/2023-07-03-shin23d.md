---
title: One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill
openreview: pmUI642icm
abstract: One-shot imitation is to learn a new task from a single demonstration, yet
  it is a challenging problem to adopt it for complex tasks with the high domain diversity
  inherent in a non-stationary environment. To tackle the problem, we explore the
  compositionality of complex tasks, and present a novel skill-based imitation learning
  framework enabling one-shot imitation and zero-shot adaptation; from a single demonstration
  for a complex unseen task, a semantic skill sequence is inferred and then each skill
  in the sequence is converted into an action sequence optimized for environmental
  hidden dynamics that can vary over time. Specifically, we leverage a vision-language
  model to learn a semantic skill set from offline video datasets, where each skill
  is represented on the vision-language embedding space, and adapt meta-learning with
  dynamics inference to enable zero-shot skill adaptation. We evaluate our framework
  with various one-shot imitation scenarios for extended multi-stage Meta-world tasks,
  showing its superiority in learning complex tasks, generalizing to dynamics changes,
  and extending to different demonstration conditions and modalities, compared to
  other baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shin23d
month: 0
tex_title: One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill
firstpage: 31562
lastpage: 31578
page: 31562-31578
order: 31562
cycles: false
bibtex_author: Shin, Sangwoo and Lee, Daehee and Yoo, Minjong and Kim, Woo Kyung and
  Woo, Honguk
author:
- given: Sangwoo
  family: Shin
- given: Daehee
  family: Lee
- given: Minjong
  family: Yoo
- given: Woo Kyung
  family: Kim
- given: Honguk
  family: Woo
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/shin23d/shin23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
