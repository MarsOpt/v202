---
title: Learning Temporally AbstractWorld Models without Online Experimentation
openreview: YeTYJz7th5
abstract: Agents that can build temporally abstract representations of their environment
  are better able to understand their world and make plans on extended time scales,
  with limited computational power and modeling capacity. However, existing methods
  for automatically learning temporally abstract world models usually require millions
  of online environmental interactions and incentivize agents to reach every accessible
  environmental state, which is infeasible for most real-world robots both in terms
  of data efficiency and hardware safety. In this paper, we present an approach for
  simultaneously learning sets of skills and temporally abstract, skill-conditioned
  world models purely from offline data, enabling agents to perform zero-shot online
  planning of skill sequences for new tasks. We show that our approach performs comparably
  to or better than a wide array of state-of-the-art offline RL algorithms on a number
  of simulated robotics locomotion and manipulation benchmarks, while offering a higher
  degree of adaptability to new goals. Finally, we show that our approach offers a
  much higher degree of robustness to perturbations in environmental dynamics, compared
  to policy-based methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: freed23a
month: 0
tex_title: Learning Temporally {A}bstract{W}orld Models without Online Experimentation
firstpage: 10338
lastpage: 10356
page: 10338-10356
order: 10338
cycles: false
bibtex_author: Freed, Benjamin and Venkatraman, Siddarth and Sartoretti, Guillaume
  Adrien and Schneider, Jeff and Choset, Howie
author:
- given: Benjamin
  family: Freed
- given: Siddarth
  family: Venkatraman
- given: Guillaume Adrien
  family: Sartoretti
- given: Jeff
  family: Schneider
- given: Howie
  family: Choset
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/freed23a/freed23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
