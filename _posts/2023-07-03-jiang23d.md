---
title: Online Restless Bandits with Unobserved States
openreview: 6gl82eUmkI
abstract: We study the online restless bandit problem, where each arm evolves according
  to a Markov chain independently, and the reward of pulling an arm depends on both
  the current state of the corresponding Markov chain and the pulled arm. The agent
  (decision maker) does not know the transition functions and reward functions, and
  cannot observe the states of arms even after pulling. The goal is to sequentially
  choose which arms to pull so as to maximize the expected cumulative rewards collected.
  In this paper, we propose TSEETC, a learning algorithm based on Thompson Sampling
  with Episodic Explore-Then-Commit. The algorithm proceeds in episodes of increasing
  length and each episode is divided into exploration and exploitation phases. During
  the exploration phase, samples of action-reward pairs are collected in a round-robin
  fashion and utilized to update the posterior distribution as a mixture of Dirichlet
  distributions. At the beginning of the exploitation phase, TSEETC generates a sample
  from the posterior distribution as true parameters. It then follows the optimal
  policy for the sampled model for the rest of the episode. We establish the Bayesian
  regret bound $\tilde {\mathcal{O}}(\sqrt{T})$ for TSEETC, where $T$ is the time
  horizon. We show through simulations that TSEETC outperforms existing algorithms
  in regret.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jiang23d
month: 0
tex_title: Online Restless Bandits with Unobserved States
firstpage: 15041
lastpage: 15066
page: 15041-15066
order: 15041
cycles: false
bibtex_author: Jiang, Bowen and Jiang, Bo and Li, Jian and Lin, Tao and Wang, Xinbing
  and Zhou, Chenghu
author:
- given: Bowen
  family: Jiang
- given: Bo
  family: Jiang
- given: Jian
  family: Li
- given: Tao
  family: Lin
- given: Xinbing
  family: Wang
- given: Chenghu
  family: Zhou
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/jiang23d/jiang23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
