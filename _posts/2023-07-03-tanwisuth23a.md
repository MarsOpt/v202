---
title: 'POUF: Prompt-Oriented Unsupervised Fine-tuning for Large Pre-trained Models'
openreview: 0ndiQEXIcW
abstract: Through prompting, large-scale pre-trained models have become more expressive
  and powerful, gaining significant attention in recent years. Though these big models
  have zero-shot capabilities, in general, labeled data are still required to adapt
  them to downstream tasks. To overcome this critical limitation, we propose an unsupervised
  fine-tuning framework to directly fine-tune the model or prompt on the unlabeled
  target data. We demonstrate how to apply our method to both language-augmented vision
  and masked-language models, by aligning the discrete distributions extracted from
  the prompts and target data. To verify our approachâ€™s applicability, we conduct
  extensive experiments on image classification, sentiment analysis, and natural language
  inference tasks. Across 13 image-related tasks and 15 language-related ones, the
  proposed approach achieves consistent improvements over the baselines. PyTorch code
  is available at https://github.com/korawat-tanwisuth/POUF.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tanwisuth23a
month: 0
tex_title: "{POUF}: Prompt-Oriented Unsupervised Fine-tuning for Large Pre-trained
  Models"
firstpage: 33816
lastpage: 33832
page: 33816-33832
order: 33816
cycles: false
bibtex_author: Tanwisuth, Korawat and Zhang, Shujian and Zheng, Huangjie and He, Pengcheng
  and Zhou, Mingyuan
author:
- given: Korawat
  family: Tanwisuth
- given: Shujian
  family: Zhang
- given: Huangjie
  family: Zheng
- given: Pengcheng
  family: He
- given: Mingyuan
  family: Zhou
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/tanwisuth23a/tanwisuth23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
