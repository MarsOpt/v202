---
title: GFlowNet-EM for Learning Compositional Latent Variable Models
openreview: VlEAJkmlMs
abstract: Latent variable models (LVMs) with discrete compositional latents are an
  important but challenging setting due to a combinatorially large number of possible
  configurations of the latents. A key tradeoff in modeling the posteriors over latents
  is between expressivity and tractable optimization. For algorithms based on expectation-maximization
  (EM), the E-step is often intractable without restrictive approximations to the
  posterior. We propose the use of GFlowNets, algorithms for sampling from an unnormalized
  density by learning a stochastic policy for sequential construction of samples,
  for this intractable E-step. By training GFlowNets to sample from the posterior
  over latents, we take advantage of their strengths as amortized variational inference
  algorithms for complex distributions over discrete structures. Our approach, GFlowNet-EM,
  enables the training of expressive LVMs with discrete compositional latents, as
  shown by experiments on non-context-free grammar induction and on images using discrete
  variational autoencoders (VAEs) without conditional independence enforced in the
  encoder.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu23c
month: 0
tex_title: "{GF}low{N}et-{EM} for Learning Compositional Latent Variable Models"
firstpage: 13528
lastpage: 13549
page: 13528-13549
order: 13528
cycles: false
bibtex_author: Hu, Edward J and Malkin, Nikolay and Jain, Moksh and Everett, Katie
  E and Graikos, Alexandros and Bengio, Yoshua
author:
- given: Edward J
  family: Hu
- given: Nikolay
  family: Malkin
- given: Moksh
  family: Jain
- given: Katie E
  family: Everett
- given: Alexandros
  family: Graikos
- given: Yoshua
  family: Bengio
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/hu23c/hu23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
