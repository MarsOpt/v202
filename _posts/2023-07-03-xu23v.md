---
title: 'SLAMB: Accelerated Large Batch Training with Sparse Communication'
openreview: cMmjBH5LqW
abstract: Distributed training of large deep neural networks requires frequent exchange
  of massive data between machines, thus communication efficiency is a major concern.
  Existing compressed communication methods are either not compatible with large batch
  optimization algorithms, or do not provide sufficient speedup in large scale. In
  this paper, we combine sparsification-based gradient compression with the layer-wise
  adaptive moments optimizer for large batch training (LAMB). We propose SLAMB, a
  novel communication-efficient optimizer that supports large batch sizes and scales
  to thousands of GPUs. SLAMB employs momentum masking, local error compensation,
  and element-wise adaptive rescaling to achieve accurate layer-wise weight updates,
  which translates to fast convergence for very large batches. Our empirical results
  show that, compared to the state-of-the-art, SLAMB transmits half the amount of
  data in large-batch BERT pre-training, without sacrificing accuracy. Moreover, SLAMB
  achieves excellent scalability in large computing infrastructures. For instance,
  SLAMB with 128 GPUs reduces the training time of Swin Transformer pre-training on
  ImageNet to 5.35 hours, which is 2 hours faster than the state-of-the-art. At the
  extreme, we trained BERT-XL (2.8B parameters) on 1,024 NVIDIA A100 GPUs, where SLAMB
  achieved 90% scaling efficiency.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu23v
month: 0
tex_title: "{SLAMB}: Accelerated Large Batch Training with Sparse Communication"
firstpage: 38801
lastpage: 38825
page: 38801-38825
order: 38801
cycles: false
bibtex_author: Xu, Hang and Zhang, Wenxuan and Fei, Jiawei and Wu, Yuzhe and Xie,
  Tingwen and Huang, Jun and Xie, Yuchen and Elhoseiny, Mohamed and Kalnis, Panos
author:
- given: Hang
  family: Xu
- given: Wenxuan
  family: Zhang
- given: Jiawei
  family: Fei
- given: Yuzhe
  family: Wu
- given: Tingwen
  family: Xie
- given: Jun
  family: Huang
- given: Yuchen
  family: Xie
- given: Mohamed
  family: Elhoseiny
- given: Panos
  family: Kalnis
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xu23v/xu23v.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
