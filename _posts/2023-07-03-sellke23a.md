---
title: Incentivizing Exploration with Linear Contexts and Combinatorial Actions
openreview: DpXAjLEG9G
abstract: We advance the study of incentivized bandit exploration, in which arm choices
  are viewed as recommendations and are required to be Bayesian incentive compatible.
  Recent work of Sellke-Slivkins (Operations Research 2022) has shown that for the
  special case of independent arms, after collecting enough initial samples, the popular
  Thompson sampling algorithm becomes incentive compatible. This was generalized to
  the combinatorial semibandit in Hu-Ngo-Slivkins-Wu (NeurIPS 2022). We give an analog
  of this result for linear bandits, where the independence of the prior is replaced
  by a natural convexity condition. This opens up the possibility of efficient and
  regret-optimal incentivized exploration in high-dimensional action spaces. In the
  semibandit model, we also improve the sample complexity for the pre-Thompson sampling
  phase of initial data collection.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sellke23a
month: 0
tex_title: Incentivizing Exploration with Linear Contexts and Combinatorial Actions
firstpage: 30570
lastpage: 30583
page: 30570-30583
order: 30570
cycles: false
bibtex_author: Sellke, Mark
author:
- given: Mark
  family: Sellke
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/sellke23a/sellke23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
