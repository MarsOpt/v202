---
title: Does a Neural Network Really Encode Symbolic Concepts?
openreview: 4vhIK9HNxY
abstract: Recently, a series of studies have tried to extract interactions between
  input variables modeled by a DNN and define such interactions as concepts encoded
  by the DNN. However, strictly speaking, there still lacks a solid guarantee whether
  such interactions indeed represent meaningful concepts. Therefore, in this paper,
  we examine the trustworthiness of interaction concepts from four perspectives. Extensive
  empirical studies have verified that a well-trained DNN usually encodes sparse,
  transferable, and discriminative concepts, which is partially aligned with human
  intuition. The code is released at https://github.com/sjtu-xai-lab/interaction-concept.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23at
month: 0
tex_title: Does a Neural Network Really Encode Symbolic Concepts?
firstpage: 20452
lastpage: 20469
page: 20452-20469
order: 20452
cycles: false
bibtex_author: Li, Mingjie and Zhang, Quanshi
author:
- given: Mingjie
  family: Li
- given: Quanshi
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23at/li23at.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
