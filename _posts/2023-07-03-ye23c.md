---
title: Compositional Exemplars for In-context Learning
openreview: AXer5BvRn1
abstract: Large pretrained language models (LMs) have shown impressive In-Context
  Learning (ICL) ability, where the model learns to do an unseen task simply by conditioning
  on a prompt consisting of input-output examples as demonstration, without any parameter
  updates. The performance of ICL is highly dominated by the quality of the selected
  in-context examples. However, previous selection methods are mostly based on simple
  heuristics, leading to sub-optimal performance. In this work, we systematically
  formulate in-context example selection as a subset selection problem, and optimize
  it in an end-to-end fashion. We propose CEIL (Compositional Exemplars for In-context
  Learning), which is instantiated by Determinantal Point Processes (DPPs) to model
  the interaction between the given input and in-context examples, and optimized through
  carefully-designed contrastive learning to obtain preference from LMs. We validate
  CEIL on 12 classification and generation datasets from 7 distinct NLP tasks, including
  sentiment analysis, phraphrase detection, natural language inference, commonsense
  reasoning, open-domain question answering, code generation and semantic parsing.
  Extensive experiments demonstrate the effectiveness, transferability, compositionality
  of CEIL, shedding new lights on in-context leaning. Our code is released at https://github.com/HKUNLP/icl-ceil.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ye23c
month: 0
tex_title: Compositional Exemplars for In-context Learning
firstpage: 39818
lastpage: 39833
page: 39818-39833
order: 39818
cycles: false
bibtex_author: Ye, Jiacheng and Wu, Zhiyong and Feng, Jiangtao and Yu, Tao and Kong,
  Lingpeng
author:
- given: Jiacheng
  family: Ye
- given: Zhiyong
  family: Wu
- given: Jiangtao
  family: Feng
- given: Tao
  family: Yu
- given: Lingpeng
  family: Kong
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/ye23c/ye23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
