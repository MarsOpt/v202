---
title: How to address monotonicity for model risk management?
openreview: fB9YIfI6WQ
abstract: 'In this paper, we study the problem of establishing the accountability
  and fairness of transparent machine learning models through monotonicity. Although
  there have been numerous studies on individual monotonicity, pairwise monotonicity
  is often overlooked in the existing literature. This paper studies transparent neural
  networks in the presence of three types of monotonicity: individual monotonicity,
  weak pairwise monotonicity, and strong pairwise monotonicity. As a means of achieving
  monotonicity while maintaining transparency, we propose the monotonic groves of
  neural additive models. As a result of empirical examples, we demonstrate that monotonicity
  is often violated in practice and that monotonic groves of neural additive models
  are transparent, accountable, and fair.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23al
month: 0
tex_title: How to address monotonicity for model risk management?
firstpage: 5282
lastpage: 5295
page: 5282-5295
order: 5282
cycles: false
bibtex_author: Chen, Dangxing and Ye, Weicheng
author:
- given: Dangxing
  family: Chen
- given: Weicheng
  family: Ye
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chen23al/chen23al.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
