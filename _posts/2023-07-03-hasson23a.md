---
title: Theoretical Guarantees of Learning Ensembling Strategies with Applications
  to Time Series Forecasting
openreview: YbYMRZbO1Y
abstract: Ensembling is among the most popular tools in machine learning (ML) due
  to its effectiveness in minimizing variance and thus improving generalization. Most
  ensembling methods for black-box base learners fall under the umbrella of "stacked
  generalization," namely training an ML algorithm that takes the inferences from
  the base learners as input. While stacking has been widely applied in practice,
  its theoretical properties are poorly understood. In this paper, we prove a novel
  result, showing that choosing the best stacked generalization from a (finite or
  finite-dimensional) family of stacked generalizations based on cross-validated performance
  does not perform "much worse" than the oracle best. Our result strengthens and significantly
  extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis,
  we further propose a particular family of stacked generalizations in the context
  of probabilistic forecasting, each one with a different sensitivity for how much
  the ensemble weights are allowed to vary across items, timestamps in the forecast
  horizon, and quantiles. Experimental results demonstrate the performance gain of
  the proposed method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hasson23a
month: 0
tex_title: Theoretical Guarantees of Learning Ensembling Strategies with Applications
  to Time Series Forecasting
firstpage: 12616
lastpage: 12632
page: 12616-12632
order: 12616
cycles: false
bibtex_author: Hasson, Hilaf and Maddix, Danielle C. and Wang, Bernie and Gupta, Gaurav
  and Park, Youngsuk
author:
- given: Hilaf
  family: Hasson
- given: Danielle C.
  family: Maddix
- given: Bernie
  family: Wang
- given: Gaurav
  family: Gupta
- given: Youngsuk
  family: Park
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/hasson23a/hasson23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
