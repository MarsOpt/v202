---
title: A Robust Optimisation Perspective on Counterexample-Guided Repair of Neural
  Networks
openreview: z3hnQh5UJd
abstract: Counterexample-guided repair aims at creating neural networks with mathematical
  safety guarantees, facilitating the application of neural networks in safety-critical
  domains. However, whether counterexample-guided repair is guaranteed to terminate
  remains an open question. We approach this question by showing that counterexample-guided
  repair can be viewed as a robust optimisation algorithm. While termination guarantees
  for neural network repair itself remain beyond our reach, we prove termination for
  more restrained machine learning models and disprove termination in a general setting.
  We empirically study the practical implications of our theoretical results, demonstrating
  the suitability of common verifiers and falsifiers for repair despite a disadvantageous
  theoretical result. Additionally, we use our theoretical insights to devise a novel
  algorithm for repairing linear regression models based on quadratic programming,
  surpassing existing approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: boetius23a
month: 0
tex_title: A Robust Optimisation Perspective on Counterexample-Guided Repair of Neural
  Networks
firstpage: 2712
lastpage: 2737
page: 2712-2737
order: 2712
cycles: false
bibtex_author: Boetius, David and Leue, Stefan and Sutter, Tobias
author:
- given: David
  family: Boetius
- given: Stefan
  family: Leue
- given: Tobias
  family: Sutter
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/boetius23a/boetius23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
