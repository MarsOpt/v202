---
title: Computational Asymmetries in Robust Classification
openreview: qO8YziH2hO
abstract: 'In the context of adversarial robustness, we make three strongly related
  contributions. First, we prove that while attacking ReLU classifiers is $\mathit{NP}$-hard,
  ensuring their robustness at training time is $\Sigma^2_P$-hard (even on a single
  example). This asymmetry provides a rationale for the fact that robust classifications
  approaches are frequently fooled in the literature. Second, we show that inference-time
  robustness certificates are not affected by this asymmetry, by introducing a proof-of-concept
  approach named Counter-Attack (CA). Indeed, CA displays a reversed asymmetry: running
  the defense is $\mathit{NP}$-hard, while attacking it is $\Sigma_2^P$-hard. Finally,
  motivated by our previous result, we argue that adversarial attacks can be used
  in the context of robustness certification, and provide an empirical evaluation
  of their effectiveness. As a byproduct of this process, we also release UG100, a
  benchmark dataset for adversarial attacks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: marro23a
month: 0
tex_title: Computational Asymmetries in Robust Classification
firstpage: 24082
lastpage: 24138
page: 24082-24138
order: 24082
cycles: false
bibtex_author: Marro, Samuele and Lombardi, Michele
author:
- given: Samuele
  family: Marro
- given: Michele
  family: Lombardi
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/marro23a/marro23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
