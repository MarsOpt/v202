---
title: 'Bandits with Knapsacks: Advice on Time-Varying Demands'
openreview: KlYxn7bVZW
abstract: We consider a non-stationary Bandits with Knapsack problem. The outcome
  distribution at each time is scaled by a non-stationary quantity that signifies
  changing demand volumes. Instead of studying settings with limited non-stationarity,
  we investigate how online predictions on the total demand volume $Q$ allows us to
  improve our performance guarantees. We show that, without any prediction, any online
  algorithm incurs a linear-in-$T$ regret. In contrast, with online predictions on
  $Q$, we propose an online algorithm that judiciously incorporates the predictions,
  and achieve regret bounds that depends on the accuracy of the predictions. These
  bounds are shown to be tight in settings when prediction accuracy improves across
  time. Our theoretical results are corroborated by our numerical findings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lyu23a
month: 0
tex_title: 'Bandits with Knapsacks: Advice on Time-Varying Demands'
firstpage: 23212
lastpage: 23238
page: 23212-23238
order: 23212
cycles: false
bibtex_author: Lyu, Lixing and Cheung, Wang Chi
author:
- given: Lixing
  family: Lyu
- given: Wang Chi
  family: Cheung
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/lyu23a/lyu23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
