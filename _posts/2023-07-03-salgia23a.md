---
title: Provably and Practically Efficient Neural Contextual Bandits
openreview: MOCvBgWzug
abstract: We consider the neural contextual bandit problem. In contrast to the existing
  work which primarily focuses on ReLU neural nets, we consider a general set of smooth
  activation functions. Under this more general setting, (i) we derive non-asymptotic
  error bounds on the difference between an overparameterized neural net and its corresponding
  neural tangent kernel, (ii) we propose an algorithm with a provable sublinear regret
  bound that is also efficient in the finite regime as demonstrated by empirical studies.
  The non-asymptotic error bounds may be of broader interests as a tool to establish
  the relation between the smoothness of the activation functions in neural contextual
  bandits and the smoothness of the kernels in kernel bandits.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: salgia23a
month: 0
tex_title: Provably and Practically Efficient Neural Contextual Bandits
firstpage: 29800
lastpage: 29844
page: 29800-29844
order: 29800
cycles: false
bibtex_author: Salgia, Sudeep
author:
- given: Sudeep
  family: Salgia
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/salgia23a/salgia23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
