---
title: Bandit Multi-linear DR-Submodular Maximization and Its Applications on Adversarial
  Submodular Bandits
openreview: Vqj48SbjJt
abstract: We investigate the online bandit learning of the monotone multi-linear DR-submodular
  functions, designing the algorithm $\mathtt{BanditMLSM}$ that attains $O(T^{2/3}\log
  T)$ of $(1-1/e)$-regret. Then we reduce submodular bandit with partition matroid
  constraint and bandit sequential monotone maximization to the online bandit learning
  of the monotone multi-linear DR-submodular functions, attaining $O(T^{2/3}\log T)$
  of $(1-1/e)$-regret in both problems, which improve the existing results. To the
  best of our knowledge, we are the first to give a sublinear regret algorithm for
  the submodular bandit with partition matroid constraint. A special case of this
  problem is studied by Streeter et al.(2009). They prove a $O(T^{4/5})$ $(1-1/e)$-regret
  upper bound. For the bandit sequential submodular maximization, the existing work
  proves an $O(T^{2/3})$ regret with a suboptimal $1/2$ approximation ratio (Niazadeh
  et al. 2021).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wan23e
month: 0
tex_title: Bandit Multi-linear {DR}-Submodular Maximization and Its Applications on
  Adversarial Submodular Bandits
firstpage: 35491
lastpage: 35524
page: 35491-35524
order: 35491
cycles: false
bibtex_author: Wan, Zongqi and Zhang, Jialin and Chen, Wei and Sun, Xiaoming and Zhang,
  Zhijie
author:
- given: Zongqi
  family: Wan
- given: Jialin
  family: Zhang
- given: Wei
  family: Chen
- given: Xiaoming
  family: Sun
- given: Zhijie
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wan23e/wan23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
