---
title: Anti-Exploration by Random Network Distillation
openreview: NRQ5lC8Dit
abstract: Despite the success of Random Network Distillation (RND) in various domains,
  it was shown as not discriminative enough to be used as an uncertainty estimator
  for penalizing out-of-distribution actions in offline reinforcement learning. In
  this paper, we revisit these results and show that, with a naive choice of conditioning
  for the RND prior, it becomes infeasible for the actor to effectively minimize the
  anti-exploration bonus and discriminativity is not an issue. We show that this limitation
  can be avoided with conditioning based on Feature-wise Linear Modulation (FiLM),
  resulting in a simple and efficient ensemble-free algorithm based on Soft Actor-Critic.
  We evaluate it on the D4RL benchmark, showing that it is capable of achieving performance
  comparable to ensemble-based methods and outperforming ensemble-free approaches
  by a wide margin.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nikulin23a
month: 0
tex_title: Anti-Exploration by Random Network Distillation
firstpage: 26228
lastpage: 26244
page: 26228-26244
order: 26228
cycles: false
bibtex_author: Nikulin, Alexander and Kurenkov, Vladislav and Tarasov, Denis and Kolesnikov,
  Sergey
author:
- given: Alexander
  family: Nikulin
- given: Vladislav
  family: Kurenkov
- given: Denis
  family: Tarasov
- given: Sergey
  family: Kolesnikov
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/nikulin23a/nikulin23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
