---
title: 'Data Feedback Loops: Model-driven Amplification of Dataset Biases'
openreview: 8JXMDw2xGa
abstract: Datasets scraped from the internet have been critical to large-scale machine
  learning. Yet, its success puts the utility of future internet-derived datasets
  at potential risk, as model outputs begin to replace human annotations as a source
  of supervision. In this work, we formalize a system where interactions with one
  model are recorded as history and scraped as training data in the future. We then
  analyze its stability over time by tracking changes to a test-time bias statistic
  (e.g. gender bias of model predictions). We find that the degree of bias amplification
  is closely linked to whether the model’s outputs behave like samples from the training
  distribution, a behavior which we characterize and define as uniform faithfulness.
  Experiments in three conditional prediction scenarios – image classification, visual
  role-labeling, and language generation – demonstrate that models that exhibit a
  sampling-like behavior are more faithful and thus more stable. Based on this insight,
  we propose an intervention to help mitigate and stabilize unstable feedback systems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: taori23a
month: 0
tex_title: 'Data Feedback Loops: Model-driven Amplification of Dataset Biases'
firstpage: 33883
lastpage: 33920
page: 33883-33920
order: 33883
cycles: false
bibtex_author: Taori, Rohan and Hashimoto, Tatsunori
author:
- given: Rohan
  family: Taori
- given: Tatsunori
  family: Hashimoto
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/taori23a/taori23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
