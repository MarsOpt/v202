---
title: Differential Privacy has Bounded Impact on Fairness in Classification
openreview: VyflUVKn83
abstract: We theoretically study the impact of differential privacy on fairness in
  classification. We prove that, given a class of models, popular group fairness measures
  are pointwise Lipschitz-continuous with respect to the parameters of the model.
  This result is a consequence of a more general statement on accuracy conditioned
  on an arbitrary event (such as membership to a sensitive group), which may be of
  independent interest. We use this Lipschitz property to prove a non-asymptotic bound
  showing that, as the number of samples increases, the fairness level of private
  models gets closer to the one of their non-private counterparts. This bound also
  highlights the importance of the confidence margin of a model on the disparate impact
  of differential privacy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mangold23a
month: 0
tex_title: Differential Privacy has Bounded Impact on Fairness in Classification
firstpage: 23681
lastpage: 23705
page: 23681-23705
order: 23681
cycles: false
bibtex_author: Mangold, Paul and Perrot, Micha\"{e}l and Bellet, Aur\'{e}lien and
  Tommasi, Marc
author:
- given: Paul
  family: Mangold
- given: Michaël
  family: Perrot
- given: Aurélien
  family: Bellet
- given: Marc
  family: Tommasi
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/mangold23a/mangold23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
