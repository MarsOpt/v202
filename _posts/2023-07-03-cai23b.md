---
title: On the Connection Between MPNN and Graph Transformer
openreview: 1EuHYKFPgA
abstract: Graph Transformer (GT) recently has emerged as a new paradigm of graph learning
  algorithms, outperforming the previously popular Message Passing Neural Network
  (MPNN) on multiple benchmarks. Previous work shows that with proper position embedding,
  GT can approximate MPNN arbitrarily well, implying that GT is at least as powerful
  as MPNN. In this paper, we study the inverse connection and show that MPNN with
  virtual node (VN), a commonly used heuristic with little theoretical understanding,
  is powerful enough to arbitrarily approximate the self-attention layer of GT. In
  particular, we first show that if we consider one type of linear transformer, the
  so-called Performer/Linear Transformer, then MPNN + VN with only $\mathcal{O}(1)$
  depth and $\mathcal{O}(1)$ width can approximate a self-attention layer in Performer/Linear
  Transformer. Next, via a connection between MPNN + VN and DeepSets, we prove the
  MPNN + VN with $\mathcal{O}(n^d)$ width and $\mathcal{O}(1)$ depth can approximate
  the self-attention layer arbitrarily well, where $d$ is the input feature dimension.
  Lastly, under some assumptions, we provide an explicit construction of MPNN + VN
  with $\mathcal{O}(1)$ width and $\mathcal{O}(n)$ depth approximating the self-attention
  layer in GT arbitrarily well. On the empirical side, we demonstrate that 1) MPNN
  + VN is a surprisingly strong baseline, outperforming GT on the recently proposed
  Long Range Graph Benchmark (LRGB) dataset, 2) our MPNN + VN improves over early
  implementation on a wide range of OGB datasets and 3) MPNN + VN outperforms Linear
  Transformer and MPNN on the climate modeling task.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cai23b
month: 0
tex_title: On the Connection Between {MPNN} and Graph Transformer
firstpage: 3408
lastpage: 3430
page: 3408-3430
order: 3408
cycles: false
bibtex_author: Cai, Chen and Hy, Truong Son and Yu, Rose and Wang, Yusu
author:
- given: Chen
  family: Cai
- given: Truong Son
  family: Hy
- given: Rose
  family: Yu
- given: Yusu
  family: Wang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/cai23b/cai23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
