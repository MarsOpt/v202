---
title: 'BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders
  and Large Language Models'
openreview: KU9UojoX7U
abstract: The cost of vision-and-language pre-training has become increasingly prohibitive
  due to end-to-end training of large-scale models. This paper proposes BLIP-2, a
  generic and efficient pre-training strategy that bootstraps vision-language pre-training
  from off-the-shelf frozen pre-trained image encoders and frozen large language models.
  BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is
  pre-trained in two stages. The first stage bootstraps vision-language representation
  learning from a frozen image encoder. The second stage bootstraps vision-to-language
  generative learning from a frozen language model. BLIP-2 achieves state-of-the-art
  performance on various vision-language tasks, despite having significantly fewer
  trainable parameters than existing methods. For example, our model outperforms Flamingo80B
  by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate
  the modelâ€™s emerging capabilities of zero-shot image-to-text generation that can
  follow natural language instructions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23q
month: 0
tex_title: "{BLIP}-2: Bootstrapping Language-Image Pre-training with Frozen Image
  Encoders and Large Language Models"
firstpage: 19730
lastpage: 19742
page: 19730-19742
order: 19730
cycles: false
bibtex_author: Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven
author:
- given: Junnan
  family: Li
- given: Dongxu
  family: Li
- given: Silvio
  family: Savarese
- given: Steven
  family: Hoi
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23q/li23q.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
