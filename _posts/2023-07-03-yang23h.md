---
title: Improving Adversarial Robustness by Putting More Regularizations on Less Robust
  Samples
openreview: uSF5isjdSQ
abstract: Adversarial training, which is to enhance robustness against adversarial
  attacks, has received much attention because it is easy to generate human-imperceptible
  perturbations of data to deceive a given deep neural network. In this paper, we
  propose a new adversarial training algorithm that is theoretically well motivated
  and empirically superior to other existing algorithms. A novel feature of the proposed
  algorithm is to apply more regularization to data vulnerable to adversarial attacks
  than other existing regularization algorithms do. Theoretically, we show that our
  algorithm can be understood as an algorithm of minimizing a newly derived upper
  bound of the robust risk. Numerical experiments illustrate that our proposed algorithm
  improves the generalization (accuracy on examples) and robustness (accuracy on adversarial
  attacks) simultaneously to achieve the state-of-the-art performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23h
month: 0
tex_title: Improving Adversarial Robustness by Putting More Regularizations on Less
  Robust Samples
firstpage: 39331
lastpage: 39348
page: 39331-39348
order: 39331
cycles: false
bibtex_author: Yang, Dongyoon and Kong, Insung and Kim, Yongdai
author:
- given: Dongyoon
  family: Yang
- given: Insung
  family: Kong
- given: Yongdai
  family: Kim
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yang23h/yang23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
