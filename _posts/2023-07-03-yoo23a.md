---
title: Improving Visual Prompt Tuning for Self-supervised Vision Transformers
openreview: 1ZqavMwxxx
abstract: Visual Prompt Tuning (VPT) is an effective tuning method for adapting pretrained
  Vision Transformers (ViTs) to downstream tasks. It leverages extra learnable tokens,
  known as prompts, which steer the frozen pretrained ViTs. Although VPT has demonstrated
  its applicability with supervised vision transformers, it often underperforms with
  self-supervised ones. Through empirical observations, we deduce that the effectiveness
  of VPT hinges largely on the ViT blocks with which the prompt tokens interact. Specifically,
  VPT shows improved performance on image classification tasks for MAE and MoCo v3
  when the prompt tokens are inserted into later blocks rather than the first block.
  These observations suggest that there exists an optimal location of blocks for the
  insertion of prompt tokens. Unfortunately, identifying the optimal blocks for prompts
  within each self-supervised ViT for diverse future scenarios is a costly process.
  To mitigate this problem, we propose a simple yet effective method that learns a
  gate for each ViT block to adjust its intervention into the prompt tokens. With
  our method, prompt tokens are selectively influenced by blocks that require steering
  for task adaptation. Our method outperforms VPT variants in FGVC and VTAB image
  classification and ADE20K semantic segmentation. The code is available at https://github.com/ryongithub/GatedPromptTuning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yoo23a
month: 0
tex_title: Improving Visual Prompt Tuning for Self-supervised Vision Transformers
firstpage: 40075
lastpage: 40092
page: 40075-40092
order: 40075
cycles: false
bibtex_author: Yoo, Seungryong and Kim, Eunji and Jung, Dahuin and Lee, Jungbeom and
  Yoon, Sungroh
author:
- given: Seungryong
  family: Yoo
- given: Eunji
  family: Kim
- given: Dahuin
  family: Jung
- given: Jungbeom
  family: Lee
- given: Sungroh
  family: Yoon
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yoo23a/yoo23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
