---
title: Bayesian Reparameterization of Reward-Conditioned Reinforcement Learning with
  Energy-based Models
openreview: JTTFrBX8KN
abstract: Recently, reward-conditioned reinforcement learning (RCRL) has gained popularity
  due to its simplicity, flexibility, and off-policy nature. However, we will show
  that current RCRL approaches are fundamentally limited and fail to address two critical
  challenges of RCRL – improving generalization on high reward-to-go (RTG) inputs,
  and avoiding out-of-distribution (OOD) RTG queries during testing time. To address
  these challenges when training vanilla RCRL architectures, we propose Bayesian Reparameterized
  RCRL (BR-RCRL), a novel set of inductive biases for RCRL inspired by Bayes’ theorem.
  BR-RCRL removes a core obstacle preventing vanilla RCRL from generalizing on high
  RTG inputs – a tendency that the model treats different RTG inputs as independent
  values, which we term “RTG Independence". BR-RCRL also allows us to design an accompanying
  adaptive inference method, which maximizes total returns while avoiding OOD queries
  that yield unpredictable behaviors in vanilla RCRL methods. We show that BR-RCRL
  achieves state-of-the-art performance on the Gym-Mujoco and Atari offline RL benchmarks,
  improving upon vanilla RCRL by up to 11%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding23a
month: 0
tex_title: "{B}ayesian Reparameterization of Reward-Conditioned Reinforcement Learning
  with Energy-based Models"
firstpage: 8053
lastpage: 8066
page: 8053-8066
order: 8053
cycles: false
bibtex_author: Ding, Wenhao and Che, Tong and Zhao, Ding and Pavone, Marco
author:
- given: Wenhao
  family: Ding
- given: Tong
  family: Che
- given: Ding
  family: Zhao
- given: Marco
  family: Pavone
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/ding23a/ding23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
