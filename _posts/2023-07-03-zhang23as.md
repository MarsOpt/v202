---
title: 'ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval'
openreview: SP01yVIC2o
abstract: Diffusion models show promising generation capability for a variety of data.
  Despite their high generation quality, the inference for diffusion models is still
  time-consuming due to the numerous sampling iterations required. To accelerate the
  inference, we propose ReDi, a simple yet learning-free Retrieval-based Diffusion
  sampling framework. From a precomputed knowledge base, ReDi retrieves a trajectory
  similar to the partially generated trajectory at an early stage of generation, skips
  a large portion of intermediate steps, and continues sampling from a later step
  in the retrieved trajectory. We theoretically prove that the generation performance
  of ReDi is guaranteed. Our experiments demonstrate that ReDi improves the model
  inference efficiency by 2$\times$ speedup. Furthermore, ReDi is able to generalize
  well in zero-shot cross-domain image generation such as image stylization. The code
  and demo for ReDi is available at https://github.com/zkx06111/ReDiffusion.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23as
month: 0
tex_title: "{R}e{D}i: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval"
firstpage: 41770
lastpage: 41785
page: 41770-41785
order: 41770
cycles: false
bibtex_author: Zhang, Kexun and Yang, Xianjun and Wang, William Yang and Li, Lei
author:
- given: Kexun
  family: Zhang
- given: Xianjun
  family: Yang
- given: William Yang
  family: Wang
- given: Lei
  family: Li
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhang23as/zhang23as.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
