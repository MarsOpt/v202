---
title: 'UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers'
openreview: dovQpb7Qda
abstract: Real-world data contains a vast amount of multimodal information, among
  which vision and language are the two most representative modalities. Moreover,
  increasingly heavier models, e.g., Transformers, have attracted the attention of
  researchers to model compression. However, how to compress multimodal models, especially
  vison-language Transformers, is still under-explored. This paper proposes the Unified
  and Progressive Pruning (UPop) as a universal vison-language Transformer compression
  framework, which incorporates 1) unifiedly searching multimodal subnets in a continuous
  optimization space from the original model, which enables automatic assignment of
  pruning ratios among compressible modalities and structures; 2) progressively searching
  and retraining the subnet, which maintains convergence between the search and retrain
  to attain higher compression ratios. Experiments on various tasks, datasets, and
  model architectures demonstrate the effectiveness and versatility of the proposed
  UPop framework. The code is available at https://github.com/sdc17/UPop.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shi23e
month: 0
tex_title: "{UP}op: Unified and Progressive Pruning for Compressing Vision-Language
  Transformers"
firstpage: 31292
lastpage: 31311
page: 31292-31311
order: 31292
cycles: false
bibtex_author: Shi, Dachuan and Tao, Chaofan and Jin, Ying and Yang, Zhendong and
  Yuan, Chun and Wang, Jiaqi
author:
- given: Dachuan
  family: Shi
- given: Chaofan
  family: Tao
- given: Ying
  family: Jin
- given: Zhendong
  family: Yang
- given: Chun
  family: Yuan
- given: Jiaqi
  family: Wang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/shi23e/shi23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
