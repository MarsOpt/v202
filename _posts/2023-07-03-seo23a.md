---
title: Multi-View Masked World Models for Visual Robotic Manipulation
openreview: DwOUndjwiV
abstract: 'Visual robotic manipulation research and applications often use multiple
  cameras, or views, to better perceive the world. How else can we utilize the richness
  of multi-view data? In this paper, we investigate how to learn good representations
  with multi-view data and utilize them for visual robotic manipulation. Specifically,
  we train a multi-view masked autoencoder which reconstructs pixels of randomly masked
  viewpoints and then learn a world model operating on the representations from the
  autoencoder. We demonstrate the effectiveness of our method in a range of scenarios,
  including multi-view control and single-view control with auxiliary cameras for
  representation learning. We also show that the multi-view masked autoencoder trained
  with multiple randomized viewpoints enables training a policy with strong viewpoint
  randomization and transferring the policy to solve real-robot tasks without camera
  calibration and an adaptation procedure. Video demonstrations are available at:
  https://sites.google.com/view/mv-mwm.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: seo23a
month: 0
tex_title: Multi-View Masked World Models for Visual Robotic Manipulation
firstpage: 30613
lastpage: 30632
page: 30613-30632
order: 30613
cycles: false
bibtex_author: Seo, Younggyo and Kim, Junsu and James, Stephen and Lee, Kimin and
  Shin, Jinwoo and Abbeel, Pieter
author:
- given: Younggyo
  family: Seo
- given: Junsu
  family: Kim
- given: Stephen
  family: James
- given: Kimin
  family: Lee
- given: Jinwoo
  family: Shin
- given: Pieter
  family: Abbeel
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/seo23a/seo23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
