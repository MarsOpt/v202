---
title: Multiplier Bootstrap-based Exploration
openreview: M6n9VdvThQ
abstract: Despite the great interest in the bandit problem, designing efficient algorithms
  for complex models remains challenging, as there is typically no analytical way
  to quantify uncertainty. In this paper, we propose Multiplier Bootstrap-based Exploration
  (MBE), a novel exploration strategy that is applicable to any reward model amenable
  to weighted loss minimization. We prove both instance-dependent and instance-independent
  rate-optimal regret bounds for MBE in sub-Gaussian multi-armed bandits. With extensive
  simulation and real-data experiments, we show the generality and adaptivity of MBE.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wan23d
month: 0
tex_title: Multiplier Bootstrap-based Exploration
firstpage: 35444
lastpage: 35490
page: 35444-35490
order: 35444
cycles: false
bibtex_author: Wan, Runzhe and Wei, Haoyu and Kveton, Branislav and Song, Rui
author:
- given: Runzhe
  family: Wan
- given: Haoyu
  family: Wei
- given: Branislav
  family: Kveton
- given: Rui
  family: Song
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wan23d/wan23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
