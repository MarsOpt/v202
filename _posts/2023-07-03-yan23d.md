---
title: Self-Interpretable Time Series Prediction with Counterfactual Explanations
openreview: JPMT9kjeJi
abstract: Interpretable time series prediction is crucial for safety-critical areas
  such as healthcare and autonomous driving. Most existing methods focus on interpreting
  predictions by assigning important scores to segments of time series. In this paper,
  we take a different and more challenging route and aim at developing a self-interpretable
  model, dubbed Counterfactual Time Series (CounTS), which generates counterfactual
  and actionable explanations for time series predictions. Specifically, we formalize
  the problem of time series counterfactual explanations, establish associated evaluation
  protocols, and propose a variational Bayesian deep learning model equipped with
  counterfactual inference capability of time series abduction, action, and prediction.
  Compared with state-of-the-art baselines, our self-interpretable model can generate
  better counterfactual explanations while maintaining comparable prediction accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan23d
month: 0
tex_title: Self-Interpretable Time Series Prediction with Counterfactual Explanations
firstpage: 39110
lastpage: 39125
page: 39110-39125
order: 39110
cycles: false
bibtex_author: Yan, Jingquan and Wang, Hao
author:
- given: Jingquan
  family: Yan
- given: Hao
  family: Wang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yan23d/yan23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
