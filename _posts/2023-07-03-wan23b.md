---
title: Poisoning Language Models During Instruction Tuning
openreview: JxtE52KIBR
abstract: 'Instruction-tuned LMs such as ChatGPT, FLAN, and InstructGPT are finetuned
  on datasets that contain user-submitted examples, e.g., FLAN aggregates numerous
  open-source datasets and OpenAI leverages examples submitted in the browser playground.
  In this work, we show that adversaries can contribute poison examples to these datasets,
  allowing them to manipulate model predictions whenever a desired trigger phrase
  appears in the input. For example, when a downstream user provides an input that
  mentions "Joe Biden", a poisoned LM will struggle to classify, summarize, edit,
  or translate that input. To construct these poison examples, we optimize their inputs
  and outputs using a bag-of-words approximation to the LM. We evaluate our method
  on open-source instruction-tuned LMs. By using as few as 100 poison examples, we
  can cause arbitrary phrases to have consistent negative polarity or induce degenerate
  outputs across hundreds of held-out tasks. Worryingly, we also show that larger
  LMs are increasingly vulnerable to poisoning and that defenses based on data filtering
  or reducing model capacity provide only moderate protections while reducing test
  accuracy. Notice: This paper contains tasks with obscene content.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wan23b
month: 0
tex_title: Poisoning Language Models During Instruction Tuning
firstpage: 35413
lastpage: 35425
page: 35413-35425
order: 35413
cycles: false
bibtex_author: Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan
author:
- given: Alexander
  family: Wan
- given: Eric
  family: Wallace
- given: Sheng
  family: Shen
- given: Dan
  family: Klein
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wan23b/wan23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
