---
title: A Flexible Diffusion Model
openreview: NwICIHHpKf
abstract: Denoising diffusion (score-based) generative models have become a popular
  choice for modeling complex data. Recently, a deep connection between forward-backward
  stochastic differential equations (SDEs) and diffusion-based models has been established,
  leading to the development of new SDE variants such as sub-VP and critically-damped
  Langevin. Despite the empirical success of some hand-crafted forward SDEs, many
  potentially promising forward SDEs remain unexplored. In this work, we propose a
  general framework for parameterizing diffusion models, particularly the spatial
  part of forward SDEs, by leveraging the symplectic and Riemannian geometry of the
  data manifold. We introduce a systematic formalism with theoretical guarantees and
  connect it with previous diffusion models. Finally, we demonstrate the theoretical
  advantages of our method from a variational optimization perspective. We present
  numerical experiments on synthetic datasets, MNIST and CIFAR10 to validate the effectiveness
  of our framework.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: du23g
month: 0
tex_title: A Flexible Diffusion Model
firstpage: 8678
lastpage: 8696
page: 8678-8696
order: 8678
cycles: false
bibtex_author: Du, Weitao and Zhang, He and Yang, Tao and Du, Yuanqi
author:
- given: Weitao
  family: Du
- given: He
  family: Zhang
- given: Tao
  family: Yang
- given: Yuanqi
  family: Du
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/du23g/du23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
