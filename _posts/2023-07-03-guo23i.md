---
title: Graph Neural Networks with Learnable and Optimal Polynomial Bases
openreview: UjQIoJv927
abstract: 'Polynomial filters, a kind of Graph Neural Networks, typically use a predetermined
  polynomial basis and learn the coefficients from the training data. It has been
  observed that the effectiveness of the model is highly dependent on the property
  of the polynomial basis. Consequently, two natural and fundamental questions arise:
  Can we learn a suitable polynomial basis from the training data? Can we determine
  the optimal polynomial basis for a given graph and node features? In this paper,
  we propose two spectral GNN models that provide positive answers to the questions
  posed above. First, inspired by Favardâ€™s Theorem, we propose the FavardGNN model,
  which learns a polynomial basis from the space of all possible orthonormal bases.
  Second, we examine the supposedly unsolvable definition of optimal polynomial basis
  from Wang et al. (2022) and propose a simple model, OptBasisGNN, which computes
  the optimal basis for a given graph structure and graph signal. Extensive experiments
  are conducted to demonstrate the effectiveness of our proposed models. Our code
  is available at https://github.com/yuziGuo/FarOptBasis.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo23i
month: 0
tex_title: Graph Neural Networks with Learnable and Optimal Polynomial Bases
firstpage: 12077
lastpage: 12097
page: 12077-12097
order: 12077
cycles: false
bibtex_author: Guo, Yuhe and Wei, Zhewei
author:
- given: Yuhe
  family: Guo
- given: Zhewei
  family: Wei
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/guo23i/guo23i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
