---
title: 'Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing:
  A Lesson From Fano'
openreview: Fry8Yz5Ngl
abstract: Differential privacy (DP) is by far the most widely accepted framework for
  mitigating privacy risks in machine learning. However, exactly how small the privacy
  parameter $\epsilon$ needs to be to protect against certain privacy risks in practice
  is still not well-understood. In this work, we study data reconstruction attacks
  for discrete data and analyze it under the framework of multiple hypothesis testing.
  For a learning algorithm satisfying $(\alpha, \epsilon)$-Renyi DP, we utilize different
  variants of the celebrated Fanoâ€™s inequality to upper bound the attack advantage
  of a data reconstruction adversary. Our bound can be numerically computed to relate
  the parameter $\epsilon$ to the desired level of privacy protection in practice,
  and complements the empirical evidence for the effectiveness of DP against data
  reconstruction attacks even at relatively large values of $\epsilon$.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo23e
month: 0
tex_title: 'Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis
  Testing: A Lesson From Fano'
firstpage: 11998
lastpage: 12011
page: 11998-12011
order: 11998
cycles: false
bibtex_author: Guo, Chuan and Sablayrolles, Alexandre and Sanjabi, Maziar
author:
- given: Chuan
  family: Guo
- given: Alexandre
  family: Sablayrolles
- given: Maziar
  family: Sanjabi
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/guo23e/guo23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
