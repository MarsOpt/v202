---
title: 'FAIRER: Fairness as Decision Rationale Alignment'
openreview: 4Q2Y0kKwPU
abstract: Deep neural networks (DNNs) have made significant progress, but often suffer
  from fairness issues, as deep models typically show distinct accuracy differences
  among certain subgroups (e.g., males and females). Existing research addresses this
  critical issue by employing fairness-aware loss functions to constrain the last-layer
  outputs and directly regularize DNNs. Although the fairness of DNNs is improved,
  it is unclear how the trained network makes a fair prediction, which limits future
  fairness improvements. In this paper, we investigate fairness from the perspective
  of decision rationale and define the parameter parity score to characterize the
  fair decision process of networks by analyzing neuron influence in various subgroups.
  Extensive empirical studies show that the unfair issue could arise from the unaligned
  decision rationales of subgroups. Existing fairness regularization terms fail to
  achieve decision rationale alignment because they only constrain last-layer outputs
  while ignoring intermediate neuron alignment. To address the issue, we formulate
  the fairness as a new task, i.e., decision rationale alignment that requires DNNsâ€™
  neurons to have consistent responses on subgroups at both intermediate processes
  and the final prediction. To make this idea practical during optimization, we relax
  the naive objective function and propose gradient-guided parity alignment, which
  encourages gradient-weighted consistency of neurons across subgroups. Extensive
  experiments on a variety of datasets show that our method can significantly enhance
  fairness while sustaining a high level of accuracy and outperforming other approaches
  by a wide margin.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23h
month: 0
tex_title: "{FAIRER}: Fairness as Decision Rationale Alignment"
firstpage: 19471
lastpage: 19489
page: 19471-19489
order: 19471
cycles: false
bibtex_author: Li, Tianlin and Guo, Qing and Liu, Aishan and Du, Mengnan and Li, Zhiming
  and Liu, Yang
author:
- given: Tianlin
  family: Li
- given: Qing
  family: Guo
- given: Aishan
  family: Liu
- given: Mengnan
  family: Du
- given: Zhiming
  family: Li
- given: Yang
  family: Liu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23h/li23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
