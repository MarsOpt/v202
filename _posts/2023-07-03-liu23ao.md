---
title: 'Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language
  Models'
openreview: 9UCTB84L6e
abstract: 'Language modeling on large-scale datasets improves performance of various
  downstream tasks. The validation pre-training loss is often used as the evaluation
  metric for language models since the pre-training loss tends to be well-correlated
  with downstream performance (which is itself hard to evaluate comprehensively).
  Contrary to the conventional wisdom, this paper shows that 1) pre-training loss
  cannot fully explain downstream performance and 2) flatness of the model is well-correlated
  with downstream performance where pre-training loss is not. We identify three ways
  to produce models with the same pre-training loss but different downstream performance:
  continue pre-training after convergence, increasing the model size, and changing
  the pre-training algorithms. These experiments demonstrate the existence of implicit
  bias of pre-training algorithmsâ€”among models with the same minimal pre-training
  loss, they implicitly prefer more transferable ones. Toward understanding this implicit
  bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter
  minima of pre-training loss in language models, and empirically observe a strong
  correlation between flatness (measured by the trace of Hessian) and downstream performance
  among models with the same pre-training loss. We also prove in a synthetic language
  setting that among models with the minimal pre-training loss, the flattest model
  transfers to downstream tasks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23ao
month: 0
tex_title: 'Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language
  Models'
firstpage: 22188
lastpage: 22214
page: 22188-22214
order: 22188
cycles: false
bibtex_author: Liu, Hong and Xie, Sang Michael and Li, Zhiyuan and Ma, Tengyu
author:
- given: Hong
  family: Liu
- given: Sang Michael
  family: Xie
- given: Zhiyuan
  family: Li
- given: Tengyu
  family: Ma
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/liu23ao/liu23ao.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
