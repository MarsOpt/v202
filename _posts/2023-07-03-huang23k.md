---
title: Reparameterized Policy Learning for Multimodal Trajectory Optimization
openreview: 5Akrk9Ln6N
abstract: We investigate the challenge of parametrizing policies for reinforcement
  learning (RL) in high-dimensional continuous action spaces. Our objective is to
  develop a multimodal policy that overcomes limitations inherent in the commonly-used
  Gaussian parameterization. To achieve this, we propose a principled framework that
  models the continuous RL policy as a generative model of optimal trajectories. By
  conditioning the policy on a latent variable, we derive a novel variational bound
  as the optimization objective, which promotes exploration of the environment. We
  then present a practical model-based RL method, called Reparameterized Policy Gradient
  (RPG), which leverages the multimodal policy parameterization and learned world
  model to achieve strong exploration capabilities and high data efficiency. Empirical
  results demonstrate that our method can help agents evade local optima in tasks
  with dense rewards and solve challenging sparse-reward environments by incorporating
  an object-centric intrinsic reward. Our method consistently outperforms previous
  approaches across a range of tasks. Code and supplementary materials are available
  on the project page https://haosulab.github.io/RPG/
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang23k
month: 0
tex_title: Reparameterized Policy Learning for Multimodal Trajectory Optimization
firstpage: 13957
lastpage: 13975
page: 13957-13975
order: 13957
cycles: false
bibtex_author: Huang, Zhiao and Liang, Litian and Ling, Zhan and Li, Xuanlin and Gan,
  Chuang and Su, Hao
author:
- given: Zhiao
  family: Huang
- given: Litian
  family: Liang
- given: Zhan
  family: Ling
- given: Xuanlin
  family: Li
- given: Chuang
  family: Gan
- given: Hao
  family: Su
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/huang23k/huang23k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
