---
title: Multi-Environment Pretraining Enables Transfer to Action Limited Datasets
openreview: 5RvZb6Lcbz
abstract: Using massive datasets to train large-scale models has emerged as a dominant
  approach for broad generalization in natural language and vision applications. In
  reinforcement learning, however, a key challenge is that available data of sequential
  decision making is often not annotated with actions - for example, videos of game-play
  are much more available than sequences of frames paired with their logged game controls.
  We propose to circumvent this challenge by combining large but sparsely-annotated
  datasets from a <em>target</em> environment of interest with fully-annotated datasets
  from various other <em>source</em> environments. Our method, Action Limited PreTraining
  (ALPT), leverages the generalization capabilities of inverse dynamics modelling
  (IDM) to label missing action data in the target environment. We show that utilizing
  even one additional environment dataset of labelled data during IDM pretraining
  gives rise to substantial improvements in generating action labels for unannotated
  sequences. We evaluate our method on benchmark game-playing environments and show
  that we can significantly improve game performance and generalization capability
  compared to other approaches, using annotated datasets equivalent to only $12$ minutes
  of gameplay. Highlighting the power of IDM, we show that these benefits remain even
  when target and source environments share no common actions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: venuto23a
month: 0
tex_title: Multi-Environment Pretraining Enables Transfer to Action Limited Datasets
firstpage: 35024
lastpage: 35036
page: 35024-35036
order: 35024
cycles: false
bibtex_author: Venuto, David and Yang, Sherry and Abbeel, Pieter and Precup, Doina
  and Mordatch, Igor and Nachum, Ofir
author:
- given: David
  family: Venuto
- given: Sherry
  family: Yang
- given: Pieter
  family: Abbeel
- given: Doina
  family: Precup
- given: Igor
  family: Mordatch
- given: Ofir
  family: Nachum
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/venuto23a/venuto23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
