---
title: Bootstrapped Representations in Reinforcement Learning
openreview: QFhYahlGNZ
abstract: In reinforcement learning (RL), state representations are key to dealing
  with large or continuous state spaces. While one of the promises of deep learning
  algorithms is to automatically construct features well-tuned for the task they try
  to solve, such a representation might not emerge from end-to-end training of deep
  RL agents. To mitigate this issue, auxiliary objectives are often incorporated into
  the learning process and help shape the learnt state representation. Bootstrapping
  methods are todayâ€™s method of choice to make these additional predictions. Yet,
  it is unclear which features these algorithms capture and how they relate to those
  from other auxiliary-task-based approaches. In this paper, we address this gap and
  provide a theoretical characterization of the state representation learnt by temporal
  difference learning (Sutton, 1988). Surprisingly, we find that this representation
  differs from the features learned by Monte Carlo and residual gradient algorithms
  for most transition structures of the environment in the policy evaluation setting.
  We describe the efficacy of these representations for policy evaluation, and use
  our theoretical analysis to design new auxiliary learning rules. We complement our
  theoretical results with an empirical comparison of these learning rules for different
  cumulant functions on classic domains such as the four-room domain (Sutton et al,
  1999) and Mountain Car (Moore, 1990).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: le-lan23a
month: 0
tex_title: Bootstrapped Representations in Reinforcement Learning
firstpage: 18686
lastpage: 18713
page: 18686-18713
order: 18686
cycles: false
bibtex_author: Le Lan, Charline and Tu, Stephen and Rowland, Mark and Harutyunyan,
  Anna and Agarwal, Rishabh and Bellemare, Marc G and Dabney, Will
author:
- given: Charline
  family: Le Lan
- given: Stephen
  family: Tu
- given: Mark
  family: Rowland
- given: Anna
  family: Harutyunyan
- given: Rishabh
  family: Agarwal
- given: Marc G
  family: Bellemare
- given: Will
  family: Dabney
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/le-lan23a/le-lan23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
