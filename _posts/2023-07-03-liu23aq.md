---
title: Dropout Reduces Underfitting
openreview: CcDN1PKxjx
abstract: 'Introduced by Hinton et al. in 2012, dropout has stood the test of time
  as a regularizer for preventing overfitting in neural networks. In this study, we
  demonstrate that dropout can also mitigate underfitting when used at the start of
  training. During the early phase, we find dropout reduces the directional variance
  of gradients across mini-batches and helps align the mini-batch gradients with the
  entire datasetâ€™s gradient. This helps counteract the stochasticity of SGD and limit
  the influence of individual batches on model training. Our findings lead us to a
  solution for improving performance in underfitting models - early dropout: dropout
  is applied only during the initial phases of training, and turned off afterwards.
  Models equipped with early dropout achieve lower final training loss compared to
  their counterparts without dropout. Additionally, we explore a symmetric technique
  for regularizing overfitting models - late dropout, where dropout is not used in
  the early iterations and is only activated later in training. Experiments on ImageNet
  and various vision tasks demonstrate that our methods consistently improve generalization
  accuracy. Our results encourage more research on understanding regularization in
  deep learning and our methods can be useful tools for future neural network training,
  especially in the era of large data. Code is available at https://github.com/facebookresearch/dropout.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23aq
month: 0
tex_title: Dropout Reduces Underfitting
firstpage: 22233
lastpage: 22248
page: 22233-22248
order: 22233
cycles: false
bibtex_author: Liu, Zhuang and Xu, Zhiqiu and Jin, Joseph and Shen, Zhiqiang and Darrell,
  Trevor
author:
- given: Zhuang
  family: Liu
- given: Zhiqiu
  family: Xu
- given: Joseph
  family: Jin
- given: Zhiqiang
  family: Shen
- given: Trevor
  family: Darrell
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/liu23aq/liu23aq.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
