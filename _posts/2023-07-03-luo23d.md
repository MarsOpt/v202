---
title: Iterative Approximate Cross-Validation
openreview: BZDqjqbJmg
abstract: Cross-validation (CV) is one of the most popular tools for assessing and
  selecting predictive models. However, standard CV suffers from high computational
  cost when the number of folds is large. Recently, under the empirical risk minimization
  (ERM) framework, a line of works proposed efficient methods to approximate CV based
  on the solution of the ERM problem trained on the full dataset. However, in large-scale
  problems, it can be hard to obtain the exact solution of the ERM problem, either
  due to limited computational resources or due to early stopping as a way of preventing
  overfitting. In this paper, we propose a new paradigm to efficiently approximate
  CV when the ERM problem is solved via an iterative first-order algorithm, without
  running until convergence. Our new method extends existing guarantees for CV approximation
  to hold along the whole trajectory of the algorithm, including at convergence, thus
  generalizing existing CV approximation methods. Finally, we illustrate the accuracy
  and computational efficiency of our method through a range of empirical studies.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: luo23d
month: 0
tex_title: Iterative Approximate Cross-Validation
firstpage: 23083
lastpage: 23102
page: 23083-23102
order: 23083
cycles: false
bibtex_author: Luo, Yuetian and Ren, Zhimei and Barber, Rina
author:
- given: Yuetian
  family: Luo
- given: Zhimei
  family: Ren
- given: Rina
  family: Barber
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/luo23d/luo23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
