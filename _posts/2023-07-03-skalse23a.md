---
title: Invariance in Policy Optimisation and Partial Identifiability in Reward Learning
openreview: nqvBUsnC5L
abstract: It is often very challenging to manually design reward functions for complex,
  real-world tasks. To solve this, one can instead use reward learning to infer a
  reward function from data. However, there are often multiple reward functions that
  fit the data equally well, even in the infinite-data limit. This means that the
  reward function is only partially identifiable. In this work, we formally characterise
  the partial identifiability of the reward function given several popular reward
  learning data sources, including expert demonstrations and trajectory comparisons.
  We also analyse the impact of this partial identifiability for several downstream
  tasks, such as policy optimisation. We unify our results in a framework for comparing
  data sources and downstream tasks by their invariances, with implications for the
  design and selection of data sources for reward learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: skalse23a
month: 0
tex_title: Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning
firstpage: 32033
lastpage: 32058
page: 32033-32058
order: 32033
cycles: false
bibtex_author: Skalse, Joar Max Viktor and Farrugia-Roberts, Matthew and Russell,
  Stuart and Abate, Alessandro and Gleave, Adam
author:
- given: Joar Max Viktor
  family: Skalse
- given: Matthew
  family: Farrugia-Roberts
- given: Stuart
  family: Russell
- given: Alessandro
  family: Abate
- given: Adam
  family: Gleave
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/skalse23a/skalse23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
