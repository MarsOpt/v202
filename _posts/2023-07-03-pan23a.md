---
title: Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and
  Ethical Behavior in the Machiavelli Benchmark
openreview: nkals4A4Vs
abstract: Artificial agents have traditionally been trained to maximize reward, which
  may incentivize power-seeking and deception, analogous to how next-token prediction
  in language models (LMs) may incentivize toxicity. So do agents naturally learn
  to be Machiavellian? And how do we measure these behaviors in general-purpose models
  such as GPT-4? Towards answering these questions, we introduce Machiavelli, a benchmark
  of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse
  scenarios that center on social decision-making. Scenario labeling is automated
  with LMs, which are more performant than human annotators. We mathematize dozens
  of harmful behaviors and use our annotations to evaluate agents’ tendencies to be
  power-seeking, cause disutility, and commit ethical violations. We observe some
  tension between maximizing reward and behaving ethically. To improve this trade-off,
  we investigate LM-based methods to steer agents towards less harmful behaviors.
  Our results show that agents can both act competently and morally, so concrete progress
  can currently be made in machine ethics–designing agents that are Pareto improvements
  in both safety and capabilities.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pan23a
month: 0
tex_title: Do the Rewards Justify the Means? {M}easuring Trade-Offs Between Rewards
  and Ethical Behavior in the Machiavelli Benchmark
firstpage: 26837
lastpage: 26867
page: 26837-26867
order: 26837
cycles: false
bibtex_author: Pan, Alexander and Chan, Jun Shern and Zou, Andy and Li, Nathaniel
  and Basart, Steven and Woodside, Thomas and Zhang, Hanlin and Emmons, Scott and
  Hendrycks, Dan
author:
- given: Alexander
  family: Pan
- given: Jun Shern
  family: Chan
- given: Andy
  family: Zou
- given: Nathaniel
  family: Li
- given: Steven
  family: Basart
- given: Thomas
  family: Woodside
- given: Hanlin
  family: Zhang
- given: Scott
  family: Emmons
- given: Dan
  family: Hendrycks
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/pan23a/pan23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
