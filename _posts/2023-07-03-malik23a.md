---
title: 'Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure
  Optimality'
openreview: YfRey5GvTF
abstract: In human-interactive applications of online learning, a human’s preferences
  or abilities are often a function of the algorithm’s recent actions. Motivated by
  this, a significant line of work has formalized settings where an action’s loss
  is a function of the number of times it was played in the prior $m$ timesteps, where
  $m$ corresponds to a bound on human memory capacity. To more faithfully capture
  decay of human memory with time, we introduce the Weighted Tallying Bandit (WTB),
  which generalizes this setting by requiring that an action’s loss is a function
  of a <em>weighted</em> summation of the number of times it was played in the last
  $m$ timesteps. WTB is intractable without further assumption. So we study it under
  Repeated Exposure Optimality (REO), a condition requiring the existence of an action
  that when repetitively played will eventually yield smaller loss than any other
  action sequence. We study the minimization of complete policy regret (CPR), which
  is the strongest notion of regret, in WTB under REO. Since $m$ is often unknown,
  we only assume access to an upper bound $M$ on $m$. We show that for problems with
  $K$ actions and horizon $T$, a simple modification of the successive elimination
  algorithm has $\mathcal{O} \left( \sqrt{KT} + (m+M)K \right)$ CPR. Upto an additive
  (in lieu of mutliplicative) factor in $(m+M)K$, this recovers the classical guarantee
  for the far simpler stochastic multi-armed bandit with traditional regret. We additionally
  show that in our setting, any algorithm will suffer additive CPR of $\Omega \left(
  mK + M \right)$, demonstrating our result is near optimal. Our method is computationally
  efficient, and we experimentally demonstrate its practicality and superiority over
  various baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: malik23a
month: 0
tex_title: 'Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure
  Optimality'
firstpage: 23590
lastpage: 23609
page: 23590-23609
order: 23590
cycles: false
bibtex_author: Malik, Dhruv and Igoe, Conor and Li, Yuanzhi and Singh, Aarti
author:
- given: Dhruv
  family: Malik
- given: Conor
  family: Igoe
- given: Yuanzhi
  family: Li
- given: Aarti
  family: Singh
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/malik23a/malik23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
