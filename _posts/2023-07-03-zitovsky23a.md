---
title: Revisiting Bellman Errors for Offline Model Selection
openreview: l3uttHb0YW
abstract: Offline model selection (OMS), that is, choosing the best policy from a
  set of many policies given only logged data, is crucial for applying offline RL
  in real-world settings. One idea that has been extensively explored is to select
  policies based on the mean squared Bellman error (MSBE) of the associated Q-functions.
  However, previous work has struggled to obtain adequate OMS performance with Bellman
  errors, leading many researchers to abandon the idea. To this end, we elucidate
  why previous work has seen pessimistic results with Bellman errors and identify
  conditions under which OMS algorithms based on Bellman errors will perform well.
  Moreover, we develop a new estimator of the MSBE that is more accurate than prior
  methods. Our estimator obtains impressive OMS performance on diverse discrete control
  tasks, including Atari games.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zitovsky23a
month: 0
tex_title: Revisiting {B}ellman Errors for Offline Model Selection
firstpage: 43369
lastpage: 43406
page: 43369-43406
order: 43369
cycles: false
bibtex_author: Zitovsky, Joshua P and De Marchi, Daniel and Agarwal, Rishabh and Kosorok,
  Michael Rene
author:
- given: Joshua P
  family: Zitovsky
- given: Daniel
  family: De Marchi
- given: Rishabh
  family: Agarwal
- given: Michael Rene
  family: Kosorok
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zitovsky23a/zitovsky23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
