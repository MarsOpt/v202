---
title: Understanding Backdoor Attacks through the Adaptability Hypothesis
openreview: iIuLNEnOue
abstract: A poisoning backdoor attack is a rising security concern for deep learning.
  This type of attack can result in the backdoored model functioning normally most
  of the time but exhibiting abnormal behavior when presented with inputs containing
  the backdoor trigger, making it difficult to detect and prevent. In this work, we
  propose the adaptability hypothesis to understand when and why a backdoor attack
  works for general learning models, including deep neural networks, based on the
  theoretical investigation of classical kernel-based learning models. The adaptability
  hypothesis postulates that for an effective attack, the effect of incorporating
  a new dataset on the predictions of the original data points will be small, provided
  that the original data points are distant from the new dataset. Experiments on benchmark
  image datasets and state-of-the-art backdoor attacks for deep neural networks are
  conducted to corroborate the hypothesis. Our finding provides insight into the factors
  that affect the attackâ€™s effectiveness and has implications for the design of future
  attacks and defenses.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xian23a
month: 0
tex_title: Understanding Backdoor Attacks through the Adaptability Hypothesis
firstpage: 37952
lastpage: 37976
page: 37952-37976
order: 37952
cycles: false
bibtex_author: Xian, Xun and Wang, Ganghua and Srinivasa, Jayanth and Kundu, Ashish
  and Bi, Xuan and Hong, Mingyi and Ding, Jie
author:
- given: Xun
  family: Xian
- given: Ganghua
  family: Wang
- given: Jayanth
  family: Srinivasa
- given: Ashish
  family: Kundu
- given: Xuan
  family: Bi
- given: Mingyi
  family: Hong
- given: Jie
  family: Ding
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xian23a/xian23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
