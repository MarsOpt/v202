---
title: Parallel Neurosymbolic Integration with Concordia
openreview: zbYo7Ay4Mt
abstract: Parallel neurosymbolic architectures have been applied effectively in NLP
  by distilling knowledge from a logic theory into a deep model. However, prior art
  faces several limitations including supporting restricted forms of logic theories
  and relying on the assumption of independence between the logic and the deep network.
  We present Concordia, a framework overcoming the limitations of prior art. Concordia
  is agnostic both to the deep network and the logic theory offering support for a
  wide range of probabilistic theories. Our framework can support supervised training
  of both components and unsupervised training of the neural component. Concordia
  has been successfully applied to tasks beyond NLP and data classification, improving
  the accuracy of state-of-the-art on collective activity detection, entity linking
  and recommendation tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feldstein23a
month: 0
tex_title: Parallel Neurosymbolic Integration with Concordia
firstpage: 9870
lastpage: 9885
page: 9870-9885
order: 9870
cycles: false
bibtex_author: Feldstein, Jonathan and Jur\v{c}ius, Modestas and Tsamoura, Efthymia
author:
- given: Jonathan
  family: Feldstein
- given: Modestas
  family: Jurƒçius
- given: Efthymia
  family: Tsamoura
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/feldstein23a/feldstein23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
