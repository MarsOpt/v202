---
title: 'Certifying Ensembles: A General Certification Theory with S-Lipschitzness'
openreview: zv7X5ybgSQ
abstract: Improving and guaranteeing the robustness of deep learning models has been
  a topic of intense research. Ensembling, which combines several classifiers to provide
  a better model, has been shown to be beneficial for generalisation, uncertainty
  estimation, calibration, and mitigating the effects of concept drift. However, the
  impact of ensembling on certified robustness is less well understood. In this work,
  we generalise Lipschitz continuity by introducing S-Lipschitz classifiers, which
  we use to analyse the theoretical robustness of ensembles. Our results are precise
  conditions when ensembles of robust classifiers are more robust than any constituent
  classifier, as well as conditions when they are less robust.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: petrov23a
month: 0
tex_title: 'Certifying Ensembles: A General Certification Theory with S-Lipschitzness'
firstpage: 27709
lastpage: 27736
page: 27709-27736
order: 27709
cycles: false
bibtex_author: Petrov, Aleksandar and Eiras, Francisco and Sanyal, Amartya and Torr,
  Philip and Bibi, Adel
author:
- given: Aleksandar
  family: Petrov
- given: Francisco
  family: Eiras
- given: Amartya
  family: Sanyal
- given: Philip
  family: Torr
- given: Adel
  family: Bibi
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/petrov23a/petrov23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
