---
title: 'LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation'
openreview: P98vAWoj5W
abstract: 'Recent works have demonstrated the benefits of capturing long-distance
  dependency in graphs by deeper graph neural networks (GNNs). But deeper GNNs suffer
  from the long-lasting scalability challenge due to the neighborhood explosion problem
  in large-scale graphs. In this work, we propose to capture long-distance dependency
  in graphs by shallower models instead of deeper models, which leads to a much more
  efficient model, LazyGNN, for graph representation learning. Moreover, we demonstrate
  that LazyGNN is compatible with existing scalable approaches (such as sampling methods)
  for further accelerations through the development of mini-batch LazyGNN. Comprehensive
  experiments demonstrate its superior prediction performance and scalability on large-scale
  benchmarks. The implementation of LazyGNN is available at https: //github.com/RXPHD/Lazy_GNN.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xue23c
month: 0
tex_title: "{L}azy{GNN}: Large-Scale Graph Neural Networks via Lazy Propagation"
firstpage: 38926
lastpage: 38937
page: 38926-38937
order: 38926
cycles: false
bibtex_author: Xue, Rui and Han, Haoyu and Torkamani, Mohamadali and Pei, Jian and
  Liu, Xiaorui
author:
- given: Rui
  family: Xue
- given: Haoyu
  family: Han
- given: Mohamadali
  family: Torkamani
- given: Jian
  family: Pei
- given: Xiaorui
  family: Liu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xue23c/xue23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
