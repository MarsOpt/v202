---
title: Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional
  Curriculum
openreview: BMO1vLKq7D
abstract: While reinforcement learning (RL) has achieved great success in acquiring
  complex skills solely from environmental interactions, it assumes that resets to
  the initial state are readily available at the end of each episode. Such an assumption
  hinders the autonomous learning of embodied agents due to the time-consuming and
  cumbersome workarounds for resetting in the physical world. Hence, there has been
  a growing interest in autonomous RL (ARL) methods that are capable of learning from
  non-episodic interactions. However, existing works on ARL are limited by their reliance
  on prior data and are unable to learn in environments where task-relevant interactions
  are sparse. In contrast, we propose a demonstration-free ARL algorithm via Implicit
  and Bi-directional Curriculum (IBC). With an auxiliary agent that is conditionally
  activated upon learning progress and a bidirectional goal curriculum based on optimal
  transport, our method outperforms previous methods, even the ones that leverage
  demonstrations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim23d
month: 0
tex_title: Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional
  Curriculum
firstpage: 16441
lastpage: 16457
page: 16441-16457
order: 16441
cycles: false
bibtex_author: Kim, Jigang and Cho, Daesol and Kim, H. Jin
author:
- given: Jigang
  family: Kim
- given: Daesol
  family: Cho
- given: H. Jin
  family: Kim
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/kim23d/kim23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
