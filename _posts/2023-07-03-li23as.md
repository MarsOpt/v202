---
title: Understanding the Complexity Gains of Single-Task RL with a Curriculum
openreview: GKxLarv7S5
abstract: Reinforcement learning (RL) problems can be challenging without well-shaped
  rewards. Prior work on provably efficient RL methods generally proposes to address
  this issue with dedicated exploration strategies. However, another way to tackle
  this challenge is to reformulate it as a multi-task RL problem, where the task space
  contains not only the challenging task of interest but also easier tasks that implicitly
  function as a curriculum. Such a reformulation opens up the possibility of running
  existing multi-task RL methods as a more efficient alternative to solving a single
  challenging task from scratch. In this work, we provide a theoretical framework
  that reformulates a single-task RL problem as a multi-task RL problem defined by
  a curriculum. Under mild regularity conditions on the curriculum, we show that sequentially
  solving each task in the multi-task RL problem is more computationally efficient
  than solving the original single-task problem, without any explicit exploration
  bonuses or other exploration strategies. We also show that our theoretical insights
  can be translated into an effective practical learning algorithm that can accelerate
  curriculum learning on simulated robotic tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23as
month: 0
tex_title: Understanding the Complexity Gains of Single-Task {RL} with a Curriculum
firstpage: 20412
lastpage: 20451
page: 20412-20451
order: 20412
cycles: false
bibtex_author: Li, Qiyang and Zhai, Yuexiang and Ma, Yi and Levine, Sergey
author:
- given: Qiyang
  family: Li
- given: Yuexiang
  family: Zhai
- given: Yi
  family: Ma
- given: Sergey
  family: Levine
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23as/li23as.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
