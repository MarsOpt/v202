---
title: 'Towards Sustainable Learning: Coresets for Data-efficient Deep Learning'
openreview: ASOCqTnWIY
abstract: To improve the efficiency and sustainability of learning deep models, we
  propose CREST, the first scalable framework with rigorous theoretical guarantees
  to identify the most valuable examples for training non-convex models, particularly
  deep networks. To guarantee convergence to a stationary point of a non-convex function,
  CREST models the non-convex loss as a series of quadratic functions and extracts
  a coreset for each quadratic sub-region. In addition, to ensure faster convergence
  of stochastic gradient methods such as (mini-batch) SGD, CREST iteratively extracts
  multiple mini-batch coresets from larger random subsets of training data, to ensure
  nearly-unbiased gradients with small variances. Finally, to further improve scalability
  and efficiency, CREST identifies and excludes the examples that are learned from
  the coreset selection pipeline. Our extensive experiments on several deep networks
  trained on vision and NLP datasets, including CIFAR-10, CIFAR-100, TinyImageNet,
  and SNLI, confirm that CREST speeds up training deep networks on very large datasets,
  by 1.7x to 2.5x with minimum loss in the performance. By analyzing the learning
  difficulty of the subsets selected by CREST, we show that deep models benefit the
  most by learning from subsets of increasing difficulty levels.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23g
month: 0
tex_title: 'Towards Sustainable Learning: Coresets for Data-efficient Deep Learning'
firstpage: 39314
lastpage: 39330
page: 39314-39330
order: 39314
cycles: false
bibtex_author: Yang, Yu and Kang, Hao and Mirzasoleiman, Baharan
author:
- given: Yu
  family: Yang
- given: Hao
  family: Kang
- given: Baharan
  family: Mirzasoleiman
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yang23g/yang23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
