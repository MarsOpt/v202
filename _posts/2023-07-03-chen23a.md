---
title: Multi-Layer Neural Networks as Trainable Ladders of Hilbert Spaces
openreview: ZMvv6laV5b
abstract: To characterize the functions spaces explored by multi-layer neural networks
  (NNs), we introduce Neural Hilbert Ladders (NHLs), a collection of reproducing kernel
  Hilbert spaces (RKHSes) that are defined iteratively and adaptive to training. First,
  we prove a correspondence between functions expressed by L-layer NNs and those belonging
  to L-level NHLs. Second, we prove generalization guarantees for learning the NHL
  based on a new complexity measure. Third, corresponding to the training of multi-layer
  NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized
  by the dynamics of multiple random fields. Finally, we examine linear and shallow
  NNs from the new perspective and complement the theory with numerical results.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23a
month: 0
tex_title: Multi-Layer Neural Networks as Trainable Ladders of {H}ilbert Spaces
firstpage: 4294
lastpage: 4329
page: 4294-4329
order: 4294
cycles: false
bibtex_author: Chen, Zhengdao
author:
- given: Zhengdao
  family: Chen
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chen23a/chen23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
