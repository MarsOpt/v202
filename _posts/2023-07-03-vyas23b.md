---
title: On Provable Copyright Protection for Generative Models
openreview: qRAHZVnQNY
abstract: There is a growing concern that learned conditional generative models may
  output samples that are substantially similar to some copyrighted data $C$ that
  was in their training set. We give a formal definition of near access-freeness (NAF)
  and prove bounds on the probability that a model satisfying this definition outputs
  a sample similar to $C$, even if $C$ is included in its training set. Roughly speaking,
  a generative model $p$ is $k$-NAF if for every potentially copyrighted data $C$,
  the output of $p$ diverges by at most $k$-bits from the output of a model $q$ that
  did not access $C$ at all. We also give generative model learning algorithms, which
  efficiently modify the original generative model learning algorithm in a black box
  manner, that output generative models with strong bounds on the probability of sampling
  protected content. Furthermore, we provide promising experiments for both language
  (transformers) and image (diffusion) generative models, showing minimal degradation
  in output quality while ensuring strong protections against sampling protected content.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vyas23b
month: 0
tex_title: On Provable Copyright Protection for Generative Models
firstpage: 35277
lastpage: 35299
page: 35277-35299
order: 35277
cycles: false
bibtex_author: Vyas, Nikhil and Kakade, Sham M. and Barak, Boaz
author:
- given: Nikhil
  family: Vyas
- given: Sham M.
  family: Kakade
- given: Boaz
  family: Barak
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/vyas23b/vyas23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
