---
title: Exploring the Limits of Model-Targeted Indiscriminate Data Poisoning Attacks
openreview: r1DAAD9IyE
abstract: 'Indiscriminate data poisoning attacks aim to decrease a modelâ€™s test accuracy
  by injecting a small amount of corrupted training data. Despite significant interest,
  existing attacks remain relatively ineffective against modern machine learning (ML)
  architectures. In this work, we introduce the notion of model poisoning reachability
  as a technical tool to explore the intrinsic limits of data poisoning attacks towards
  target parameters (i.e., model-targeted attacks). We derive an easily computable
  threshold to establish and quantify a surprising phase transition phenomenon among
  popular ML models: data poisoning attacks can achieve certain target parameters
  only when the poisoning ratio exceeds our threshold. Building on existing parameter
  corruption attacks and refining the Gradient Canceling attack, we perform extensive
  experiments to confirm our theoretical findings, test the predictability of our
  transition threshold, and significantly improve existing indiscriminate data poisoning
  baselines over a range of datasets and models. Our work highlights the critical
  role played by the poisoning ratio, and sheds new insights on existing empirical
  results, attacks and mitigation strategies in data poisoning.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu23e
month: 0
tex_title: Exploring the Limits of Model-Targeted Indiscriminate Data Poisoning Attacks
firstpage: 22856
lastpage: 22879
page: 22856-22879
order: 22856
cycles: false
bibtex_author: Lu, Yiwei and Kamath, Gautam and Yu, Yaoliang
author:
- given: Yiwei
  family: Lu
- given: Gautam
  family: Kamath
- given: Yaoliang
  family: Yu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/lu23e/lu23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
