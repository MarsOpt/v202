---
title: Open-Vocabulary Universal Image Segmentation with MaskCLIP
openreview: Hsfchgv3WW
abstract: 'In this paper, we tackle an emerging computer vision task, open-vocabulary
  universal image segmentation, that aims to perform semantic/instance/panoptic segmentation
  (background semantic labeling + foreground instance segmentation) for arbitrary
  categories of text-based descriptions in inference time. We first build a baseline
  method by directly adopting pre-trained CLIP models without finetuning or distillation.
  We then develop MaskCLIP, a Transformer-based approach with a MaskCLIP Visual Encoder,
  which is an encoder-only module that seamlessly integrates mask tokens with a pre-trained
  ViT CLIP model for semantic/instance segmentation and class prediction. MaskCLIP
  learns to efficiently and effectively utilize pre-trained partial/dense CLIP features
  within the MaskCLIP Visual Encoder that avoids the time-consuming student-teacher
  training process. MaskCLIP outperforms previous methods for semantic/instance/panoptic
  segmentation on ADE20K and PASCAL datasets. We show qualitative illustrations for
  MaskCLIP with online custom categories. Project website: https://maskclip.github.io.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding23c
month: 0
tex_title: Open-Vocabulary Universal Image Segmentation with {M}ask{CLIP}
firstpage: 8090
lastpage: 8102
page: 8090-8102
order: 8090
cycles: false
bibtex_author: Ding, Zheng and Wang, Jieke and Tu, Zhuowen
author:
- given: Zheng
  family: Ding
- given: Jieke
  family: Wang
- given: Zhuowen
  family: Tu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/ding23c/ding23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
