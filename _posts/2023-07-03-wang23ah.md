---
title: 'InfoDiffusion: Representation Learning Using Information Maximizing Diffusion
  Models'
openreview: ycZSQdo2F9
abstract: While diffusion models excel at generating high-quality samples, their latent
  variables typically lack semantic meaning and are not suitable for representation
  learning. Here, we propose InfoDiffusion, an algorithm that augments diffusion models
  with low-dimensional latent variables that capture high-level factors of variation
  in the data. InfoDiffusion relies on a learning objective regularized with the mutual
  information between observed and hidden variables, which improves latent space quality
  and prevents the latents from being ignored by expressive diffusion-based decoders.
  Empirically, we find that InfoDiffusion learns disentangled and human-interpretable
  latent representations that are competitive with state-of-the-art generative and
  contrastive methods, while retaining the high sample quality of diffusion models.
  Our method enables manipulating the attributes of generated images and has the potential
  to assist tasks that require exploring a learned latent space to generate quality
  samples, e.g., generative design.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23ah
month: 0
tex_title: "{I}nfo{D}iffusion: Representation Learning Using Information Maximizing
  Diffusion Models"
firstpage: 36336
lastpage: 36354
page: 36336-36354
order: 36336
cycles: false
bibtex_author: Wang, Yingheng and Schiff, Yair and Gokaslan, Aaron and Pan, Weishen
  and Wang, Fei and De Sa, Christopher and Kuleshov, Volodymyr
author:
- given: Yingheng
  family: Wang
- given: Yair
  family: Schiff
- given: Aaron
  family: Gokaslan
- given: Weishen
  family: Pan
- given: Fei
  family: Wang
- given: Christopher
  family: De Sa
- given: Volodymyr
  family: Kuleshov
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wang23ah/wang23ah.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
