---
title: Towards Understanding Generalization of Macro-AUC in Multi-label Learning
openreview: DDX1YCwOag
abstract: 'Macro-AUC is the arithmetic mean of the class-wise AUCs in multi-label
  learning and is commonly used in practice. However, its theoretical understanding
  is far lacking. Toward solving it, we characterize the generalization properties
  of various learning algorithms based on the corresponding surrogate losses w.r.t.
  Macro-AUC. We theoretically identify a critical factor of the dataset affecting
  the generalization bounds: <em>the label-wise class imbalance</em>. Our results
  on the imbalance-aware error bounds show that the widely-used univariate loss-based
  algorithm is more sensitive to the label-wise class imbalance than the proposed
  pairwise and reweighted loss-based ones, which probably implies its worse performance.
  Moreover, empirical results on various datasets corroborate our theory findings.
  To establish it, technically, we propose a new (and more general) McDiarmid-type
  concentration inequality, which may be of independent interest.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu23l
month: 0
tex_title: Towards Understanding Generalization of Macro-{AUC} in Multi-label Learning
firstpage: 37540
lastpage: 37570
page: 37540-37570
order: 37540
cycles: false
bibtex_author: Wu, Guoqiang and Li, Chongxuan and Yin, Yilong
author:
- given: Guoqiang
  family: Wu
- given: Chongxuan
  family: Li
- given: Yilong
  family: Yin
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wu23l/wu23l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
