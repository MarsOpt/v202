---
title: Efficient Latency-Aware CNN Depth Compression via Two-Stage Dynamic Programming
openreview: JOrh26MBOT
abstract: Recent works on neural network pruning advocate that reducing the depth
  of the network is more effective in reducing run-time memory usage and accelerating
  inference latency than reducing the width of the network through channel pruning.
  In this regard, some recent works propose depth compression algorithms that merge
  convolution layers. However, the existing algorithms have a constricted search space
  and rely on human-engineered heuristics. In this paper, we propose a novel depth
  compression algorithm which targets general convolution operations. We propose a
  subset selection problem that replaces inefficient activation layers with identity
  functions and optimally merges consecutive convolution operations into shallow equivalent
  convolution operations for efficient end-to-end inference latency. Since the proposed
  subset selection problem is NP-hard, we formulate a surrogate optimization problem
  that can be solved exactly via two-stage dynamic programming within a few seconds.
  We evaluate our methods and baselines by TensorRT for a fair inference latency comparison.
  Our method outperforms the baseline method with higher accuracy and faster inference
  speed in MobileNetV2 on the ImageNet dataset. Specifically, we achieve $1.41\times$
  speed-up with $0.11$%p accuracy gain in MobileNetV2-1.0 on the ImageNet.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim23f
month: 0
tex_title: Efficient Latency-Aware {CNN} Depth Compression via Two-Stage Dynamic Programming
firstpage: 16502
lastpage: 16520
page: 16502-16520
order: 16502
cycles: false
bibtex_author: Kim, Jinuk and Jeong, Yeonwoo and Lee, Deokjae and Song, Hyun Oh
author:
- given: Jinuk
  family: Kim
- given: Yeonwoo
  family: Jeong
- given: Deokjae
  family: Lee
- given: Hyun Oh
  family: Song
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/kim23f/kim23f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
