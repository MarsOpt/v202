---
title: Provable Benefit of Mixup for Finding Optimal Decision Boundaries
openreview: dls28A9vYi
abstract: We investigate how pair-wise data augmentation techniques like Mixup affect
  the sample complexity of finding optimal decision boundaries in a binary linear
  classification problem. For a family of data distributions with a separability constant
  $\kappa$, we analyze how well the optimal classifier in terms of training loss aligns
  with the optimal one in test accuracy (i.e., Bayes optimal classifier). For vanilla
  training without augmentation, we uncover an interesting phenomenon named the curse
  of separability. As we increase $\kappa$ to make the data distribution more separable,
  the sample complexity of vanilla training increases exponentially in $\kappa$; perhaps
  surprisingly, the task of finding optimal decision boundaries becomes harder for
  more separable distributions. For Mixup training, we show that Mixup mitigates this
  problem by significantly reducing the sample complexity. To this end, we develop
  new concentration results applicable to $n^2$ pair-wise augmented data points constructed
  from $n$ independent data, by carefully dealing with dependencies between overlapping
  pairs. Lastly, we study other masking-based Mixup-style techniques and show that
  they can distort the training loss and make its minimizer converge to a suboptimal
  classifier in terms of test accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: oh23a
month: 0
tex_title: Provable Benefit of Mixup for Finding Optimal Decision Boundaries
firstpage: 26403
lastpage: 26450
page: 26403-26450
order: 26403
cycles: false
bibtex_author: Oh, Junsoo and Yun, Chulhee
author:
- given: Junsoo
  family: Oh
- given: Chulhee
  family: Yun
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/oh23a/oh23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
