---
title: 'LoSparse: Structured Compression of Large Language Models based on Low-Rank
  and Sparse Approximation'
openreview: STmbtFRpdz
abstract: 'Transformer models have achieved remarkable results in various natural
  language tasks, but they are often prohibitively large, requiring massive memories
  and computational resources. To re- duce the size and complexity of these models,
  we propose LoSparse (Low-Rank and Sparse ap- proximation), a novel model compression
  tech- nique that approximates a weight matrix by the sum of a low-rank matrix and
  a sparse matrix. Our method combines the advantages of both low- rank approximations
  and pruning, while avoid- ing their limitations. Low-rank approximation compresses
  the coherent and expressive parts in neurons, while pruning removes the incoherent
  and non-expressive parts in neurons. Pruning enhances the diversity of low-rank
  approxima- tions, and low-rank approximation prevents prun- ing from losing too
  many expressive neurons. We evaluate our method on natural language under- standing,
  question answering, and natural lan- guage generation tasks. We show that it signif-
  icantly outperforms existing compression meth- ods. Our code is publicly available
  at https: //github.com/yxli2123/LoSparse'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23ap
month: 0
tex_title: "{L}o{S}parse: Structured Compression of Large Language Models based on
  Low-Rank and Sparse Approximation"
firstpage: 20336
lastpage: 20350
page: 20336-20350
order: 20336
cycles: false
bibtex_author: Li, Yixiao and Yu, Yifan and Zhang, Qingru and Liang, Chen and He,
  Pengcheng and Chen, Weizhu and Zhao, Tuo
author:
- given: Yixiao
  family: Li
- given: Yifan
  family: Yu
- given: Qingru
  family: Zhang
- given: Chen
  family: Liang
- given: Pengcheng
  family: He
- given: Weizhu
  family: Chen
- given: Tuo
  family: Zhao
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23ap/li23ap.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
