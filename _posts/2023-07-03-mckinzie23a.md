---
title: Robustness in Multimodal Learning under Train-Test Modality Mismatch
openreview: pw5vm7tzeE
abstract: Multimodal learning is defined as learning over multiple heterogeneous input
  modalities such as video, audio, and text. In this work, we are concerned with understanding
  how models behave as the type of modalities differ between training and deployment,
  a situation that naturally arises in many applications of multimodal learning to
  hardware platforms. We present a multimodal robustness framework to provide a systematic
  analysis of common multimodal representation learning methods. Further, we identify
  robustness short-comings of these approaches and propose two intervention techniques
  leading to $1.5\times$-$4\times$ robustness improvements on three datasets, AudioSet,
  Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions
  better utilize additional modalities, if present, to achieve competitive results
  of $44.2$ mAP on AudioSet 20K.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mckinzie23a
month: 0
tex_title: Robustness in Multimodal Learning under Train-Test Modality Mismatch
firstpage: 24291
lastpage: 24303
page: 24291-24303
order: 24291
cycles: false
bibtex_author: Mckinzie, Brandon and Shankar, Vaishaal and Cheng, Joseph Yitan and
  Yang, Yinfei and Shlens, Jonathon and Toshev, Alexander T
author:
- given: Brandon
  family: Mckinzie
- given: Vaishaal
  family: Shankar
- given: Joseph Yitan
  family: Cheng
- given: Yinfei
  family: Yang
- given: Jonathon
  family: Shlens
- given: Alexander T
  family: Toshev
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/mckinzie23a/mckinzie23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
