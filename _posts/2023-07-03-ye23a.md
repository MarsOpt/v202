---
title: 'On the Power of Pre-training for Generalization in RL: Provable Benefits and
  Hardness'
openreview: ZvKWki48yP
abstract: 'Generalization in Reinforcement Learning (RL) aims to train an agent during
  training that generalizes to the target environment. In this work, we first point
  out that RL generalization is fundamentally different from the generalization in
  supervised learning, and fine-tuning on the target environment is necessary for
  good test performance. Therefore, we seek to answer the following question: how
  much can we expect pre-training over training environments to be helpful for efficient
  and effective fine-tuning? On one hand, we give a surprising result showing that
  asymptotically, the improvement from pre-training is at most a constant factor.
  On the other hand, we show that pre-training can be indeed helpful in the non-asymptotic
  regime by designing a policy collection-elimination (PCE) algorithm and proving
  a distribution-dependent regret bound that is independent of the state-action space.
  We hope our theoretical results can provide insight towards understanding pre-training
  and generalization in RL.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ye23a
month: 0
tex_title: 'On the Power of Pre-training for Generalization in {RL}: Provable Benefits
  and Hardness'
firstpage: 39770
lastpage: 39800
page: 39770-39800
order: 39770
cycles: false
bibtex_author: Ye, Haotian and Chen, Xiaoyu and Wang, Liwei and Du, Simon Shaolei
author:
- given: Haotian
  family: Ye
- given: Xiaoyu
  family: Chen
- given: Liwei
  family: Wang
- given: Simon Shaolei
  family: Du
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/ye23a/ye23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
