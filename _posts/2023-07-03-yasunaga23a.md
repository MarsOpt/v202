---
title: Retrieval-Augmented Multimodal Language Modeling
openreview: VZ8bs0fwoO
abstract: Recent multimodal models such as DALL-E and CM3 have achieved remarkable
  progress in text-to-image and image-to-text generation. However, these models store
  all their knowledge (e.g., the appearance of the Eiffel Tower) in the model parameters,
  requiring increasingly larger models and training data to capture more knowledge.
  To integrate knowledge in a more scalable and modular way, we propose a retrieval-augmented
  multimodal model, which enables a base multimodal model (generator) to refer to
  relevant text and images fetched by a retriever from external memory (e.g., documents
  on the web). Specifically, for the retriever, we use a pretrained CLIP, and for
  the generator, we train a CM3 Transformer on the LAION dataset. Our resulting model,
  named Retrieval-Augmented CM3 (RA-CM3), is the first multimodal model that can retrieve
  and generate both text and images. We show that RA-CM3 significantly outperforms
  baseline multimodal models such as DALL-E and CM3 on both image and caption generation
  tasks (12 FID and 17 CIDEr improvements on MS-COCO), while requiring much less compute
  for training ($<$30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel capabilities
  such as faithful image generation and multimodal in-context learning (e.g., image
  generation from demonstrations).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yasunaga23a
month: 0
tex_title: Retrieval-Augmented Multimodal Language Modeling
firstpage: 39755
lastpage: 39769
page: 39755-39769
order: 39755
cycles: false
bibtex_author: Yasunaga, Michihiro and Aghajanyan, Armen and Shi, Weijia and James,
  Richard and Leskovec, Jure and Liang, Percy and Lewis, Mike and Zettlemoyer, Luke
  and Yih, Wen-Tau
author:
- given: Michihiro
  family: Yasunaga
- given: Armen
  family: Aghajanyan
- given: Weijia
  family: Shi
- given: Richard
  family: James
- given: Jure
  family: Leskovec
- given: Percy
  family: Liang
- given: Mike
  family: Lewis
- given: Luke
  family: Zettlemoyer
- given: Wen-Tau
  family: Yih
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yasunaga23a/yasunaga23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
