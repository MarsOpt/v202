---
title: 'Certified Robust Neural Networks: Generalization and Corruption Resistance'
openreview: 4cvSExetbO
abstract: Recent work have demonstrated that robustness (to "corruption") can be at
  odds with generalization. Adversarial training, for instance, aims to reduce the
  problematic susceptibility of modern neural networks to small data perturbations.
  Surprisingly, overfitting is a major concern in adversarial training despite being
  mostly absent in standard training. We provide here theoretical evidence for this
  peculiar “robust overfitting” phenomenon. Subsequently, we advance a novel distributionally
  robust loss function bridging robustness and generalization. We demonstrate both
  theoretically as well as empirically the loss to enjoy a certified level of robustness
  against two common types of corruption|data evasion and poisoning attacks|while
  ensuring guaranteed generalization. We show through careful numerical experiments
  that our resulting holistic robust (HR) training procedure yields SOTA performance.
  Finally, we indicate that HR training can be interpreted as a direct extension of
  adversarial training and comes with a negligible additional computational burden.
  A ready-to-use python library implementing our algorithm is available at https://github.com/RyanLucas3/HR_Neural_Networks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bennouna23a
month: 0
tex_title: 'Certified Robust Neural Networks: Generalization and Corruption Resistance'
firstpage: 2092
lastpage: 2112
page: 2092-2112
order: 2092
cycles: false
bibtex_author: Bennouna, Amine and Lucas, Ryan and Van Parys, Bart
author:
- given: Amine
  family: Bennouna
- given: Ryan
  family: Lucas
- given: Bart
  family: Van Parys
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/bennouna23a/bennouna23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
