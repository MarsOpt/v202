---
title: Compressing Tabular Data via Latent Variable Estimation
openreview: TdGIfSZDV3
abstract: 'Data used for analytics and machine learning often take the form of tables
  with categorical entries. We introduce a family of lossless compression algorithms
  for such data that proceed in four steps: (i) Estimate latent variables associated
  to rows and columns; (ii) Partition the table in blocks according to the row/column
  latents; (iii) Apply a sequential (e.g. Lempel-Ziv) coder to each of the blocks;
  (iv) Append a compressed encoding of the latents. We evaluate this approach on several
  benchmark datasets, and study optimal compression in a probabilistic model for tabular
  data, whereby latent values are independent and table entries are conditionally
  independent given the latent values. We prove that the model has a well defined
  entropy rate and satisfies an asymptotic equipartition property. We also prove that
  classical compression schemes such as Lempel-Ziv and finite-state encoders do not
  achieve this rate. On the other hand, the latent estimation strategy outlined above
  achieves the optimal rate.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: montanari23a
month: 0
tex_title: Compressing Tabular Data via Latent Variable Estimation
firstpage: 25174
lastpage: 25208
page: 25174-25208
order: 25174
cycles: false
bibtex_author: Montanari, Andrea and Weiner, Eric
author:
- given: Andrea
  family: Montanari
- given: Eric
  family: Weiner
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/montanari23a/montanari23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
