---
title: On the Effectiveness of Offline RL for Dialogue Response Generation
openreview: gVAk5bYETD
abstract: A common training technique for language models is teacher forcing (TF).
  TF attempts to match human language exactly, even though identical meanings can
  be expressed in different ways. This motivates use of sequence-level objectives
  for dialogue response generation. In this paper, we study the efficacy of various
  offline reinforcement learning (RL) methods to maximize such objectives. We present
  a comprehensive evaluation across multiple datasets, models, and metrics. Offline
  RL shows a clear performance improvement over teacher forcing while not inducing
  training instability or sacrificing practical training budgets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sodhi23a
month: 0
tex_title: On the Effectiveness of Offline {RL} for Dialogue Response Generation
firstpage: 32088
lastpage: 32104
page: 32088-32104
order: 32088
cycles: false
bibtex_author: Sodhi, Paloma and Wu, Felix and Elenberg, Ethan R. and Weinberger,
  Kilian Q and Mcdonald, Ryan
author:
- given: Paloma
  family: Sodhi
- given: Felix
  family: Wu
- given: Ethan R.
  family: Elenberg
- given: Kilian Q
  family: Weinberger
- given: Ryan
  family: Mcdonald
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/sodhi23a/sodhi23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
