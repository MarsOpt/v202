---
title: Is Learning Summary Statistics Necessary for Likelihood-free Inference?
openreview: jjzJ768iV1
abstract: Likelihood-free inference (LFI) is a set of techniques for inference in
  implicit statistical models. A longstanding question in LFI has been how to design
  or learn good summary statistics of data, but this might now seem unnecessary due
  to the advent of recent end-to-end (i.e. neural network-based) LFI methods. In this
  work, we rethink this question with a new method for learning summary statistics.
  We show that learning sufficient statistics may be easier than direct posterior
  inference, as the former problem can be reduced to a set of low-dimensional, easy-to-solve
  learning problems. This suggests us to explicitly decouple summary statistics learning
  from posterior inference in LFI. Experiments on diverse inference tasks with different
  data types validate our hypothesis.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23h
month: 0
tex_title: Is Learning Summary Statistics Necessary for Likelihood-free Inference?
firstpage: 4529
lastpage: 4544
page: 4529-4544
order: 4529
cycles: false
bibtex_author: Chen, Yanzhi and Gutmann, Michael U. and Weller, Adrian
author:
- given: Yanzhi
  family: Chen
- given: Michael U.
  family: Gutmann
- given: Adrian
  family: Weller
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chen23h/chen23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
