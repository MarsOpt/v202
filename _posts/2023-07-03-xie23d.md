---
title: Semiparametrically Efficient Off-Policy Evaluation in Linear Markov Decision
  Processes
openreview: 6lP80vBiI6
abstract: We study semiparametrically efficient estimation in off-policy evaluation
  (OPE) where the underlying Markov decision process (MDP) is linear with a known
  feature map. We characterize the variance lower bound for regular estimators in
  the linear MDP setting and propose an efficient estimator whose variance achieves
  that lower bound. Consistency and asymptotic normality of our estimator are established
  under mild conditions, which merely requires the only infinite-dimensional nuisance
  parameter to be estimated at a $n^{-1/4}$ convergence rate. We also construct an
  asymptotically valid confidence interval for statistical inference and conduct simulation
  studies to validate our results. To our knowledge, this is the first work that concerns
  efficient estimation in the presence of a known structure of MDPs in the OPE literature.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xie23d
month: 0
tex_title: Semiparametrically Efficient Off-Policy Evaluation in Linear {M}arkov Decision
  Processes
firstpage: 38227
lastpage: 38257
page: 38227-38257
order: 38227
cycles: false
bibtex_author: Xie, Chuhan and Yang, Wenhao and Zhang, Zhihua
author:
- given: Chuhan
  family: Xie
- given: Wenhao
  family: Yang
- given: Zhihua
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/xie23d/xie23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
