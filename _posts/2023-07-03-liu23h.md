---
title: A Group Symmetric Stochastic Differential Equation Model for Molecule Multi-modal
  Pretraining
openreview: mPEVwu50th
abstract: Molecule pretraining has quickly become the go-to schema to boost the performance
  of AI-based drug discovery. Naturally, molecules can be represented as 2D topological
  graphs or 3D geometric point clouds. Although most existing pertaining methods focus
  on merely the single modality, recent research has shown that maximizing the mutual
  information (MI) between such two modalities enhances the molecule representation
  ability. Meanwhile, existing molecule multi-modal pretraining approaches approximate
  MI based on the representation space encoded from the topology and geometry, thus
  resulting in the loss of critical structural information of molecules. To address
  this issue, we propose MoleculeSDE. MoleculeSDE leverages group symmetric (e.g.,
  SE(3)-equivariant and reflection-antisymmetric) stochastic differential equation
  models to generate the 3D geometries from 2D topologies, and vice versa, directly
  in the input space. It not only obtains tighter MI bound but also enables prosperous
  downstream tasks than the previous work. By comparing with 17 pretraining baselines,
  we empirically verify that MoleculeSDE can learn an expressive representation with
  state-of-the-art performance on 26 out of 32 downstream tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23h
month: 0
tex_title: A Group Symmetric Stochastic Differential Equation Model for Molecule Multi-modal
  Pretraining
firstpage: 21497
lastpage: 21526
page: 21497-21526
order: 21497
cycles: false
bibtex_author: Liu, Shengchao and Du, Weitao and Ma, Zhi-Ming and Guo, Hongyu and
  Tang, Jian
author:
- given: Shengchao
  family: Liu
- given: Weitao
  family: Du
- given: Zhi-Ming
  family: Ma
- given: Hongyu
  family: Guo
- given: Jian
  family: Tang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/liu23h/liu23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
