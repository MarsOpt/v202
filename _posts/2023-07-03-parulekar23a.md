---
title: PAC Generalization via Invariant Representations
openreview: zAgouWgI7b
abstract: 'Invariant representations are transformations of the covariates such that
  the best model on top of the representation is invariant across training environments.
  In the context of linear Structural Equation Models (SEMs), invariant representations
  might allow us to learn models with out-of-distribution guarantees, i.e., models
  that are robust to interventions in the SEM. To address the invariant representation
  problem in a <em>finite sample</em> setting, we consider the notion of $\epsilon$-approximate
  invariance. We study the following question: If a representation is approximately
  invariant with respect to a given number of training interventions, will it continue
  to be approximately invariant on a larger collection of unseen intervened SEMs?
  Inspired by PAC learning, we obtain finite-sample out-of-distribution generalization
  guarantees for approximate invariance that holds <em>probabilistically</em> over
  a family of linear SEMs without faithfulness assumptions.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: parulekar23a
month: 0
tex_title: "{PAC} Generalization via Invariant Representations"
firstpage: 27378
lastpage: 27400
page: 27378-27400
order: 27378
cycles: false
bibtex_author: Parulekar, Advait U and Shanmugam, Karthikeyan and Shakkottai, Sanjay
author:
- given: Advait U
  family: Parulekar
- given: Karthikeyan
  family: Shanmugam
- given: Sanjay
  family: Shakkottai
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/parulekar23a/parulekar23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
