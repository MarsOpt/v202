---
title: 'XTab: Cross-table Pretraining for Tabular Transformers'
openreview: uGORNDmIdr
abstract: The success of self-supervised learning in computer vision and natural language
  processing has motivated pretraining methods on tabular data. However, most existing
  tabular self-supervised learning models fail to leverage information across multiple
  data tables and cannot generalize to new tables. In this work, we introduce XTab,
  a framework for cross-table pretraining of tabular transformers on datasets from
  various domains. We address the challenge of inconsistent column types and quantities
  among tables by utilizing independent featurizers and using federated learning to
  pretrain the shared component. Tested on 84 tabular prediction tasks from the OpenML-AutoML
  Benchmark (AMLB), we show that (1) XTab consistently boosts the generalizability,
  learning speed, and performance of multiple tabular transformers, (2) by pretraining
  FT-Transformer via XTab, we achieve superior performance than other state-of-the-art
  tabular deep learning models on various tasks such as regression, binary, and multiclass
  classification.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu23k
month: 0
tex_title: "{XT}ab: Cross-table Pretraining for Tabular Transformers"
firstpage: 43181
lastpage: 43204
page: 43181-43204
order: 43181
cycles: false
bibtex_author: Zhu, Bingzhao and Shi, Xingjian and Erickson, Nick and Li, Mu and Karypis,
  George and Shoaran, Mahsa
author:
- given: Bingzhao
  family: Zhu
- given: Xingjian
  family: Shi
- given: Nick
  family: Erickson
- given: Mu
  family: Li
- given: George
  family: Karypis
- given: Mahsa
  family: Shoaran
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhu23k/zhu23k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
