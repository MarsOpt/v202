---
title: Revisiting Weighted Aggregation in Federated Learning with Neural Networks
openreview: FuDAjnWhrQ
abstract: In federated learning (FL), weighted aggregation of local models is conducted
  to generate a global model, and the aggregation weights are normalized (the sum
  of weights is 1) and proportional to the local data sizes. In this paper, we revisit
  the weighted aggregation process and gain new insights into the training dynamics
  of FL. First, we find that the sum of weights can be smaller than 1, causing global
  weight shrinking effect (analogous to weight decay) and improving generalization.
  We explore how the optimal shrinking factor is affected by clients’ data heterogeneity
  and local epochs. Second, we dive into the relative aggregation weights among clients
  to depict the clients’ importance. We develop client coherence to study the learning
  dynamics and find a critical point that exists. Before entering the critical point,
  more coherent clients play more essential roles in generalization. Based on the
  above insights, we propose an effective method for Federated Learning with Learnable
  Aggregation Weights, named as FedLAW. Extensive experiments verify that our method
  can improve the generalization of the global model by a large margin on different
  datasets and models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23s
month: 0
tex_title: Revisiting Weighted Aggregation in Federated Learning with Neural Networks
firstpage: 19767
lastpage: 19788
page: 19767-19788
order: 19767
cycles: false
bibtex_author: Li, Zexi and Lin, Tao and Shang, Xinyi and Wu, Chao
author:
- given: Zexi
  family: Li
- given: Tao
  family: Lin
- given: Xinyi
  family: Shang
- given: Chao
  family: Wu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23s/li23s.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
