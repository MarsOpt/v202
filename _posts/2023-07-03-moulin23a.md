---
title: Optimistic Planning by Regularized Dynamic Programming
openreview: LctoTBcGUf
abstract: We propose a new method for optimistic planning in infinite-horizon discounted
  Markov decision processes based on the idea of adding regularization to the updates
  of an otherwise standard approximate value iteration procedure. This technique allows
  us to avoid contraction and monotonicity arguments typically required by existing
  analyses of approximate dynamic programming methods, and in particular to use approximate
  transition functions estimated via least-squares procedures in MDPs with linear
  function approximation. We use our method to recover known guarantees in tabular
  MDPs and to provide a computationally efficient algorithm for learning near-optimal
  policies in discounted linear mixture MDPs from a single stream of experience, and
  show it achieves near-optimal statistical guarantees.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: moulin23a
month: 0
tex_title: Optimistic Planning by Regularized Dynamic Programming
firstpage: 25337
lastpage: 25357
page: 25337-25357
order: 25337
cycles: false
bibtex_author: Moulin, Antoine and Neu, Gergely
author:
- given: Antoine
  family: Moulin
- given: Gergely
  family: Neu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/moulin23a/moulin23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
