---
title: Behavior Contrastive Learning for Unsupervised Skill Discovery
openreview: AfHIuNCzV4
abstract: In reinforcement learning, unsupervised skill discovery aims to learn diverse
  skills without extrinsic rewards. Previous methods discover skills by maximizing
  the mutual information (MI) between states and skills. However, such an MI objective
  tends to learn simple and static skills and may hinder exploration. In this paper,
  we propose a novel unsupervised skill discovery method through contrastive learning
  among behaviors, which makes the agent produce similar behaviors for the same skill
  and diverse behaviors for different skills. Under mild assumptions, our objective
  maximizes the MI between different behaviors based on the same skill, which serves
  as an upper bound of the previous MI objective. Meanwhile, our method implicitly
  increases the state entropy to obtain better state coverage. We evaluate our method
  on challenging mazes and continuous control tasks. The results show that our method
  generates diverse and far-reaching skills, and also obtains competitive performance
  in downstream tasks compared to the state-of-the-art methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23a
month: 0
tex_title: Behavior Contrastive Learning for Unsupervised Skill Discovery
firstpage: 39183
lastpage: 39204
page: 39183-39204
order: 39183
cycles: false
bibtex_author: Yang, Rushuai and Bai, Chenjia and Guo, Hongyi and Li, Siyuan and Zhao,
  Bin and Wang, Zhen and Liu, Peng and Li, Xuelong
author:
- given: Rushuai
  family: Yang
- given: Chenjia
  family: Bai
- given: Hongyi
  family: Guo
- given: Siyuan
  family: Li
- given: Bin
  family: Zhao
- given: Zhen
  family: Wang
- given: Peng
  family: Liu
- given: Xuelong
  family: Li
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yang23a/yang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
