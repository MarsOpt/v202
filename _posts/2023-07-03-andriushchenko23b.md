---
title: SGD with Large Step Sizes Learns Sparse Features
openreview: DnTuz0ziwN
abstract: 'We showcase important features of the dynamics of the Stochastic Gradient
  Descent (SGD) in the training of neural networks. We present empirical observations
  that commonly used large step sizes (i) may lead the iterates to jump from one side
  of a valley to the other causing <em>loss stabilization</em>, and (ii) this stabilization
  induces a hidden stochastic dynamics that <em>biases it implicitly</em> toward simple
  predictors. Furthermore, we show empirically that the longer large step sizes keep
  SGD high in the loss landscape valleys, the better the implicit regularization can
  operate and find sparse representations. Notably, no explicit regularization is
  used: the regularization effect comes solely from the SGD dynamics influenced by
  the large step sizes schedule. Therefore, these observations unveil how, through
  the step size schedules, both gradient and noise drive together the SGD dynamics
  through the loss landscape of neural networks. We justify these findings theoretically
  through the study of simple neural network models as well as qualitative arguments
  inspired from stochastic processes. This analysis allows us to shed new light on
  some common practices and observed phenomena when training deep networks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: andriushchenko23b
month: 0
tex_title: "{SGD} with Large Step Sizes Learns Sparse Features"
firstpage: 903
lastpage: 925
page: 903-925
order: 903
cycles: false
bibtex_author: Andriushchenko, Maksym and Varre, Aditya Vardhan and Pillaud-Vivien,
  Loucas and Flammarion, Nicolas
author:
- given: Maksym
  family: Andriushchenko
- given: Aditya Vardhan
  family: Varre
- given: Loucas
  family: Pillaud-Vivien
- given: Nicolas
  family: Flammarion
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/andriushchenko23b/andriushchenko23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
