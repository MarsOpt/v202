---
title: Learning in POMDPs is Sample-Efficient with Hindsight Observability
openreview: WPjMrOi1KE
abstract: POMDPs capture a broad class of decision making problems, but hardness results
  suggest that learning is intractable even in simple settings due to the inherent
  partial observability. However, in many realistic problems, more information is
  either revealed or can be computed during some point of the learning process. Motivated
  by diverse applications ranging from robotics to data center scheduling, we formulate
  a Hindsight Observable Markov Decision Process (HOMDP) as a POMDP where the latent
  states are revealed to the learner in hindsight and only during training. We introduce
  new algorithms for the tabular and function approximation settings that are provably
  sample-efficient with hindsight observability, even in POMDPs that would otherwise
  be statistically intractable. We give a lower bound showing that the tabular algorithm
  is optimal in its dependence on latent state and observation cardinalities.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lee23a
month: 0
tex_title: Learning in {POMDP}s is Sample-Efficient with Hindsight Observability
firstpage: 18733
lastpage: 18773
page: 18733-18773
order: 18733
cycles: false
bibtex_author: Lee, Jonathan and Agarwal, Alekh and Dann, Christoph and Zhang, Tong
author:
- given: Jonathan
  family: Lee
- given: Alekh
  family: Agarwal
- given: Christoph
  family: Dann
- given: Tong
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/lee23a/lee23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
