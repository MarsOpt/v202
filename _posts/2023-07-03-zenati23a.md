---
title: Sequential Counterfactual Risk Minimization
openreview: E3Ny4RnbiT
abstract: Counterfactual Risk Minimization (CRM) is a framework for dealing with the
  logged bandit feedback problem, where the goal is to improve a logging policy using
  offline data. In this paper, we explore the case where it is possible to deploy
  learned policies multiple times and acquire new data. We extend the CRM principle
  and its theory to this scenario, which we call "Sequential Counterfactual Risk Minimization
  (SCRM)." We introduce a novel counterfactual estimator and identify conditions that
  can improve the performance of CRM in terms of excess risk and regret rates, by
  using an analysis similar to restart strategies in accelerated optimization methods.
  We also provide an empirical evaluation of our method in both discrete and continuous
  action settings, and demonstrate the benefits of multiple deployments of CRM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zenati23a
month: 0
tex_title: Sequential Counterfactual Risk Minimization
firstpage: 40681
lastpage: 40706
page: 40681-40706
order: 40681
cycles: false
bibtex_author: Zenati, Houssam and Diemert, Eustache and Martin, Matthieu and Mairal,
  Julien and Gaillard, Pierre
author:
- given: Houssam
  family: Zenati
- given: Eustache
  family: Diemert
- given: Matthieu
  family: Martin
- given: Julien
  family: Mairal
- given: Pierre
  family: Gaillard
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zenati23a/zenati23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
