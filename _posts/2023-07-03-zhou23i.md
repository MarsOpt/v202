---
title: Deep Latent State Space Models for Time-Series Generation
openreview: juHlutJcm6
abstract: Methods based on ordinary differential equations (ODEs) are widely used
  to build generative models of time-series. In addition to high computational overhead
  due to explicitly computing hidden states recurrence, existing ODE-based models
  fall short in learning sequence data with sharp transitions - common in many real-world
  systems - due to numerical challenges during optimization. In this work, we propose
  LS4, a generative model for sequences with latent variables evolving according to
  a state space ODE to increase modeling capacity. Inspired by recent deep state space
  models (S4), we achieve speedups by leveraging a convolutional representation of
  LS4 which bypasses the explicit evaluation of hidden states. We show that LS4 significantly
  outperforms previous continuous-time generative models in terms of marginal distribution,
  classification, and prediction scores on real-world datasets in the Monash Forecasting
  Repository, and is capable of modeling highly stochastic data with sharp temporal
  transitions. LS4 sets state-of-the-art for continuous-time latent generative models,
  with significant improvement of mean squared error and tighter variational lower
  bounds on irregularly-sampled datasets, while also being x100 faster than other
  baselines on long sequences.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhou23i
month: 0
tex_title: Deep Latent State Space Models for Time-Series Generation
firstpage: 42625
lastpage: 42643
page: 42625-42643
order: 42625
cycles: false
bibtex_author: Zhou, Linqi and Poli, Michael and Xu, Winnie and Massaroli, Stefano
  and Ermon, Stefano
author:
- given: Linqi
  family: Zhou
- given: Michael
  family: Poli
- given: Winnie
  family: Xu
- given: Stefano
  family: Massaroli
- given: Stefano
  family: Ermon
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhou23i/zhou23i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
