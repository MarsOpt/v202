---
title: 'Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective'
openreview: dolp65Z6re
abstract: The top-$k$ operator returns a $k$-sparse vector, where the non-zero values
  correspond to the $k$ largest values of the input. Unfortunately, because it is
  a discontinuous function, it is difficult to incorporate in neural networks trained
  end-to-end with backpropagation. Recent works have considered differentiable relaxations,
  based either on regularization or perturbation techniques. However, to date, no
  approach is fully differentiable and sparse. In this paper, we propose new differentiable
  and sparse top-$k$ operators. We view the top-$k$ operator as a linear program over
  the permutahedron, the convex hull of permutations. We then introduce a $p$-norm
  regularization term to smooth out the operator, and show that its computation can
  be reduced to isotonic optimization. Our framework is significantly more general
  than the existing one and allows for example to express top-$k$ operators that select
  values in magnitude. On the algorithmic side, in addition to pool adjacent violator
  (PAV) algorithms, we propose a new GPU/TPU-friendly Dykstra algorithm to solve isotonic
  optimization problems. We successfully use our operators to prune weights in neural
  networks, to fine-tune vision transformers, and as a router in sparse mixture of
  experts.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sander23a
month: 0
tex_title: 'Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective'
firstpage: 29919
lastpage: 29936
page: 29919-29936
order: 29919
cycles: false
bibtex_author: Sander, Michael Eli and Puigcerver, Joan and Djolonga, Josip and Peyr\'{e},
  Gabriel and Blondel, Mathieu
author:
- given: Michael Eli
  family: Sander
- given: Joan
  family: Puigcerver
- given: Josip
  family: Djolonga
- given: Gabriel
  family: Peyr√©
- given: Mathieu
  family: Blondel
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/sander23a/sander23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
