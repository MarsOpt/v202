---
title: Scalable Safe Policy Improvement via Monte Carlo Tree Search
openreview: tevbBSzSfK
abstract: Algorithms for safely improving policies are important to deploy reinforcement
  learning approaches in real-world scenarios. In this work, we propose an algorithm,
  called MCTS-SPIBB, that computes safe policy improvement online using a Monte Carlo
  Tree Search based strategy. We theoretically prove that the policy generated by
  MCTS-SPIBB converges, as the number of simulations grows, to the optimal safely
  improved policy generated by Safe Policy Improvement with Baseline Bootstrapping
  (SPIBB), a popular algorithm based on policy iteration. Moreover, our empirical
  analysis performed on three standard benchmark domains shows that MCTS-SPIBB scales
  to significantly larger problems than SPIBB because it computes the policy online
  and locally, i.e., only in the states actually visited by the agent.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: castellini23a
month: 0
tex_title: Scalable Safe Policy Improvement via {M}onte {C}arlo Tree Search
firstpage: 3732
lastpage: 3756
page: 3732-3756
order: 3732
cycles: false
bibtex_author: Castellini, Alberto and Bianchi, Federico and Zorzi, Edoardo and Sim\~{a}o,
  Thiago D. and Farinelli, Alessandro and Spaan, Matthijs T. J.
author:
- given: Alberto
  family: Castellini
- given: Federico
  family: Bianchi
- given: Edoardo
  family: Zorzi
- given: Thiago D.
  family: Sim√£o
- given: Alessandro
  family: Farinelli
- given: Matthijs T. J.
  family: Spaan
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/castellini23a/castellini23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
