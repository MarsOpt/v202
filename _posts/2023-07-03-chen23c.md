---
title: 'Trompt: Towards a Better Deep Neural Network for Tabular Data'
openreview: 0yNmeyteuS
abstract: Tabular data is arguably one of the most commonly used data structures in
  various practical domains, including finance, healthcare and e-commerce. The inherent
  heterogeneity allows tabular data to store rich information. However, based on a
  recently published tabular benchmark, we can see deep neural networks still fall
  behind tree-based models on tabular datasets. In this paper, we propose Trompt–which
  stands for Tabular Prompt–a novel architecture inspired by prompt learning of language
  models. The essence of prompt learning is to adjust a large pre-trained model through
  a set of prompts outside the model without directly modifying the model. Based on
  this idea, Trompt separates the learning strategy of tabular data into two parts.
  The first part, analogous to pre-trained models, focus on learning the intrinsic
  information of a table. The second part, analogous to prompts, focus on learning
  the variations among samples. Trompt is evaluated with the benchmark mentioned above.
  The experimental results demonstrate that Trompt outperforms state-of-the-art deep
  neural networks and is comparable to tree-based models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23c
month: 0
tex_title: 'Trompt: Towards a Better Deep Neural Network for Tabular Data'
firstpage: 4392
lastpage: 4434
page: 4392-4434
order: 4392
cycles: false
bibtex_author: Chen, Kuan-Yu and Chiang, Ping-Han and Chou, Hsin-Rung and Chen, Ting-Wei
  and Chang, Tien-Hao
author:
- given: Kuan-Yu
  family: Chen
- given: Ping-Han
  family: Chiang
- given: Hsin-Rung
  family: Chou
- given: Ting-Wei
  family: Chen
- given: Tien-Hao
  family: Chang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chen23c/chen23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
