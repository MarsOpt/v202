---
title: Accelerated Stochastic Optimization Methods under Quasar-convexity
openreview: yg4k1kYbXe
abstract: Non-convex optimization plays a key role in a growing number of machine
  learning applications. This motivates the identification of specialized structure
  that enables sharper theoretical analysis. One such identified structure is quasar-convexity,
  a non-convex generalization of convexity that subsumes convex functions. Existing
  algorithms for minimizing quasar-convex functions in the stochastic setting have
  either high complexity or slow convergence, which prompts us to derive a new class
  of stochastic methods for optimizing smooth quasar-convex functions. We demonstrate
  that our algorithms have fast convergence and outperform existing algorithms on
  several examples, including the classical problem of learning linear dynamical systems.
  We also present a unified analysis of our newly proposed algorithms and a previously
  studied deterministic algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fu23e
month: 0
tex_title: Accelerated Stochastic Optimization Methods under Quasar-convexity
firstpage: 10431
lastpage: 10460
page: 10431-10460
order: 10431
cycles: false
bibtex_author: Fu, Qiang and Xu, Dongchu and Wilson, Ashia Camage
author:
- given: Qiang
  family: Fu
- given: Dongchu
  family: Xu
- given: Ashia Camage
  family: Wilson
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/fu23e/fu23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
