---
title: Optimizing the Collaboration Structure in Cross-Silo Federated Learning
openreview: rnNBSMOWvA
abstract: 'In federated learning (FL), multiple clients collaborate to train machine
  learning models together while keeping their data decentralized. Through utilizing
  more training data, FL suffers from the potential negative transfer problem: the
  global FL model may even perform worse than the models trained with local data only.
  In this paper, we propose FedCollab, a novel FL framework that alleviates negative
  transfer by clustering clients into non-overlapping coalitions based on their distribution
  distances and data quantities. As a result, each client only collaborates with the
  clients having similar data distributions, and tends to collaborate with more clients
  when it has less data. We evaluate our framework with a variety of datasets, models,
  and types of non-IIDness. Our results demonstrate that FedCollab effectively mitigates
  negative transfer across a wide range of FL algorithms and consistently outperforms
  other clustered FL algorithms.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bao23b
month: 0
tex_title: Optimizing the Collaboration Structure in Cross-Silo Federated Learning
firstpage: 1718
lastpage: 1736
page: 1718-1736
order: 1718
cycles: false
bibtex_author: Bao, Wenxuan and Wang, Haohan and Wu, Jun and He, Jingrui
author:
- given: Wenxuan
  family: Bao
- given: Haohan
  family: Wang
- given: Jun
  family: Wu
- given: Jingrui
  family: He
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/bao23b/bao23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
