---
title: Sampling-based Nyström Approximation and Kernel Quadrature
openreview: eg7mjtvKlE
abstract: We analyze the Nyström approximation of a positive definite kernel associated
  with a probability measure. We first prove an improved error bound for the conventional
  Nyström approximation with i.i.d. sampling and singular-value decomposition in the
  continuous regime; the proof techniques are borrowed from statistical learning theory.
  We further introduce a refined selection of subspaces in Nyström approximation with
  theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally,
  we discuss their application to convex kernel quadrature and give novel theoretical
  guarantees as well as numerical observations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hayakawa23a
month: 0
tex_title: Sampling-based Nyström Approximation and Kernel Quadrature
firstpage: 12678
lastpage: 12699
page: 12678-12699
order: 12678
cycles: false
bibtex_author: Hayakawa, Satoshi and Oberhauser, Harald and Lyons, Terry
author:
- given: Satoshi
  family: Hayakawa
- given: Harald
  family: Oberhauser
- given: Terry
  family: Lyons
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/hayakawa23a/hayakawa23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
