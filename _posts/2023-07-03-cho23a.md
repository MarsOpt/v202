---
title: 'Neural Latent Aligner: Cross-trial Alignment for Learning Representations
  of Complex, Naturalistic Neural Data'
openreview: S2hcTJB6fb
abstract: Understanding the neural implementation of complex human behaviors is one
  of the major goals in neuroscience. To this end, it is crucial to find a true representation
  of the neural data, which is challenging due to the high complexity of behaviors
  and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised
  learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally
  relevant neural representations of complex behaviors. The key idea is to align representations
  across repeated trials to learn cross-trial consistent information. Furthermore,
  we propose a novel, fully differentiable time warping model (TWM) to resolve the
  temporal misalignment of trials. When applied to intracranial electrocorticography
  (ECoG) of natural speaking, our model learns better representations for decoding
  behaviors than the baseline models, especially in lower dimensional space. The TWM
  is empirically validated by measuring behavioral coherence between aligned trials.
  The proposed framework learns more cross-trial consistent representations than the
  baselines, and when visualized, the manifold reveals shared neural trajectories
  across trials.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cho23a
month: 0
tex_title: 'Neural Latent Aligner: Cross-trial Alignment for Learning Representations
  of Complex, Naturalistic Neural Data'
firstpage: 5661
lastpage: 5676
page: 5661-5676
order: 5661
cycles: false
bibtex_author: Cho, Cheol Jun and Chang, Edward and Anumanchipalli, Gopala
author:
- given: Cheol Jun
  family: Cho
- given: Edward
  family: Chang
- given: Gopala
  family: Anumanchipalli
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/cho23a/cho23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
