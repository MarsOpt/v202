---
title: The Fast Johnson-Lindenstrauss Transform Is Even Faster
openreview: XnV8dbrGI4
abstract: The Johnson-Lindenstaruss lemma (Johnson & Lindenstrauss, 1984) is a cornerstone
  result in dimensionality reduction, stating it is possible to embed a set of $n$
  points in $d$-dimensional Euclidean space into optimal $k=O(\varepsilon^{-2} \ln
  n)$ dimensions, while preserving all pairwise distances to within a factor $(1 \pm
  \varepsilon)$. The seminal Fast Johnson-Lindenstrauss (Fast JL) transform by Ailon
  and Chazelle (SICOMP’09) supports computing the embedding of a data point in $O(d
  \ln d +k \ln^2 n)$ time, where the $d \ln d$ term comes from multiplication with
  a $d \times d$ Hadamard matrix and the $k \ln^2 n$ term comes from multiplication
  with a sparse $k \times d$ matrix. Despite the Fast JL transform being more than
  a decade old, it is one of the fastest dimensionality reduction techniques for many
  tradeoffs between $\varepsilon, d$ and $n$. In this work, we give a surprising new
  analysis of the Fast JL transform, showing that the $k \ln^2 n$ term in the embedding
  time can be improved to $(k \ln^2 n)/\alpha$ for an $\alpha = \Omega(\min\{\varepsilon^{-1}\ln(1/\varepsilon),
  \ln n\})$. The improvement follows by using an even sparser matrix. We complement
  our improved analysis with a lower bound showing that our new analysis is in fact
  tight.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fandina23a
month: 0
tex_title: The Fast Johnson-Lindenstrauss Transform Is Even Faster
firstpage: 9689
lastpage: 9715
page: 9689-9715
order: 9689
cycles: false
bibtex_author: Fandina, Ora Nova and H{\o}gsgaard, Mikael M{\o}ller and Larsen, Kasper
  Green
author:
- given: Ora Nova
  family: Fandina
- given: Mikael Møller
  family: Høgsgaard
- given: Kasper Green
  family: Larsen
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/fandina23a/fandina23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
