---
title: Long-Tailed Recognition by Mutual Information Maximization between Latent Features
  and Ground-Truth Labels
openreview: KqNX6VOqnJ
abstract: Although contrastive learning methods have shown prevailing performance
  on a variety of representation learning tasks, they encounter difficulty when the
  training dataset is long-tailed. Many researchers have combined contrastive learning
  and a logit adjustment technique to address this problem, but the combinations are
  done ad-hoc and a theoretical background has not yet been provided. The goal of
  this paper is to provide the background and further improve the performance. First,
  we show that the fundamental reason contrastive learning methods struggle with long-tailed
  tasks is that they try to maximize the mutual information between latent features
  and input data. As ground-truth labels are not considered in the maximization, they
  are not able to address imbalances between classes. Rather, we interpret the long-tailed
  recognition task as a mutual information maximization between latent features and
  ground-truth labels. This approach integrates contrastive learning and logit adjustment
  seamlessly to derive a loss function that shows state-of-the-art performance on
  long-tailed recognition benchmarks. It also demonstrates its efficacy in image segmentation
  tasks, verifying its versatility beyond image classification. Code is available
  at https://github.com/bluecdm/Long-tailed-recognition.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: suh23a
month: 0
tex_title: Long-Tailed Recognition by Mutual Information Maximization between Latent
  Features and Ground-Truth Labels
firstpage: 32770
lastpage: 32782
page: 32770-32782
order: 32770
cycles: false
bibtex_author: Suh, Min-Kook and Seo, Seung-Woo
author:
- given: Min-Kook
  family: Suh
- given: Seung-Woo
  family: Seo
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/suh23a/suh23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
