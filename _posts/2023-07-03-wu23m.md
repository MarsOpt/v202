---
title: Quantifying the Knowledge in GNNs for Reliable Distillation into MLPs
openreview: SZldtLz7xg
abstract: 'To bridge the gaps between topology-aware Graph Neural Networks (GNNs)
  and inference-efficient Multi-Layer Perceptron (MLPs), GLNN proposes to distill
  knowledge from a well-trained teacher GNN into a student MLP. Despite their great
  progress, comparatively little work has been done to explore the reliability of
  different knowledge points (nodes) in GNNs, especially their roles played during
  distillation. In this paper, we first quantify the knowledge reliability in GNN
  by measuring the invariance of their information entropy to noise perturbations,
  from which we observe that different knowledge points (1) show different distillation
  speeds (temporally); (2) are differentially distributed in the graph (spatially).
  To achieve reliable distillation, we propose an effective approach, namely Knowledge-inspired
  Reliable Distillation (KRD), that models the probability of each node being an informative
  and reliable knowledge point, based on which we sample a set of additional reliable
  knowledge points as supervision for training student MLPs. Extensive experiments
  show that KRD improves over the vanilla MLPs by 12.62% and outperforms its corresponding
  teacher GNNs by 2.16% averaged over 7 datasets and 3 GNN architectures. Codes are
  publicly available at: https://github.com/LirongWu/RKD.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu23m
month: 0
tex_title: Quantifying the Knowledge in {GNN}s for Reliable Distillation into {MLP}s
firstpage: 37571
lastpage: 37581
page: 37571-37581
order: 37571
cycles: false
bibtex_author: Wu, Lirong and Lin, Haitao and Huang, Yufei and Li, Stan Z.
author:
- given: Lirong
  family: Wu
- given: Haitao
  family: Lin
- given: Yufei
  family: Huang
- given: Stan Z.
  family: Li
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wu23m/wu23m.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
