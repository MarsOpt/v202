---
title: 'Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility
  and Possibility Theorems for Multilingual Language Models'
openreview: SP6w4sVCyp
abstract: Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual
  generalization or compression to facilitate transfer to a large number of (potentially
  unseen) languages. However, these models should ideally also be private, linguistically
  fair, and transparent, by relating their predictions to training data. Can these
  requirements be simultaneously satisfied? We show that multilingual compression
  and linguistic fairness are compatible with differential privacy, but that differential
  privacy is at odds with training data influence sparsity, an objective for transparency.
  We further present a series of experiments on two common NLP tasks and evaluate
  multilingual compression and training data influence sparsity under different privacy
  guarantees, exploring these trade-offs in more detail. Our results suggest that
  we need to develop ways to jointly optimize for these objectives in order to find
  practical trade-offs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rust23a
month: 0
tex_title: 'Differential Privacy, Linguistic Fairness, and Training Data Influence:
  Impossibility and Possibility Theorems for Multilingual Language Models'
firstpage: 29354
lastpage: 29387
page: 29354-29387
order: 29354
cycles: false
bibtex_author: Rust, Phillip and S{\o}gaard, Anders
author:
- given: Phillip
  family: Rust
- given: Anders
  family: SÃ¸gaard
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/rust23a/rust23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
