---
title: Reward-Mixing MDPs with Few Latent Contexts are Learnable
openreview: 6GHuDWZojq
abstract: 'We consider episodic reinforcement learning in reward-mixing Markov decision
  processes (RMMDPs): at the beginning of every episode nature randomly picks a latent
  reward model among $M$ candidates and an agent interacts with the MDP throughout
  the episode for $H$ time steps. Our goal is to learn a near-optimal policy that
  nearly maximizes the $H$ time-step cumulative rewards in such a model. Prior work
  established an upper bound for RMMDPs with $M=2$. In this work, we resolve several
  open questions for the general RMMDP setting. We consider an arbitrary $M\ge2$ and
  provide a sample-efficient algorithm–$EM^2$–that outputs an $\epsilon$-optimal policy
  using $O \left(\epsilon^{-2} \cdot S^d A^d \cdot \text{poly}(H, Z)^d \right)$ episodes,
  where $S, A$ are the number of states and actions respectively, $H$ is the time-horizon,
  $Z$ is the support size of reward distributions and $d=O(\min(M,H))$. We also provide
  a $(SA)^{\Omega(\sqrt{M})} / \epsilon^{2}$ lower bound, supporting that super-polynomial
  sample complexity in $M$ is necessary.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kwon23b
month: 0
tex_title: Reward-Mixing {MDP}s with Few Latent Contexts are Learnable
firstpage: 18057
lastpage: 18082
page: 18057-18082
order: 18057
cycles: false
bibtex_author: Kwon, Jeongyeol and Efroni, Yonathan and Caramanis, Constantine and
  Mannor, Shie
author:
- given: Jeongyeol
  family: Kwon
- given: Yonathan
  family: Efroni
- given: Constantine
  family: Caramanis
- given: Shie
  family: Mannor
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/kwon23b/kwon23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
