---
title: 'Go Beyond Imagination: Maximizing Episodic Reachability with World Models'
openreview: JsAMuzA9o2
abstract: Efficient exploration is a challenging topic in reinforcement learning,
  especially for sparse reward tasks. To deal with the reward sparsity, people commonly
  apply intrinsic rewards to motivate agents to explore the state space efficiently.
  In this paper, we introduce a new intrinsic reward design called GoBI - Go Beyond
  Imagination, which combines the traditional lifelong novelty motivation with an
  episodic intrinsic reward that is designed to maximize the stepwise reachability
  expansion. More specifically, we apply learned world models to generate predicted
  future states with random actions. States with more unique predictions that are
  not in episodic memory are assigned high intrinsic rewards. Our method greatly outperforms
  previous state-of-the-art methods on 12 of the most challenging Minigrid navigation
  tasks and improves the sample efficiency on locomotion tasks from DeepMind Control
  Suite.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fu23c
month: 0
tex_title: 'Go Beyond Imagination: Maximizing Episodic Reachability with World Models'
firstpage: 10405
lastpage: 10420
page: 10405-10420
order: 10405
cycles: false
bibtex_author: Fu, Yao and Peng, Run and Lee, Honglak
author:
- given: Yao
  family: Fu
- given: Run
  family: Peng
- given: Honglak
  family: Lee
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/fu23c/fu23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
