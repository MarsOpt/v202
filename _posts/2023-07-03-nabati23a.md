---
title: Representation-Driven Reinforcement Learning
openreview: qGcVul46dk
abstract: We present a representation-driven framework for reinforcement learning.
  By representing policies as estimates of their expected values, we leverage techniques
  from contextual bandits to guide exploration and exploitation. Particularly, embedding
  a policy network into a linear feature space allows us to reframe the exploration-exploitation
  problem as a representation-exploitation problem, where good policy representations
  enable optimal exploration. We demonstrate the effectiveness of this framework through
  its application to evolutionary and policy gradient-based approaches, leading to
  significantly improved performance compared to traditional methods. Our framework
  provides a new perspective on reinforcement learning, highlighting the importance
  of policy representation in determining optimal exploration-exploitation strategies.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nabati23a
month: 0
tex_title: Representation-Driven Reinforcement Learning
firstpage: 25588
lastpage: 25603
page: 25588-25603
order: 25588
cycles: false
bibtex_author: Nabati, Ofir and Tennenholtz, Guy and Mannor, Shie
author:
- given: Ofir
  family: Nabati
- given: Guy
  family: Tennenholtz
- given: Shie
  family: Mannor
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/nabati23a/nabati23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
