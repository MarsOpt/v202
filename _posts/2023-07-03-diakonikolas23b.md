---
title: Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces and
  ReLU Regression under Gaussian Marginals
openreview: ZDCcGnQhCt
abstract: We study the task of agnostically learning halfspaces under the Gaussian
  distribution. Specifically, given labeled examples $(\\mathbf{x},y)$ from an unknown
  distribution on $\\mathbb{R}^n \\times \\{\pm 1 \\}$, whose marginal distribution
  on $\\mathbf{x}$ is the standard Gaussian and the labels $y$ can be arbitrary, the
  goal is to output a hypothesis with 0-1 loss $\\mathrm{OPT}+\\epsilon$, where $\\mathrm{OPT}$
  is the 0-1 loss of the best-fitting halfspace. We prove a near-optimal computational
  hardness result for this task, under the widely believed sub-exponential time hardness
  of the Learning with Errors (LWE) problem. Prior hardness results are either qualitatively
  suboptimal or apply to restricted families of algorithms. Our techniques extend
  to yield near-optimal lower bounds for related problems, including ReLU regression.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: diakonikolas23b
month: 0
tex_title: Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces
  and {R}e{LU} Regression under {G}aussian Marginals
firstpage: 7922
lastpage: 7938
page: 7922-7938
order: 7922
cycles: false
bibtex_author: Diakonikolas, Ilias and Kane, Daniel and Ren, Lisheng
author:
- given: Ilias
  family: Diakonikolas
- given: Daniel
  family: Kane
- given: Lisheng
  family: Ren
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/diakonikolas23b/diakonikolas23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
