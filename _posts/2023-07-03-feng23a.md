---
title: Weighted Sampling without Replacement for Deep Top-$k$ Classification
openreview: Tv0WUyygoe
abstract: The top-$k$ classification accuracy is a crucial metric in machine learning
  and is often used to evaluate the performance of deep neural networks. These networks
  are typically trained using the cross-entropy loss, which optimizes for top-$1$
  classification and is considered optimal in the case of infinite data. However,
  in real-world scenarios, data is often noisy and limited, leading to the need for
  more robust losses. In this paper, we propose using the Weighted Sampling Without
  Replacement (WSWR) method as a learning objective for top-$k$ loss. While traditional
  methods for evaluating <b>WSWR-based top-$k$ loss</b> are computationally impractical,
  we show a novel connection between WSWR and Reinforcement Learning (RL) and apply
  well-established RL algorithms to estimate gradients. We compared our method with
  recently proposed top-$k$ losses in various regimes of noise and data size for the
  prevalent use case of $k = 5$. Our experimental results reveal that our method consistently
  outperforms all other methods on the top-$k$ metric for noisy datasets, has more
  robustness on extreme testing scenarios, and achieves competitive results on training
  with limited data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feng23a
month: 0
tex_title: Weighted Sampling without Replacement for Deep Top-$k$ Classification
firstpage: 9910
lastpage: 9920
page: 9910-9920
order: 9910
cycles: false
bibtex_author: Feng, Dieqiao and Du, Yuanqi and Gomes, Carla P and Selman, Bart
author:
- given: Dieqiao
  family: Feng
- given: Yuanqi
  family: Du
- given: Carla P
  family: Gomes
- given: Bart
  family: Selman
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/feng23a/feng23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
