---
title: Boosting Offline Reinforcement Learning with Action Preference Query
openreview: XiGijCSGjx
abstract: Training practical agents usually involve offline and online reinforcement
  learning (RL) to balance the policy’s performance and interaction costs. In particular,
  online fine-tuning has become a commonly used method to correct the erroneous estimates
  of out-of-distribution data learned in the offline training phase. However, even
  limited online interactions can be inaccessible or catastrophic for high-stake scenarios
  like healthcare and autonomous driving. In this work, we introduce an interaction-free
  training scheme dubbed Offline-with-Action-Preferences (OAP). The main insight is
  that, compared to online fine-tuning, querying the preferences between pre-collected
  and learned actions can be equally or even more helpful to the erroneous estimate
  problem. By adaptively encouraging or suppressing policy constraint according to
  action preferences, OAP could distinguish overestimation from beneficial policy
  improvement and thus attains a more accurate evaluation of unseen data. Theoretically,
  we prove a lower bound of the behavior policy’s performance improvement brought
  by OAP. Moreover, comprehensive experiments on the D4RL benchmark and state-of-the-art
  algorithms demonstrate that OAP yields higher (29% on average) scores, especially
  on challenging AntMaze tasks (98% higher).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23o
month: 0
tex_title: Boosting Offline Reinforcement Learning with Action Preference Query
firstpage: 39509
lastpage: 39523
page: 39509-39523
order: 39509
cycles: false
bibtex_author: Yang, Qisen and Wang, Shenzhi and Lin, Matthieu Gaetan and Song, Shiji
  and Huang, Gao
author:
- given: Qisen
  family: Yang
- given: Shenzhi
  family: Wang
- given: Matthieu Gaetan
  family: Lin
- given: Shiji
  family: Song
- given: Gao
  family: Huang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/yang23o/yang23o.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
