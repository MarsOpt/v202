---
title: Generalized Implicit Follow-The-Regularized-Leader
openreview: ao0KFFEMwT
abstract: We propose a new class of online learning algorithms, generalized implicit
  Follow-The-Regularized-Leader (FTRL), that expands the scope of FTRL framework.
  Generalized implicit FTRL can recover known algorithms, such as FTRL with linearized
  losses and implicit FTRL, and it allows the design of new update rules, as extensions
  of aProx and Mirror-Prox to FTRL. Our theory is constructive in the sense that it
  provides a simple unifying framework to design updates that directly improve the
  worst-case upper bound on the regret. The key idea is substituting the linearization
  of the losses with a Fenchel-Young inequality. We show the flexibility of the framework
  by proving that some known algorithms, like the Mirror-Prox updates, are instantiations
  of the generalized implicit FTRL. Finally, the new framework allows us to recover
  the temporal variation bound of implicit OMD, with the same computational complexity.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen23t
month: 0
tex_title: Generalized Implicit Follow-The-Regularized-Leader
firstpage: 4826
lastpage: 4838
page: 4826-4838
order: 4826
cycles: false
bibtex_author: Chen, Keyi and Orabona, Francesco
author:
- given: Keyi
  family: Chen
- given: Francesco
  family: Orabona
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chen23t/chen23t.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
