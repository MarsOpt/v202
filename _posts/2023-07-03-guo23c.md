---
title: 'FeDXL: Provable Federated Learning for Deep X-Risk Optimization'
openreview: C7fNCYdptO
abstract: In this paper, we tackle a novel federated learning (FL) problem for optimizing
  a family of X-risks, to which no existing FL algorithms are applicable. In particular,
  the objective has the form of $\mathbb{E}_{\mathbf{z}\sim \mathcal{S}_1} f(\mathbb{E}_{\mathbf{z}’\sim\mathcal{S}_2}
  \ell(\mathbf{w}; \mathbf{z}, \mathbf{z}’))$, where two sets of data $\mathcal S_1,
  \mathcal S_2$ are distributed over multiple machines, $\ell(\cdot; \cdot,\cdot)$
  is a pairwise loss that only depends on the prediction outputs of the input data
  pairs $(\mathbf{z}, \mathbf{z}’)$. This problem has important applications in machine
  learning, e.g., AUROC maximization with a pairwise loss, and partial AUROC maximization
  with a compositional loss. The challenges for designing an FL algorithm for X-risks
  lie in the non-decomposability of the objective over multiple machines and the interdependency
  between different machines. To this end, we propose an active-passive decomposition
  framework that decouples the gradient’s components with two types, namely active
  parts and passive parts, where the active parts depend on local data that are computed
  with the local model and the passive parts depend on other machines that are communicated/computed
  based on historical models and samples. Under this framework, we design two FL algorithms
  (FeDXL) for handling linear and nonlinear $f$, respectively, based on federated
  averaging and merging and develop a novel theoretical analysis to combat the latency
  of the passive parts and the interdependency between the local model parameters
  and the involved data for computing local gradient estimators. We establish both
  iteration and communication complexities and show that using the historical samples
  and models for computing the passive parts do not degrade the complexities. We conduct
  empirical studies of FeDXL for deep AUROC and partial AUROC maximization, and demonstrate
  their performance compared with several baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo23c
month: 0
tex_title: "{F}e{DXL}: Provable Federated Learning for Deep X-Risk Optimization"
firstpage: 11934
lastpage: 11966
page: 11934-11966
order: 11934
cycles: false
bibtex_author: Guo, Zhishuai and Jin, Rong and Luo, Jiebo and Yang, Tianbao
author:
- given: Zhishuai
  family: Guo
- given: Rong
  family: Jin
- given: Jiebo
  family: Luo
- given: Tianbao
  family: Yang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/guo23c/guo23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
