---
title: Tuning Computer Vision Models With Task Rewards
openreview: zzOooeAqtT
abstract: Misalignment between model predictions and intended usage can be detrimental
  for the deployment of computer vision models. The issue is exacerbated when the
  task involves complex structured outputs, as it becomes harder to design procedures
  which address this misalignment. In natural language processing, this is often addressed
  using reinforcement learning techniques that align models with a task reward. We
  adopt this approach and show its surprising effectiveness to improve generic models
  pretrained to imitate example outputs across multiple computer vision tasks, such
  as object detection, panoptic segmentation, colorization and image captioning. We
  believe this approach has the potential to be widely useful for better aligning
  models with a diverse range of computer vision tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: susano-pinto23a
month: 0
tex_title: Tuning Computer Vision Models With Task Rewards
firstpage: 33229
lastpage: 33239
page: 33229-33239
order: 33229
cycles: false
bibtex_author: Susano Pinto, Andr\'{e} and Kolesnikov, Alexander and Shi, Yuge and
  Beyer, Lucas and Zhai, Xiaohua
author:
- given: Andr√©
  family: Susano Pinto
- given: Alexander
  family: Kolesnikov
- given: Yuge
  family: Shi
- given: Lucas
  family: Beyer
- given: Xiaohua
  family: Zhai
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/susano-pinto23a/susano-pinto23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
