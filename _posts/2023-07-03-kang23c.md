---
title: Poisoning Generative Replay in Continual Learning to Promote Forgetting
openreview: km7qa1hme2
abstract: Generative models have grown into the workhorse of many state-of-the-art
  machine learning methods. However, their vulnerability under poisoning attacks has
  been largely understudied. In this work, we investigate this issue in the context
  of continual learning, where generative replayers are utilized to tackle catastrophic
  forgetting. By developing a novel customization of dirty-label input-aware backdoors
  to the online setting, our attacker manages to stealthily promote forgetting while
  retaining high accuracy at the current task and sustaining strong defenders. Our
  approach taps into an intriguing property of generative models, namely that they
  cannot well capture input-dependent triggers. Experiments on four standard datasets
  corroborate the poisonerâ€™s effectiveness.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kang23c
month: 0
tex_title: Poisoning Generative Replay in Continual Learning to Promote Forgetting
firstpage: 15769
lastpage: 15785
page: 15769-15785
order: 15769
cycles: false
bibtex_author: Kang, Siteng and Shi, Zhan and Zhang, Xinhua
author:
- given: Siteng
  family: Kang
- given: Zhan
  family: Shi
- given: Xinhua
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/kang23c/kang23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
