---
title: Controlled Text Generation with Natural Language Instructions
openreview: DBlKltQIO0
abstract: Large language models can be prompted to pro- duce fluent output for a wide
  range of tasks without being specifically trained to do so. Nevertheless, it is
  notoriously difficult to control their generation in such a way that it satisfies
  user-specified constraints. In this paper, we present InstructCTG, a simple controlled
  text generation framework that incorporates different constraints by verbalizing
  them as natural language instructions. We annotate natural texts through a combination
  of off-the-shelf NLP tools and simple heuristics with the linguistic and extra-linguistic
  constraints they satisfy. Then, we verbalize the constraints into natural language
  instructions to form weakly supervised training data, i.e., we prepend the natural
  language verbalizations of the constraints in front of their corresponding natural
  language sentences. Next, we fine-tune a pre-trained language model on the augmented
  corpus. Compared to existing methods, InstructCTG is more flexible in terms of the
  types of constraints it allows the practitioner to use. It also does not require
  any modification of the decoding procedure. Finally, InstructCTG allows the model
  to adapt to new constraints without re-training through the use of in-context learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhou23g
month: 0
tex_title: Controlled Text Generation with Natural Language Instructions
firstpage: 42602
lastpage: 42613
page: 42602-42613
order: 42602
cycles: false
bibtex_author: Zhou, Wangchunshu and Jiang, Yuchen Eleanor and Wilcox, Ethan and Cotterell,
  Ryan and Sachan, Mrinmaya
author:
- given: Wangchunshu
  family: Zhou
- given: Yuchen Eleanor
  family: Jiang
- given: Ethan
  family: Wilcox
- given: Ryan
  family: Cotterell
- given: Mrinmaya
  family: Sachan
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhou23g/zhou23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
