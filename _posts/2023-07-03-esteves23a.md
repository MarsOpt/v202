---
title: Scaling Spherical CNNs
openreview: HiKPaeowPB
abstract: Spherical CNNs generalize CNNs to functions on the sphere, by using spherical
  convolutions as the main linear operation. The most accurate and efficient way to
  compute spherical convolutions is in the spectral domain (via the convolution theorem),
  which is still costlier than the usual planar convolutions. For this reason, applications
  of spherical CNNs have so far been limited to small problems that can be approached
  with low model capacity. In this work, we show how spherical CNNs can be scaled
  for much larger problems. To achieve this, we make critical improvements including
  novel variants of common model components, an implementation of core operations
  to exploit hardware accelerator characteristics, and application-specific input
  representations that exploit the properties of our model. Experiments show our larger
  spherical CNNs reach state-of-the-art on several targets of the QM9 molecular benchmark,
  which was previously dominated by equivariant graph neural networks, and achieve
  competitive performance on multiple weather forecasting tasks. Our code is available
  at https://github.com/google-research/spherical-cnn.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: esteves23a
month: 0
tex_title: Scaling Spherical {CNN}s
firstpage: 9396
lastpage: 9411
page: 9396-9411
order: 9396
cycles: false
bibtex_author: Esteves, Carlos and Slotine, Jean-Jacques and Makadia, Ameesh
author:
- given: Carlos
  family: Esteves
- given: Jean-Jacques
  family: Slotine
- given: Ameesh
  family: Makadia
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/esteves23a/esteves23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
