---
title: Competitive Gradient Optimization
openreview: HeuWdhGNk4
abstract: We study the problem of convergence to a stationary point in zero-sum games.
  We propose competitive gradient optimization (CGO), a gradient-based method that
  incorporates the interactions between two players in zero-sum games for its iterative
  updates. We provide a continuous-time analysis of CGO and its convergence properties
  while showing that in the continuous limit, previous methods degenerate to their
  gradient descent ascent (GDA) variants. We further provide a rate of convergence
  to stationary points in the discrete-time setting. We propose a generalized class
  of $\alpha$-coherent functions and show that for strictly $\alpha$-coherent functions,
  CGO ensures convergence to a saddle point. Moreover, we propose optimistic CGO (oCGO),
  an optimistic variant, for which we show a convergence rate of $O(\frac{1}{n})$
  to saddle points for $\alpha$-coherent functions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vyas23a
month: 0
tex_title: Competitive Gradient Optimization
firstpage: 35243
lastpage: 35276
page: 35243-35276
order: 35243
cycles: false
bibtex_author: Vyas, Abhijeet and Bullins, Brian and Azizzadenesheli, Kamyar
author:
- given: Abhijeet
  family: Vyas
- given: Brian
  family: Bullins
- given: Kamyar
  family: Azizzadenesheli
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/vyas23a/vyas23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
