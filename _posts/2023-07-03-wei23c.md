---
title: Boosting Graph Contrastive Learning via Graph Contrastive Saliency
openreview: XoJIpLASZx
abstract: Graph augmentation plays a crucial role in achieving good generalization
  for contrastive graph self-supervised learning. However, mainstream Graph Contrastive
  Learning (GCL) often favors random graph augmentations, by relying on random node
  dropout or edge perturbation on graphs. Random augmentations may inevitably lead
  to semantic information corruption during the training, and force the network to
  mistakenly focus on semantically irrelevant environmental background structures.
  To address these limitations and to improve generalization, we propose a novel self-supervised
  learning framework for GCL, which can adaptively screen the semantic-related substructure
  in graphs by capitalizing on the proposed gradient-based Graph Contrastive Saliency
  (GCS). The goal is to identify the most semantically discriminative structures of
  a graph via contrastive learning, such that we can generate semantically meaningful
  augmentations by leveraging on saliency. Empirical evidence on 16 benchmark datasets
  demonstrates the exclusive merits of the GCS-based framework. We also provide rigorous
  theoretical justification for GCSâ€™s robustness properties. Code is available at
  https://github.com/GCS2023/GCS .
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wei23c
month: 0
tex_title: Boosting Graph Contrastive Learning via Graph Contrastive Saliency
firstpage: 36839
lastpage: 36855
page: 36839-36855
order: 36839
cycles: false
bibtex_author: Wei, Chunyu and Wang, Yu and Bai, Bing and Ni, Kai and Brady, David
  and Fang, Lu
author:
- given: Chunyu
  family: Wei
- given: Yu
  family: Wang
- given: Bing
  family: Bai
- given: Kai
  family: Ni
- given: David
  family: Brady
- given: Lu
  family: Fang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wei23c/wei23c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
