---
title: 'Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack
  on Federated Learning'
openreview: Kz0IODB2kj
abstract: In Federated Learning (FL) and many other distributed training frameworks,
  collaborators can hold their private data locally and only share the network weights
  trained with the local data after multiple iterations. Gradient inversion is a family
  of privacy attacks that recovers data from its generated gradients. Seemingly, FL
  can provide a degree of protection against gradient inversion attacks on weight
  updates, since the gradient of a single step is concealed by the accumulation of
  gradients over multiple local iterations. In this work, we propose a principled
  way to extend gradient inversion attacks to weight updates in FL, thereby better
  exposing weaknesses in the presumed privacy protection inherent in FL. In particular,
  we propose a surrogate model method based on the characteristic of two-dimensional
  gradient flow and low-rank property of local updates. Our method largely boosts
  the ability of gradient inversion attacks on weight updates containing many iterations
  and achieves state-of-the-art (SOTA) performance. Additionally, our method runs
  up to $100\times$ faster than the SOTA baseline in the common FL scenario. Our work
  re-evaluates and highlights the privacy risk of sharing network weights. Our code
  is available at https://github.com/JunyiZhu-AI/surrogate_model_extension.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu23m
month: 0
tex_title: 'Surrogate Model Extension ({SME}): A Fast and Accurate Weight Update Attack
  on Federated Learning'
firstpage: 43228
lastpage: 43257
page: 43228-43257
order: 43228
cycles: false
bibtex_author: Zhu, Junyi and Yao, Ruicong and Blaschko, Matthew B.
author:
- given: Junyi
  family: Zhu
- given: Ruicong
  family: Yao
- given: Matthew B.
  family: Blaschko
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zhu23m/zhu23m.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
