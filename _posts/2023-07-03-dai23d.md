---
title: Moderately Distributional Exploration for Domain Generalization
openreview: fX5I7lGLuG
abstract: Domain generalization (DG) aims to tackle the distribution shift between
  training domains and unknown target domains. Generating new domains is one of the
  most effective approaches, yet its performance gain depends on the distribution
  discrepancy between the generated and target domains. Distributionally robust optimization
  is promising to tackle distribution discrepancy by exploring domains in an uncertainty
  set. However, the uncertainty set may be overwhelmingly large, leading to low-confidence
  prediction in DG. It is because a large uncertainty set could introduce domains
  containing semantically different factors from training domains. To address this
  issue, we propose to perform a $\textit{mo}$derately $\textit{d}$istributional $\textit{e}$xploration
  (MODE) for domain generalization. Specifically, MODE performs distribution exploration
  in an uncertainty $\textit{subset}$ that shares the same semantic factors with the
  training domains. We show that MODE can endow models with provable generalization
  performance on unknown target domains. The experimental results show that MODE achieves
  competitive performance compared to state-of-the-art baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dai23d
month: 0
tex_title: Moderately Distributional Exploration for Domain Generalization
firstpage: 6786
lastpage: 6817
page: 6786-6817
order: 6786
cycles: false
bibtex_author: Dai, Rui and Zhang, Yonggang and Fang, Zhen and Han, Bo and Tian, Xinmei
author:
- given: Rui
  family: Dai
- given: Yonggang
  family: Zhang
- given: Zhen
  family: Fang
- given: Bo
  family: Han
- given: Xinmei
  family: Tian
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/dai23d/dai23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
