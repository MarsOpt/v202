---
title: 'Magneto: A Foundation Transformer'
openreview: oeAhgeKFEw
abstract: A big convergence of model architectures across language, vision, speech,
  and multimodal is emerging. However, under the same name ”Transformers”, the above
  areas use different implementations for better performance, e.g., Post-LayerNorm
  for BERT, and Pre-LayerNorm for GPT and vision Transformers. We call for the development
  of Foundation Transformer for true general-purpose modeling, which serves as a go-to
  architecture for various tasks and modalities with guaranteed training stability.
  In this work, we introduce a Transformer variant, named Magneto, to fulfill the
  goal. Specifically, we propose Sub-LayerNorm for good expressivity, and the initialization
  strategy theoretically derived from DeepNet for stable scaling up. Extensive experiments
  demonstrate its superior performance and better stability than the de facto Transformer
  variants designed for various applications, including language modeling (i.e., BERT,
  and GPT), machine translation, vision pretraining (i.e., BEiT), speech recognition,
  and multimodal pretraining (i.e., BEiT-3).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23u
month: 0
tex_title: 'Magneto: A Foundation Transformer'
firstpage: 36077
lastpage: 36092
page: 36077-36092
order: 36077
cycles: false
bibtex_author: Wang, Hongyu and Ma, Shuming and Huang, Shaohan and Dong, Li and Wang,
  Wenhui and Peng, Zhiliang and Wu, Yu and Bajaj, Payal and Singhal, Saksham and Benhaim,
  Alon and Patra, Barun and Liu, Zhun and Chaudhary, Vishrav and Song, Xia and Wei,
  Furu
author:
- given: Hongyu
  family: Wang
- given: Shuming
  family: Ma
- given: Shaohan
  family: Huang
- given: Li
  family: Dong
- given: Wenhui
  family: Wang
- given: Zhiliang
  family: Peng
- given: Yu
  family: Wu
- given: Payal
  family: Bajaj
- given: Saksham
  family: Singhal
- given: Alon
  family: Benhaim
- given: Barun
  family: Patra
- given: Zhun
  family: Liu
- given: Vishrav
  family: Chaudhary
- given: Xia
  family: Song
- given: Furu
  family: Wei
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wang23u/wang23u.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
