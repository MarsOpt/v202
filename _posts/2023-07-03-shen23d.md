---
title: Non-autoregressive Conditional Diffusion Models for Time Series Prediction
openreview: wZsnZkviro
abstract: 'Recently, denoising diffusion models have led to significant breakthroughs
  in the generation of images, audio and text. However, it is still an open question
  on how to adapt their strong modeling ability to model time series. In this paper,
  we propose TimeDiff, a non-autoregressive diffusion model that achieves high-quality
  time series prediction with the introduction of two novel conditioning mechanisms:
  future mixup and autoregressive initialization. Similar to teacher forcing, future
  mixup allows parts of the ground-truth future predictions for conditioning, while
  autoregressive initialization helps better initialize the model with basic time
  series patterns such as short-term trends. Extensive experiments are performed on
  nine real-world datasets. Results show that TimeDiff consistently outperforms existing
  time series diffusion models, and also achieves the best overall performance across
  a variety of the existing strong baselines (including transformers and FiLM).'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen23d
month: 0
tex_title: Non-autoregressive Conditional Diffusion Models for Time Series Prediction
firstpage: 31016
lastpage: 31029
page: 31016-31029
order: 31016
cycles: false
bibtex_author: Shen, Lifeng and Kwok, James
author:
- given: Lifeng
  family: Shen
- given: James
  family: Kwok
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/shen23d/shen23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
