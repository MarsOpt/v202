---
title: Offline Reinforcement Learning with Closed-Form Policy Improvement Operators
openreview: pTYSknAd6J
abstract: Behavior constrained policy optimization has been demonstrated to be a successful
  paradigm for tackling Offline Reinforcement Learning. By exploiting historical transitions,
  a policy is trained to maximize a learned value function while constrained by the
  behavior policy to avoid a significant distributional shift. In this paper, we propose
  our closed-form policy improvement operators. We make a novel observation that the
  behavior constraint naturally motivates the use of first-order Taylor approximation,
  leading to a linear approximation of the policy objective. Additionally, as practical
  datasets are usually collected by heterogeneous policies, we model the behavior
  policies as a Gaussian Mixture and overcome the induced optimization difficulties
  by leveraging the LogSumExp’s lower bound and Jensen’s Inequality, giving rise to
  a closed-form policy improvement operator. We instantiate both one-step and iterative
  offline RL algorithms with our novel policy improvement operators and empirically
  demonstrate their effectiveness over state-of-the-art algorithms on the standard
  D4RL benchmark. Our code is available at https://cfpi-icml23.github.io/.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23av
month: 0
tex_title: Offline Reinforcement Learning with Closed-Form Policy Improvement Operators
firstpage: 20485
lastpage: 20528
page: 20485-20528
order: 20485
cycles: false
bibtex_author: Li, Jiachen and Zhang, Edwin and Yin, Ming and Bai, Qinxun and Wang,
  Yu-Xiang and Wang, William Yang
author:
- given: Jiachen
  family: Li
- given: Edwin
  family: Zhang
- given: Ming
  family: Yin
- given: Qinxun
  family: Bai
- given: Yu-Xiang
  family: Wang
- given: William Yang
  family: Wang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23av/li23av.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
