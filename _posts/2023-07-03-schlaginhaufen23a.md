---
title: Identifiability and Generalizability in Constrained Inverse Reinforcement Learning
openreview: tQ4hdUoM1E
abstract: Two main challenges in Reinforcement Learning (RL) are designing appropriate
  reward functions and ensuring the safety of the learned policy. To address these
  challenges, we present a theoretical framework for Inverse Reinforcement Learning
  (IRL) in constrained Markov decision processes. From a convex-analytic perspective,
  we extend prior results on reward identifiability and generalizability to both the
  constrained setting and a more general class of regularizations. In particular,
  we show that identifiability up to potential shaping (Cao et al., 2021) is a consequence
  of entropy regularization and may generally no longer hold for other regularizations
  or in the presence of safety constraints. We also show that to ensure generalizability
  to new transition laws and constraints, the true reward must be identified up to
  a constant. Additionally, we derive a finite sample guarantee for the suboptimality
  of the learned rewards, and validate our results in a gridworld environment.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schlaginhaufen23a
month: 0
tex_title: Identifiability and Generalizability in Constrained Inverse Reinforcement
  Learning
firstpage: 30224
lastpage: 30251
page: 30224-30251
order: 30224
cycles: false
bibtex_author: Schlaginhaufen, Andreas and Kamgarpour, Maryam
author:
- given: Andreas
  family: Schlaginhaufen
- given: Maryam
  family: Kamgarpour
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/schlaginhaufen23a/schlaginhaufen23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
