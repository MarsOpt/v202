---
title: 'The SSL Interplay: Augmentations, Inductive Bias, and Generalization'
openreview: d2aohFmZoB
abstract: Self-supervised learning (SSL) has emerged as a powerful framework to learn
  representations from raw data without supervision. Yet in practice, engineers face
  issues such as instability in tuning optimizers and collapse of representations
  during training. Such challenges motivate the need for a theory to shed light on
  the complex interplay between the choice of data augmentation, network architecture,
  and training algorithm. % on the resulting performance in downstream tasks. We study
  such an interplay with a precise analysis of generalization performance on both
  pretraining and downstream tasks in kernel regimes, and highlight several insights
  for SSL practitioners that arise from our theory.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cabannes23a
month: 0
tex_title: 'The {SSL} Interplay: Augmentations, Inductive Bias, and Generalization'
firstpage: 3252
lastpage: 3298
page: 3252-3298
order: 3252
cycles: false
bibtex_author: Cabannes, Vivien and Kiani, Bobak and Balestriero, Randall and Lecun,
  Yann and Bietti, Alberto
author:
- given: Vivien
  family: Cabannes
- given: Bobak
  family: Kiani
- given: Randall
  family: Balestriero
- given: Yann
  family: Lecun
- given: Alberto
  family: Bietti
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/cabannes23a/cabannes23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
