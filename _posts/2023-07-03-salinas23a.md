---
title: Optimizing Hyperparameters with Conformal Quantile Regression
openreview: UE8EkguNmO
abstract: Many state-of-the-art hyperparameter optimization (HPO) algorithms rely
  on model-based optimizers that learn surrogate models of the target function to
  guide the search. Gaussian processes are the de facto surrogate model due to their
  ability to capture uncertainty. However, they make strong assumptions about the
  observation noise, which might not be warranted in practice. In this work, we propose
  to leverage conformalized quantile regression which makes minimal assumptions about
  the observation noise and, as a result, models the target function in a more realistic
  and robust fashion which translates to quicker HPO convergence on empirical benchmarks.
  To apply our method in a multi-fidelity setting, we propose a simple, yet effective,
  technique that aggregates observed results across different resource levels and
  outperforms conventional methods across many empirical tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: salinas23a
month: 0
tex_title: Optimizing Hyperparameters with Conformal Quantile Regression
firstpage: 29876
lastpage: 29893
page: 29876-29893
order: 29876
cycles: false
bibtex_author: Salinas, David and Golebiowski, Jacek and Klein, Aaron and Seeger,
  Matthias and Archambeau, Cedric
author:
- given: David
  family: Salinas
- given: Jacek
  family: Golebiowski
- given: Aaron
  family: Klein
- given: Matthias
  family: Seeger
- given: Cedric
  family: Archambeau
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/salinas23a/salinas23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
