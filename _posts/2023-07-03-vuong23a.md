---
title: Vector Quantized Wasserstein Auto-Encoder
openreview: eh4403nqwh
abstract: Learning deep discrete latent presentations offers a promise of better symbolic
  and summarized abstractions that are more useful to subsequent downstream tasks.
  Inspired by the seminal Vector Quantized Variational Auto-Encoder (VQ-VAE), most
  of work in learning deep discrete representations has mainly focused on improving
  the original VQ-VAE form and none of them has studied learning deep discrete representations
  from the generative viewpoint. In this work, we study learning deep discrete representations
  from the generative viewpoint. Specifically, we endow discrete distributions over
  sequences of codewords and learn a deterministic decoder that transports the distribution
  over the sequences of codewords to the data distribution via minimizing a WS distance
  between them. We develop further theories to connect it with the clustering viewpoint
  of WS distance, allowing us to have a better and more controllable clustering solution.
  Finally, we empirically evaluate our method on several well-known benchmarks, where
  it achieves better qualitative and quantitative performances than the other VQ-VAE
  variants in terms of the codebook utilization and image reconstruction/generation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vuong23a
month: 0
tex_title: Vector Quantized {W}asserstein Auto-Encoder
firstpage: 35223
lastpage: 35242
page: 35223-35242
order: 35223
cycles: false
bibtex_author: Vuong, Long Tung and Le, Trung and Zhao, He and Zheng, Chuanxia and
  Harandi, Mehrtash and Cai, Jianfei and Phung, Dinh
author:
- given: Long Tung
  family: Vuong
- given: Trung
  family: Le
- given: He
  family: Zhao
- given: Chuanxia
  family: Zheng
- given: Mehrtash
  family: Harandi
- given: Jianfei
  family: Cai
- given: Dinh
  family: Phung
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/vuong23a/vuong23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
