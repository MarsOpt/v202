---
title: Pretraining Language Models with Human Preferences
openreview: AT8Iw8KOeC
abstract: 'Language models (LMs) are pretrained to imitate text from large and diverse
  datasets that contain content that would violate human preferences if generated
  by an LM: falsehoods, offensive comments, personally identifiable information, low-quality
  or buggy code, among others. Here, we explore alternative objectives for pretraining
  LMs in a way that also guides them to generate text aligned with human preferences.
  We benchmark five objectives for pretraining with human feedback across three tasks
  and study how they affect the alignment and capabilities of pretrained LMs. We find
  a Pareto-optimal and simple approach among those we explored: conditional training,
  or learning distribution over tokens conditional on their human preference scores.
  Conditional training reduces the rate of undesirable content by up to an order of
  magnitude, both when generating without a prompt and with an adversarially-chosen
  prompt. Moreover, conditional training maintains the downstream task performance
  of standard LM pretraining, both before and after task-specific finetuning. Pretraining
  with human feedback results in much better preference satisfaction than standard
  LM pretraining followed by finetuning with feedback, i.e., learning and then unlearning
  undesirable behavior. Our results suggest that we should move beyond imitation learning
  when pretraining LMs and incorporate human preferences from the start of training.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: korbak23a
month: 0
tex_title: Pretraining Language Models with Human Preferences
firstpage: 17506
lastpage: 17533
page: 17506-17533
order: 17506
cycles: false
bibtex_author: Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika
  Vinayak and Buckley, Christopher and Phang, Jason and Bowman, Samuel R. and Perez,
  Ethan
author:
- given: Tomasz
  family: Korbak
- given: Kejian
  family: Shi
- given: Angelica
  family: Chen
- given: Rasika Vinayak
  family: Bhalerao
- given: Christopher
  family: Buckley
- given: Jason
  family: Phang
- given: Samuel R.
  family: Bowman
- given: Ethan
  family: Perez
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/korbak23a/korbak23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
