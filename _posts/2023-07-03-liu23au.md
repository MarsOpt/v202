---
title: Optimization for Amortized Inverse Problems
openreview: U86dkQE5jT
abstract: Incorporating a deep generative model as the prior distribution in inverse
  problems has established substantial success in reconstructing images from corrupted
  observations. Notwithstanding, the existing optimization approaches use gradient
  descent largely without adapting to the non-convex nature of the problem and can
  be sensitive to initial values, impeding further performance improvement. In this
  paper, we propose an efficient amortized optimization scheme for inverse problems
  with a deep generative prior. Specifically, the optimization task with high degrees
  of difficulty is decomposed into optimizing a sequence of much easier ones. We provide
  a theoretical guarantee of the proposed algorithm and empirically validate it on
  different inverse problems. As a result, our approach outperforms baseline methods
  qualitatively and quantitatively by a large margin.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu23au
month: 0
tex_title: Optimization for Amortized Inverse Problems
firstpage: 22289
lastpage: 22319
page: 22289-22319
order: 22289
cycles: false
bibtex_author: Liu, Tianci and Yang, Tong and Zhang, Quan and Lei, Qi
author:
- given: Tianci
  family: Liu
- given: Tong
  family: Yang
- given: Quan
  family: Zhang
- given: Qi
  family: Lei
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/liu23au/liu23au.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
