---
title: Jump-Start Reinforcement Learning
openreview: 2M7lwN0DTp
abstract: 'Reinforcement learning (RL) provides a theoretical framework for continuously
  improving an agent’s behavior via trial and error. However, efficiently learning
  policies from scratch can be very difficult, particularly for tasks that present
  exploration challenges. In such settings, it might be desirable to initialize RL
  with an existing policy, offline data, or demonstrations. However, naively performing
  such initialization in RL often works poorly, especially for value-based methods.
  In this paper, we present a meta algorithm that can use offline data, demonstrations,
  or a pre-existing policy to initialize an RL policy, and is compatible with any
  RL approach. In particular, we propose Jump-Start Reinforcement Learning (JSRL),
  an algorithm that employs two policies to solve tasks: a guide-policy, and an exploration-policy.
  By using the guide-policy to form a curriculum of starting states for the exploration-policy,
  we are able to efficiently improve performance on a set of simulated robotic tasks.
  We show via experiments that it is able to significantly outperform existing imitation
  and reinforcement learning algorithms, particularly in the small-data regime. In
  addition, we provide an upper bound on the sample complexity of JSRL and show that
  with the help of a guide-policy, one can improve the sample complexity for non-optimism
  exploration methods from exponential in horizon to polynomial.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: uchendu23a
month: 0
tex_title: Jump-Start Reinforcement Learning
firstpage: 34556
lastpage: 34583
page: 34556-34583
order: 34556
cycles: false
bibtex_author: Uchendu, Ikechukwu and Xiao, Ted and Lu, Yao and Zhu, Banghua and Yan,
  Mengyuan and Simon, Jos\'{e}phine and Bennice, Matthew and Fu, Chuyuan and Ma, Cong
  and Jiao, Jiantao and Levine, Sergey and Hausman, Karol
author:
- given: Ikechukwu
  family: Uchendu
- given: Ted
  family: Xiao
- given: Yao
  family: Lu
- given: Banghua
  family: Zhu
- given: Mengyuan
  family: Yan
- given: Joséphine
  family: Simon
- given: Matthew
  family: Bennice
- given: Chuyuan
  family: Fu
- given: Cong
  family: Ma
- given: Jiantao
  family: Jiao
- given: Sergey
  family: Levine
- given: Karol
  family: Hausman
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/uchendu23a/uchendu23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
