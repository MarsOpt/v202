---
title: 'Reinforcement Learning with General Utilities: Simpler Variance Reduction
  and Large State-Action Space'
openreview: ZnHXYHx70x
abstract: We consider the reinforcement learning (RL) problem with general utilities
  which consists in maximizing a function of the state-action occupancy measure. Beyond
  the standard cumulative reward RL setting, this problem includes as particular cases
  constrained RL, pure exploration and learning from demonstrations among others.
  For this problem, we propose a simpler single-loop parameter-free normalized policy
  gradient algorithm. Implementing a recursive momentum variance reduction mechanism,
  our algorithm achieves $\tilde{\mathcal{O}}(\epsilon^{-3})$ and $\tilde{\mathcal{O}}(\epsilon^{-2})$
  sample complexities for $\epsilon$-first-order stationarity and $\epsilon$-global
  optimality respectively, under adequate assumptions. We further address the setting
  of large finite state action spaces via linear function approximation of the occupancy
  measure and show a $\tilde{\mathcal{O}}(\epsilon^{-4})$ sample complexity for a
  simple policy gradient method with a linear regression subroutine.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: barakat23a
month: 0
tex_title: 'Reinforcement Learning with General Utilities: Simpler Variance Reduction
  and Large State-Action Space'
firstpage: 1753
lastpage: 1800
page: 1753-1800
order: 1753
cycles: false
bibtex_author: Barakat, Anas and Fatkhullin, Ilyas and He, Niao
author:
- given: Anas
  family: Barakat
- given: Ilyas
  family: Fatkhullin
- given: Niao
  family: He
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/barakat23a/barakat23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
