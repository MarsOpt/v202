---
title: Uncovering Adversarial Risks of Test-Time Adaptation
openreview: tHLLq4S9Dr
abstract: Recently, test-time adaptation (TTA) has been proposed as a promising solution
  for addressing distribution shifts. It allows a base model to adapt to an unforeseen
  distribution during inference by leveraging the information from the batch of (unlabeled)
  test data. However, we uncover a novel security vulnerability of TTA based on the
  insight that predictions on benign samples can be impacted by malicious samples
  in the same batch. To exploit this vulnerability, we propose Distribution Invading
  Attack (DIA), which injects a small fraction of malicious data into the test batch.
  DIA causes models using TTA to misclassify benign and unperturbed test data, providing
  an entirely new capability for adversaries that is infeasible in canonical machine
  learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness
  of our attack on multiple benchmarks across six TTA methods. In response, we investigate
  two countermeasures to robustify the existing insecure TTA implementations, following
  the principle of security by design. Together, we hope our findings can make the
  community aware of the utility-security tradeoffs in deploying TTA and provide valuable
  insights for developing robust TTA approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu23h
month: 0
tex_title: Uncovering Adversarial Risks of Test-Time Adaptation
firstpage: 37456
lastpage: 37495
page: 37456-37495
order: 37456
cycles: false
bibtex_author: Wu, Tong and Jia, Feiran and Qi, Xiangyu and Wang, Jiachen T. and Sehwag,
  Vikash and Mahloujifar, Saeed and Mittal, Prateek
author:
- given: Tong
  family: Wu
- given: Feiran
  family: Jia
- given: Xiangyu
  family: Qi
- given: Jiachen T.
  family: Wang
- given: Vikash
  family: Sehwag
- given: Saeed
  family: Mahloujifar
- given: Prateek
  family: Mittal
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wu23h/wu23h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
