---
title: Long Horizon Temperature Scaling
openreview: vSqzYxbITL
abstract: Temperature scaling is a popular technique for tuning the sharpness of a
  model distribution. It is used extensively for sampling likely generations and calibrating
  model uncertainty, and even features as a controllable parameter to many large language
  models in deployment. However, autoregressive models rely on myopic temperature
  scaling that greedily optimizes the next token. To address this, we propose <em>Long
  Horizon Temperature Scaling</em> (LHTS), a novel approach for sampling from temperature-scaled
  <em>joint</em> distributions. LHTS is compatible with all likelihood-based models,
  and optimizes for the long-horizon likelihood of samples. We derive a temperature-dependent
  LHTS objective, and show that fine-tuning a model on a range of temperatures produces
  a single model capable of generation with a controllable long-horizon temperature
  parameter. We experiment with LHTS on image diffusion models and character/language
  autoregressive models, demonstrating its advantages over myopic temperature scaling
  in likelihood and sample quality, and showing improvements in accuracy of a multiple
  choice analogy by $10$%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shih23a
month: 0
tex_title: Long Horizon Temperature Scaling
firstpage: 31422
lastpage: 31434
page: 31422-31434
order: 31422
cycles: false
bibtex_author: Shih, Andy and Sadigh, Dorsa and Ermon, Stefano
author:
- given: Andy
  family: Shih
- given: Dorsa
  family: Sadigh
- given: Stefano
  family: Ermon
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/shih23a/shih23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
