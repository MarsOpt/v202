---
title: 'Forget Unlearning: Towards True Data-Deletion in Machine Learning'
openreview: aOU7OvlxeJ
abstract: Unlearning algorithms aim to remove deleted data’s influence from trained
  models at a cost lower than full retraining. However, prior guarantees of unlearning
  in literature are flawed and don’t protect the privacy of deleted records. We show
  that when people delete their data as a function of published models, records in
  a database become interdependent. So, even retraining a fresh model after deletion
  of a record doesn’t ensure its privacy. Secondly, unlearning algorithms that cache
  partial computations to speed up the processing can leak deleted information over
  a series of releases, violating the privacy of deleted records in the long run.
  To address these, we propose a sound deletion guarantee and show that ensuring the
  privacy of existing records is necessary for the privacy of deleted records. Under
  this notion, we propose an optimal, computationally efficient, and sound machine
  unlearning algorithm based on noisy gradient descent.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chourasia23a
month: 0
tex_title: 'Forget Unlearning: Towards True Data-Deletion in Machine Learning'
firstpage: 6028
lastpage: 6073
page: 6028-6073
order: 6028
cycles: false
bibtex_author: Chourasia, Rishav and Shah, Neil
author:
- given: Rishav
  family: Chourasia
- given: Neil
  family: Shah
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chourasia23a/chourasia23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
