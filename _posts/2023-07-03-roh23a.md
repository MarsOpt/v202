---
title: Improving Fair Training under Correlation Shifts
openreview: PvaPDkAbaL
abstract: 'Model fairness is an essential element for Trustworthy AI. While many techniques
  for model fairness have been proposed, most of them assume that the training and
  deployment data distributions are identical, which is often not true in practice.
  In particular, when the bias between labels and sensitive groups changes, the fairness
  of the trained model is directly influenced and can worsen. We make two contributions
  for solving this problem. First, we analytically show that existing in-processing
  fair algorithms have fundamental limits in accuracy and group fairness. We utilize
  the notion of correlation shifts between labels and groups, which can explicitly
  capture the change of the above bias. Second, we propose a novel pre-processing
  step that samples the input data to reduce correlation shifts and thus enables the
  in-processing approaches to overcome their limitations. We formulate an optimization
  problem for adjusting the data ratio among labels and sensitive groups to reflect
  the shifted correlation. A key benefit of our approach lies in decoupling the roles
  of pre- and in-processing approaches: correlation adjustment via pre-processing
  and unfairness mitigation on the processed data via in-processing. Experiments show
  that our framework effectively improves existing in-processing fair algorithms w.r.t.
  accuracy and fairness, both on synthetic and real datasets.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: roh23a
month: 0
tex_title: Improving Fair Training under Correlation Shifts
firstpage: 29179
lastpage: 29209
page: 29179-29209
order: 29179
cycles: false
bibtex_author: Roh, Yuji and Lee, Kangwook and Whang, Steven Euijong and Suh, Changho
author:
- given: Yuji
  family: Roh
- given: Kangwook
  family: Lee
- given: Steven Euijong
  family: Whang
- given: Changho
  family: Suh
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/roh23a/roh23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
