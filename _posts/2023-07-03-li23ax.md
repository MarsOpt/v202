---
title: Internally Rewarded Reinforcement Learning
openreview: lgEYRIk7GS
abstract: We study a class of reinforcement learning problems where the reward signals
  for policy learning are generated by a discriminator that is dependent on and jointly
  optimized with the policy. This interdependence between the policy and the discriminator
  leads to an unstable learning process because reward signals from an immature discriminator
  are noisy and impede policy learning, and conversely, an under-optimized policy
  impedes discriminator learning. We call this learning setting $\textit{Internally
  Rewarded Reinforcement Learning}$ (IRRL) as the reward is not provided directly
  by the environment but $\textit{internally}$ by the discriminator. In this paper,
  we formally formulate IRRL and present a class of problems that belong to IRRL.
  We theoretically derive and empirically analyze the effect of the reward function
  in IRRL and based on these analyses propose the clipped linear reward function.
  Experimental results show that the proposed reward function can consistently stabilize
  the training process by reducing the impact of reward noise, which leads to faster
  convergence and higher performance compared with baselines in diverse tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23ax
month: 0
tex_title: Internally Rewarded Reinforcement Learning
firstpage: 20556
lastpage: 20574
page: 20556-20574
order: 20556
cycles: false
bibtex_author: Li, Mengdi and Zhao, Xufeng and Lee, Jae Hee and Weber, Cornelius and
  Wermter, Stefan
author:
- given: Mengdi
  family: Li
- given: Xufeng
  family: Zhao
- given: Jae Hee
  family: Lee
- given: Cornelius
  family: Weber
- given: Stefan
  family: Wermter
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23ax/li23ax.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
