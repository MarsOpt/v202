---
title: 'ILLUME: Rationalizing Vision-Language Models through Human Interactions'
openreview: 5e5ozhz2jF
abstract: 'Bootstrapping from pre-trained language models has been proven to be an
  efficient approach for building vision-language models (VLM) for tasks such as image
  captioning or visual question answering. However, outputs of these models rarely
  align with user’s rationales for specific answers. In order to improve this alignment
  and reinforce commonsense reasons, we propose a tuning paradigm based on human interactions
  with machine-generated data. Our ILLUME executes the following loop: Given an image-question-answer
  prompt, the VLM samples multiple candidate rationales, and a human critic provides
  feedback via preference selection, used for fine-tuning. This loop increases the
  training data and gradually carves out the VLM’s rationalization capabilities that
  are aligned with human intent. Our exhaustive experiments demonstrate that ILLUME
  is competitive with standard supervised finetuning while using significantly fewer
  training data and only requiring minimal feedback.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: brack23a
month: 0
tex_title: "{ILLUME}: Rationalizing Vision-Language Models through Human Interactions"
firstpage: 3021
lastpage: 3037
page: 3021-3037
order: 3021
cycles: false
bibtex_author: Brack, Manuel and Schramowski, Patrick and Deiseroth, Bj\"{o}rn and
  Kersting, Kristian
author:
- given: Manuel
  family: Brack
- given: Patrick
  family: Schramowski
- given: Björn
  family: Deiseroth
- given: Kristian
  family: Kersting
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/brack23a/brack23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
