---
title: Out-of-Domain Robustness via Targeted Augmentations
openreview: 4SHQv4cp3I
abstract: Models trained on one set of domains often suffer performance drops on unseen
  domains, e.g., when wildlife monitoring models are deployed in new camera locations.
  In this work, we study principles for designing data augmentations for out-of-domain
  (OOD) generalization. In particular, we focus on real-world scenarios in which some
  domain-dependent features are robust, i.e., some features that vary across domains
  are predictive OOD. For example, in the wildlife monitoring application above, image
  backgrounds vary across camera locations but indicate habitat type, which helps
  predict the species of photographed animals. Motivated by theoretical analysis on
  a linear setting, we propose targeted augmentations, which selectively randomize
  spurious domain-dependent features while preserving robust ones. We prove that targeted
  augmentations improve OOD performance, allowing models to generalize better with
  fewer domains. In contrast, existing approaches such as generic augmentations, which
  fail to randomize domain-dependent features, and domain-invariant augmentations,
  which randomize all domain-dependent features, both perform poorly OOD. In experiments
  on three real-world datasets, we show that targeted augmentations set new states-of-the-art
  for OOD performance by 3.2-15.2%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao23g
month: 0
tex_title: Out-of-Domain Robustness via Targeted Augmentations
firstpage: 10800
lastpage: 10834
page: 10800-10834
order: 10800
cycles: false
bibtex_author: Gao, Irena and Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori
  and Liang, Percy
author:
- given: Irena
  family: Gao
- given: Shiori
  family: Sagawa
- given: Pang Wei
  family: Koh
- given: Tatsunori
  family: Hashimoto
- given: Percy
  family: Liang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/gao23g/gao23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
