---
title: Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal Approximation
openreview: IzehS6F8xJ
abstract: The study of universal approximation properties (UAP) for neural networks
  (NN) has a long history. When the network width is unlimited, only a single hidden
  layer is sufficient for UAP. In contrast, when the depth is unlimited, the width
  for UAP needs to be not less than the critical width $w^*_{\min}=\max(d_x,d_y)$,
  where $d_x$ and $d_y$ are the dimensions of the input and output, respectively.
  Recently, (Cai, 2022) shows that a leaky-ReLU NN with this critical width can achieve
  UAP for $L^p$ functions on a compact domain $\mathcal{K}$, <em>i.e.,</em> the UAP
  for $L^p(\mathcal{K},\mathbb{R}^{d_y})$. This paper examines a uniform UAP for the
  function class $C(\mathcal{K},\mathbb{R}^{d_y})$ and gives the exact minimum width
  of the leaky-ReLU NN as $w_{\min}=\max(d_x+1,d_y)+1_{d_y=d_x+1}$, which involves
  the effects of the output dimensions. To obtain this result, we propose a novel
  lift-flow-discretization approach that shows that the uniform UAP has a deep connection
  with topological theory.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23g
month: 0
tex_title: Minimum Width of Leaky-{R}e{LU} Neural Networks for Uniform Universal Approximation
firstpage: 19460
lastpage: 19470
page: 19460-19470
order: 19460
cycles: false
bibtex_author: Li, Li'Ang and Duan, Yifei and Ji, Guanghua and Cai, Yongqiang
author:
- given: Liâ€™Ang
  family: Li
- given: Yifei
  family: Duan
- given: Guanghua
  family: Ji
- given: Yongqiang
  family: Cai
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23g/li23g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
