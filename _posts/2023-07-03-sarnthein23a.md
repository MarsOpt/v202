---
title: Random Teachers are Good Teachers
openreview: 6NUs7C2uRo
abstract: 'In this work, we investigate the implicit regularization induced by teacher-student
  learning dynamics in self-distillation. To isolate its effect, we describe a simple
  experiment where we consider teachers at random initialization instead of trained
  teachers. Surprisingly, when distilling a student into such a random teacher, we
  observe that the resulting model and its representations already possess very interesting
  characteristics; (1) we observe a strong improvement of the distilled student over
  its teacher in terms of probing accuracy. (2) The learned representations are data-dependent
  and transferable between different tasks but deteriorate strongly if trained on
  random inputs. (3) The student checkpoint contains sparse subnetworks, so-called
  lottery tickets, and lies on the border of linear basins in the supervised loss
  landscape. These observations have interesting consequences for several important
  areas in machine learning: (1) Self-distillation can work solely based on the implicit
  regularization present in the gradient dynamics without relying on any dark knowledge,
  (2) self-supervised learning can learn features even in the absence of data augmentation
  and (3) training dynamics during the early phase of supervised training do not necessarily
  require label information. Finally, we shed light on an intriguing local property
  of the loss landscape: the process of feature learning is strongly amplified if
  the student is initialized closely to the teacher. These results raise interesting
  questions about the nature of the landscape that have remained unexplored so far.
  Code is available at https://github.com/safelix/dinopl.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sarnthein23a
month: 0
tex_title: Random Teachers are Good Teachers
firstpage: 30022
lastpage: 30041
page: 30022-30041
order: 30022
cycles: false
bibtex_author: Sarnthein, Felix and Bachmann, Gregor and Anagnostidis, Sotiris and
  Hofmann, Thomas
author:
- given: Felix
  family: Sarnthein
- given: Gregor
  family: Bachmann
- given: Sotiris
  family: Anagnostidis
- given: Thomas
  family: Hofmann
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/sarnthein23a/sarnthein23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
