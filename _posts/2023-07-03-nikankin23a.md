---
title: 'SinFusion: Training Diffusion Models on a Single Image or Video'
openreview: 9n9NJ4qMV6
abstract: Diffusion models exhibited tremendous progress in image and video generation,
  exceeding GANs in quality and diversity. However, they are usually trained on very
  large datasets and are not naturally adapted to manipulate a given input image or
  video. In this paper we show how this can be resolved by training a diffusion model
  on a single input image or video. Our image/video-specific diffusion model (SinFusion)
  learns the appearance and dynamics of the single image or video, while utilizing
  the conditioning capabilities of diffusion models. It can solve a wide array of
  image/video-specific manipulation tasks. In particular, our model can learn from
  few frames the motion and dynamics of a single input video. It can then generate
  diverse new video samples of the same dynamic scene, extrapolate short videos into
  long ones (both forward and backward in time) and perform video upsampling. Most
  of these tasks are not realizable by current video-specific generation methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nikankin23a
month: 0
tex_title: "{S}in{F}usion: Training Diffusion Models on a Single Image or Video"
firstpage: 26199
lastpage: 26214
page: 26199-26214
order: 26199
cycles: false
bibtex_author: Nikankin, Yaniv and Haim, Niv and Irani, Michal
author:
- given: Yaniv
  family: Nikankin
- given: Niv
  family: Haim
- given: Michal
  family: Irani
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/nikankin23a/nikankin23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
