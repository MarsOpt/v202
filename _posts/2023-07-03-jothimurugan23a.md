---
title: Robust Subtask Learning for Compositional Generalization
openreview: 0pCvCH8fW2
abstract: 'Compositional reinforcement learning is a promising approach for training
  policies to perform complex long-horizon tasks. Typically, a high-level task is
  decomposed into a sequence of subtasks and a separate policy is trained to perform
  each subtask. In this paper, we focus on the problem of training subtask policies
  in a way that they can be used to perform any task; here, a task is given by a sequence
  of subtasks. We aim to maximize the worst-case performance over all tasks as opposed
  to the average-case performance. We formulate the problem as a two agent zero-sum
  game in which the adversary picks the sequence of subtasks. We propose two RL algorithms
  to solve this game: one is an adaptation of existing multi-agent RL algorithms to
  our setting and the other is an asynchronous version which enables parallel training
  of subtask policies. We evaluate our approach on two multi-task environments with
  continuous states and actions and demonstrate that our algorithms outperform state-of-the-art
  baselines.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jothimurugan23a
month: 0
tex_title: Robust Subtask Learning for Compositional Generalization
firstpage: 15371
lastpage: 15387
page: 15371-15387
order: 15371
cycles: false
bibtex_author: Jothimurugan, Kishor and Hsu, Steve and Bastani, Osbert and Alur, Rajeev
author:
- given: Kishor
  family: Jothimurugan
- given: Steve
  family: Hsu
- given: Osbert
  family: Bastani
- given: Rajeev
  family: Alur
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/jothimurugan23a/jothimurugan23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
