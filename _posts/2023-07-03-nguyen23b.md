---
title: Provable Reset-free Reinforcement Learning by No-Regret Reduction
openreview: ZhPSR06M5C
abstract: Reinforcement learning (RL) so far has limited real-world applications.
  One key challenge is that typical RL algorithms heavily rely on a reset mechanism
  to sample proper initial states; these reset mechanisms, in practice, are expensive
  to implement due to the need for human intervention or heavily engineered environments.
  To make learning more practical, we propose a generic no-regret reduction to systematically
  design reset-free RL algorithms. Our reduction turns the reset-free RL problem into
  a two-player game. We show that achieving sublinear regret in this two-player game
  would imply learning a policy that has both sublinear performance regret and sublinear
  total number of resets in the original RL problem. This means that the agent eventually
  learns to perform optimally and avoid resets. To demonstrate the effectiveness of
  this reduction, we design an instantiation for linear Markov decision processes,
  which is the first provably correct reset-free RL algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nguyen23b
month: 0
tex_title: Provable Reset-free Reinforcement Learning by No-Regret Reduction
firstpage: 25939
lastpage: 25955
page: 25939-25955
order: 25939
cycles: false
bibtex_author: Nguyen, Hoai-An and Cheng, Ching-An
author:
- given: Hoai-An
  family: Nguyen
- given: Ching-An
  family: Cheng
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/nguyen23b/nguyen23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
