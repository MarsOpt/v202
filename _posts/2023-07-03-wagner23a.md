---
title: Fast Private Kernel Density Estimation via Locality Sensitive Quantization
openreview: gLH40bhHpm
abstract: We study efficient mechanisms for differentially private kernel density
  estimation (DP-KDE). Prior work for the Gaussian kernel described algorithms that
  run in time exponential in the number of dimensions $d$. This paper breaks the exponential
  barrier, and shows how the KDE can privately be approximated in time linear in $d$,
  making it feasible for high-dimensional data. We also present improved bounds for
  low-dimensional data. Our results are obtained through a general framework, which
  we term Locality Sensitive Quantization (LSQ), for constructing private KDE mechanisms
  where existing KDE approximation techniques can be applied. It lets us leverage
  several efficient non-private KDE methods—like Random Fourier Features, the Fast
  Gauss Transform, and Locality Sensitive Hashing—and “privatize” them in a black-box
  manner. Our experiments demonstrate that our resulting DP-KDE mechanisms are fast
  and accurate on large datasets in both high and low dimensions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wagner23a
month: 0
tex_title: Fast Private Kernel Density Estimation via Locality Sensitive Quantization
firstpage: 35339
lastpage: 35367
page: 35339-35367
order: 35339
cycles: false
bibtex_author: Wagner, Tal and Naamad, Yonatan and Mishra, Nina
author:
- given: Tal
  family: Wagner
- given: Yonatan
  family: Naamad
- given: Nina
  family: Mishra
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wagner23a/wagner23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
