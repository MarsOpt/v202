---
title: 'TIPS: Topologically Important Path Sampling for Anytime Neural Networks'
openreview: bo0cP4uK9w
abstract: Anytime neural networks (AnytimeNNs) are a promising solution to adaptively
  adjust the model complexity at runtime under various hardware resource constraints.
  However, the manually-designed AnytimeNNs are biased by designersâ€™ prior experience
  and thus provide sub-optimal solutions. To address the limitations of existing hand-crafted
  approaches, we first model the training process of AnytimeNNs as a discrete-time
  Markov chain (DTMC) and use it to identify the paths that contribute the most to
  the training of AnytimeNNs. Based on this new DTMC-based analysis, we further propose
  TIPS, a framework to automatically design AnytimeNNs under various hardware constraints.
  Our experimental results show that TIPS can improve the convergence rate and test
  accuracy of AnytimeNNs. Compared to the existing AnytimeNNs approaches, TIPS improves
  the accuracy by 2%-6.6% on multiple datasets and achieves SOTA accuracy-FLOPs tradeoffs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23a
month: 0
tex_title: "{TIPS}: Topologically Important Path Sampling for Anytime Neural Networks"
firstpage: 19343
lastpage: 19359
page: 19343-19359
order: 19343
cycles: false
bibtex_author: Li, Guihong and Bhardwaj, Kartikeya and Yang, Yuedong and Marculescu,
  Radu
author:
- given: Guihong
  family: Li
- given: Kartikeya
  family: Bhardwaj
- given: Yuedong
  family: Yang
- given: Radu
  family: Marculescu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23a/li23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
