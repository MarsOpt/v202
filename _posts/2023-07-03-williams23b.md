---
title: Approximate Stein Classes for Truncated Density Estimation
openreview: FJZlpWc9GN
abstract: Estimating truncated density models is difficult, as these models have intractable
  normalising constants and hard to satisfy boundary conditions. Score matching can
  be adapted to solve the truncated density estimation problem, but requires a continuous
  weighting function which takes zero at the boundary and is positive elsewhere. Evaluation
  of such a weighting function (and its gradient) often requires a closed-form expression
  of the truncation boundary and finding a solution to a complicated optimisation
  problem. In this paper, we propose approximate Stein classes, which in turn leads
  to a relaxed Stein identity for truncated density estimation. We develop a novel
  discrepancy measure, truncated kernelised Stein discrepancy (TKSD), which does not
  require fixing a weighting function in advance, and can be evaluated using only
  samples on the boundary. We estimate a truncated density model by minimising the
  Lagrangian dual of TKSD. Finally, experiments show the accuracy of our method to
  be an improvement over previous works even without the explicit functional form
  of the boundary.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: williams23b
month: 0
tex_title: Approximate Stein Classes for Truncated Density Estimation
firstpage: 37066
lastpage: 37090
page: 37066-37090
order: 37066
cycles: false
bibtex_author: Williams, Daniel James and Liu, Song
author:
- given: Daniel James
  family: Williams
- given: Song
  family: Liu
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/williams23b/williams23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
