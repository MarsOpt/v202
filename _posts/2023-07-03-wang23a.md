---
title: Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits
openreview: tbeLou0v9M
abstract: Regret minimization in streaming multi-armed bandits (MABs) has been studied
  extensively, and recent work has shown that algorithms with $o(K)$ memory have to
  incur $\Omega(T^{2/3})$ regret, where $K$ and $T$ are the numbers of arms and trials.
  However, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\log^{1/3}(T))$,
  which is achieved by the simple uniform exploration algorithm. In this paper, we
  close this gap and complete the picture of regret minimization in single-pass streaming
  MABs. We first improve the regret lower bound to $\Omega(K^{1/3}T^{2/3})$ for algorithms
  with $o(K)$ memory. We then show that the $\log^{1/3}(T)$ factor is not necessary
  by designing algorithms with at most $O(\log^*(K))$-arm memory and achieve $O(K^{1/3}T^{2/3})$
  expected regret based on streaming $\varepsilon$-best arm algorithms. We further
  tested the empirical performances of our algorithms on simulated MABs instances,
  where the proposed algorithms outperform the benchmark uniform exploration algorithm
  by a large margin and, on occasion, reduce the regret by up to 70%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23a
month: 0
tex_title: Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits
firstpage: 35525
lastpage: 35547
page: 35525-35547
order: 35525
cycles: false
bibtex_author: Wang, Chen
author:
- given: Chen
  family: Wang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/wang23a/wang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
