---
title: When is Realizability Sufficient for Off-Policy Reinforcement Learning?
openreview: 2gkWFSkdnW
abstract: 'Understanding when reinforcement learning algorithms can make successful
  off-policy predictions—and when the may fail to do so–remains an open problem. Typically,
  model-free algorithms for reinforcement learning are analyzed under a condition
  called Bellman completeness when they operate off-policy with function approximation,
  unless additional conditions are met. However, Bellman completeness is a requirement
  that is much stronger than realizability and that is deemed to be too strong to
  hold in practice. In this work, we relax this structural assumption and analyze
  the statistical complexity of off-policy reinforcement learning when only realizability
  holds for the prescribed function class. We establish finite-sample guarantees for
  off-policy reinforcement learning that are free of the approximation error term
  known as inherent Bellman error, and that depend on the interplay of three factors.
  The first two are well known: they are the metric entropy of the function class
  and the concentrability coefficient that represents the cost of learning off-policy.
  The third factor is new, and it measures the violation of Bellman completeness,
  namely the mis-alignment between the chosen function class and its image through
  the Bellman operator. Our analysis directly applies to the solution found by temporal
  difference algorithms when they converge.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zanette23a
month: 0
tex_title: When is Realizability Sufficient for Off-Policy Reinforcement Learning?
firstpage: 40637
lastpage: 40668
page: 40637-40668
order: 40637
cycles: false
bibtex_author: Zanette, Andrea
author:
- given: Andrea
  family: Zanette
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/zanette23a/zanette23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
