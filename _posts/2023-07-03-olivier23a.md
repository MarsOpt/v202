---
title: How Many Perturbations Break This Model? Evaluating Robustness Beyond Adversarial
  Accuracy
openreview: 3m9c6uYKK7
abstract: 'Robustness to adversarial attacks is typically evaluated with adversarial
  accuracy. While essential, this metric does not capture all aspects of robustness
  and in particular leaves out the question of how many perturbations can be found
  for each point. In this work, we introduce an alternative approach, adversarial
  sparsity, which quantifies how difficult it is to find a successful perturbation
  given both an input point and a constraint on the direction of the perturbation.
  We show that sparsity provides valuable insight into neural networks in multiple
  ways: for instance, it illustrates important differences between current state-of-the-art
  robust models them that accuracy analysis does not, and suggests approaches for
  improving their robustness. When applying broken defenses effective against weak
  attacks but not strong ones, sparsity can discriminate between the totally ineffective
  and the partially effective defenses. Finally, with sparsity we can measure increases
  in robustness that do not affect accuracy: we show for example that data augmentation
  can by itself increase adversarial robustness, without using adversarial training.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: olivier23a
month: 0
tex_title: How Many Perturbations Break This Model? {E}valuating Robustness Beyond
  Adversarial Accuracy
firstpage: 26583
lastpage: 26598
page: 26583-26598
order: 26583
cycles: false
bibtex_author: Olivier, Raphael and Raj, Bhiksha
author:
- given: Raphael
  family: Olivier
- given: Bhiksha
  family: Raj
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/olivier23a/olivier23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
