---
title: Global optimality of Elman-type RNNs in the mean-field regime
openreview: szQzz2H8er
abstract: We analyze Elman-type recurrent neural networks (RNNs) and their training
  in the mean-field regime. Specifically, we show convergence of gradient descent
  training dynamics of the RNN to the corresponding mean-field formulation in the
  large width limit. We also show that the fixed points of the limiting infinite-width
  dynamics are globally optimal, under some assumptions on the initialization of the
  weights. Our results establish optimality for feature-learning with wide RNNs in
  the mean-field regime.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: agazzi23a
month: 0
tex_title: Global optimality of Elman-type {RNN}s in the mean-field regime
firstpage: 196
lastpage: 227
page: 196-227
order: 196
cycles: false
bibtex_author: Agazzi, Andrea and Lu, Jianfeng and Mukherjee, Sayan
author:
- given: Andrea
  family: Agazzi
- given: Jianfeng
  family: Lu
- given: Sayan
  family: Mukherjee
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/agazzi23a/agazzi23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
