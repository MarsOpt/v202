---
title: Is Overfitting Necessary for Implicit Video Representation?
openreview: JuNIuHLm9y
abstract: Compact representation of multimedia signals using implicit neural representations
  (INRs) has advanced significantly over the past few years, and recent works address
  their applications to video. Existing studies on video INR have focused on network
  architecture design as all video information is contained within network parameters.
  Here, we propose a new paradigm in efficient INR for videos based on the idea of
  strong lottery ticket (SLT) hypothesis (Zhou et al., 2019), which demonstrates the
  possibility of finding an accurate subnetwork mask, called supermask, for a randomly
  initialized classification network without weight training. Specifically, we train
  multiple supermasks with a hierarchical structure for a randomly initialized image-wise
  video representation model without weight updates. Different from a previous approach
  employing hierarchical supermasks (Okoshi et al., 2022), a trainable scale parameter
  for each mask is used instead of multiplying by the same fixed scale for all levels.
  This simple modification widens the parameter search space to sufficiently explore
  various sparsity patterns, leading the proposed algorithm to find stronger subnetworks.
  Moreover, extensive experiments on popular UVG benchmark show that random subnetworks
  obtained from our framework achieve higher reconstruction and visual quality than
  fully trained models with similar encoding sizes. Our study is the first to demonstrate
  the existence of SLTs in video INR models and propose an efficient method for finding
  them.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: choi23b
month: 0
tex_title: Is Overfitting Necessary for Implicit Video Representation?
firstpage: 5748
lastpage: 5770
page: 5748-5770
order: 5748
cycles: false
bibtex_author: Choi, Hee Min and Kang, Hyoa and Oh, Dokwan
author:
- given: Hee Min
  family: Choi
- given: Hyoa
  family: Kang
- given: Dokwan
  family: Oh
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/choi23b/choi23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
