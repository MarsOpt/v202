---
title: Grounding Large Language Models in Interactive Environments with Online Reinforcement
  Learning
openreview: feXm8GbxWU
abstract: 'Recent works successfully leveraged Large Language Models’ (LLM) abilities
  to capture abstract knowledge about world’s physics to solve decision-making problems.
  Yet, the alignment between LLMs’ knowledge and the environment can be wrong and
  limit functional competence due to lack of grounding. In this paper, we study an
  approach (named GLAM) to achieve this alignment through functional grounding: we
  consider an agent using an LLM as a policy that is progressively updated as the
  agent interacts with the environment, leveraging online Reinforcement Learning to
  improve its performance to solve goals. Using an interactive textual environment
  designed to study higher-level forms of functional grounding, and a set of spatial
  and navigation tasks, we study several scientific questions: 1) Can LLMs boost sample
  efficiency for online learning of various RL tasks? 2) How can it boost different
  forms of generalization? 3) What is the impact of online learning? We study these
  questions by functionally grounding several variants (size, architecture) of FLAN-T5.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: carta23a
month: 0
tex_title: Grounding Large Language Models in Interactive Environments with Online
  Reinforcement Learning
firstpage: 3676
lastpage: 3713
page: 3676-3713
order: 3676
cycles: false
bibtex_author: Carta, Thomas and Romac, Cl\'{e}ment and Wolf, Thomas and Lamprier,
  Sylvain and Sigaud, Olivier and Oudeyer, Pierre-Yves
author:
- given: Thomas
  family: Carta
- given: Clément
  family: Romac
- given: Thomas
  family: Wolf
- given: Sylvain
  family: Lamprier
- given: Olivier
  family: Sigaud
- given: Pierre-Yves
  family: Oudeyer
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/carta23a/carta23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
