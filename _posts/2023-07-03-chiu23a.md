---
title: Tight Certification of Adversarially Trained Neural Networks via Nonconvex
  Low-Rank Semidefinite Relaxations
openreview: SwWLzvsURq
abstract: Adversarial training is well-known to produce high-quality neural network
  models that are empirically robust against adversarial perturbations. Nevertheless,
  once a model has been adversarially trained, one often desires a certification that
  the model is truly robust against all future attacks. Unfortunately, when faced
  with adversarially trained models, all existing approaches have significant trouble
  making certifications that are strong enough to be practically useful. Linear programming
  (LP) techniques in particular face a “convex relaxation barrier” that prevent them
  from making high-quality certifications, even after refinement with mixed-integer
  linear programming (MILP) and branch-and-bound (BnB) techniques. In this paper,
  we propose a nonconvex certification technique, based on a low-rank restriction
  of a semidefinite programming (SDP) relaxation. The nonconvex relaxation makes strong
  certifications comparable to much more expensive SDP methods, while optimizing over
  dramatically fewer variables comparable to much weaker LP methods. Despite nonconvexity,
  we show how off-the-shelf local optimization algorithms can be used to achieve and
  to certify global optimality in polynomial time. Our experiments find that the nonconvex
  relaxation almost completely closes the gap towards exact certification of adversarially
  trained models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chiu23a
month: 0
tex_title: Tight Certification of Adversarially Trained Neural Networks via Nonconvex
  Low-Rank Semidefinite Relaxations
firstpage: 5631
lastpage: 5660
page: 5631-5660
order: 5631
cycles: false
bibtex_author: Chiu, Hong-Ming and Zhang, Richard Y.
author:
- given: Hong-Ming
  family: Chiu
- given: Richard Y.
  family: Zhang
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/chiu23a/chiu23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
